Keyword: IV
Occurrences: 2629
================================================================================

Page    2: notably the Transport Layer Security (TLS) protocol, making it relatively easy to incorporate
Page    2: probability theory and algebra is provided in the appendices. The book is divided into three parts.
Page    4: 2.3.5   Bit guessing: an alternative characterization of semantic security . . . . . .          25
Page    4: iv
Page    5: 3.11   A broader perspective: computational indistinguishability . . . . . . . . . . . . . . .         81
Page    5: 4.2.2  Exhaustive search on DES: the DES challenges . . . . . . . . . . . . . . . . 111
Page    5: 4.2.3  Strengthening ciphers against exhaustive search: the 3E construction . . . . 113
Page    5: 4.3.4  Quantum exhaustive search attacks . . . . . . . . . . . . . . . . . . . . . . . 129
Page    6: 4.7.2   Exhaustive search in the ideal cipher model . . . . . . . . . . . . . . . . . . 153
Page    7: 7 Message integrity from universal hashing                                                         248
Page    7: 7.1 Universal hash functions (UHFs) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
Page    8: 8.10   Key derivation and the random oracle model . . . . . . . . . . . . . . . . . . . . . . 320
Page    8: 8.10.1 The key derivation problem . . . . . . . . . . . . . . . . . . . . . . . . . . . 320
Page    8: 9.2.1   Chosen ciphertext attacks: a motivating example . . . . . . . . . . . . . . . 350
Page    8: 9.12 A fun application: private information retrieval . . . . . . . . . . . . . . . . . . . . . 386
Page    9: 10.6 Collision resistant hash functions from number-theoretic primitives . . . . . . . . . . 409
Page    9: 11.7 Fun application: oblivious transfer from DDH . . . . . . . . . . . . . . . . . . . . . 448
Page   10: 12.5.1 Universal projective hash functions . . . . . . . . . . . . . . . . . . . . . . . 474
Page   10: 12.5.2 Universal2 projective hash functions . . . . . . . . . . . . . . . . . . . . . . 476
Page   11: 13.10 A fun application: private information retrieval . . . . . . . . . . . . . . . . . . . . . 560
Page   12: 18.1 Interactive protocols: general notions . . . . . . . . . . . . . . . . . . . . . . . . . . 621
Page   13: 18.6 Challenge-response: security against active attacks . . . . . . . . . . . . . . . . . . . 642
Page   13: 19.8.3 Actively secure identification protocols . . . . . . . . . . . . . . . . . . . . . 693
Page   14: 20.3 Non-interactive proof systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 715
Page   14: 20.3.2 Non-interactive proofs: basic syntax . . . . . . . . . . . . . . . . . . . . . . 717
Page   14: 20.3.4 Non-interactive existential soundness . . . . . . . . . . . . . . . . . . . . . . 718
Page   14: 20.3.5 Non-interactive zero knowledge . . . . . . . . . . . . . . . . . . . . . . . . . 718
Page   14: 20.6 Succinct non-interactive zero-knowledge proofs (SNARKs) . . . . . . . . . . . . . . 724
Page   14: xiv
Page   15: IV     Appendices                                                                                      813
Page   19: receiving c, Bob decrypts c under k, and the correctness property ensures that D(k, c) is the same
Page   19: transit from Alice to Bob. Of course, the goal, intuitively, is that an eavesdropper, who may obtain
Page   19: c while it is in transit, does not learn too much about Alice’s message m — this intuitive notion is
Page   20: Here, “ ” denotes bit-wise exclusive-OR, or in other words, component-wise addition modulo 2,
Page   21: Example 2.4 (additive one-time pad). We may also define a “addition mod n” variation of
Page   21: {0, . . . , n 1}, where n is a positive integer. Encryption and decryption are defined as follows:
Page   21: Next, we address the question: what is a “secure” cipher? Intuitively, the answer is that a secure
Page   21: tion. However, turning this intuitive answer into one that is both mathematically meaningful and
Page   22: message space. This fact provides the motivation for developing a definition of security that is
Page   22: and the message m. Thus, every message m gives rise to a di↵erent random variable E(k, m).
Page   23: There are a number of equivalent formulations of perfect security that we shall explore. We
Page   23: equivalent:
Page   23: As promised, we give a proof that the one-time pad (see Example 2.1) is perfectly secure.
Page   24: Intuitively, the variable length one-time pad cannot satisfy our definition of perfect security
Page   24: greatly, and while we could always “pad” short messages to e↵ectively make all messages equally
Page   24: Example 2.7. Consider the additive one-time pad, defined in Example 2.4. It is easy to verity
Page   24: The next two theorems develop two more alternative characterizations of perfect security. For
Page   25: let , m0 , and m1 be given. Let S := {c 2 C : (c)}. Then we have
Page   25: Intuitively, this means that after seeing a ciphertext, we have no more information about the
Page   25: Intuitively, this means that the choice of message has no impact on the distribution of the ciphertext.
Page   28: Since the encryption algorithm is probabilistic, for a given key k and message m, the encryption
Page   28: be trivially implemented as efficient, deterministic algorithms. The same holds for the substitution
Page   29: sized ⌃. The additive one-time pad discussed in Example 2.4 is also a deterministic cipher, since
Page   29: To motivate the definition of semantic security, consider a deterministic cipher E = (E, D), defined
Page   29: time pad, which e↵ectively leak no information about an encrypted message other than its length,
Page   29: Actually, our attack game for defining semantic security comprises two alternative “sub-games,”
Page   29: Attack Game 2.1 (semantic security). For a given cipher E = (E, D), defined over (K, M, C),
Page   29: and for a given adversary A, we define two experiments, Experiment 0 and Experiment 1. For
Page   31: (which is a non-negative integer) with any given message. For most concrete message spaces,
Page   31: deemed to have broken the system just because he can e↵ectively distinguish an encryption
Page   31: show that the lengths of encrypted messages can reveal considerable information about private
Page   31: forgiving with regard to variable length message spaces, it is also easy to see that if E is the variable
Page   31: Intuitively, negligible means so small as to be “zero for all practical purposes”: think of a number
Page   32: Intuitively, in a message recovery attack, an adversary is given an encryption of a random message,
Page   32: While this may seem intuitively obvious, we give a formal proof of this. One of our motivations
Page   32: adversary A that can e↵ectively mount a message recovery attack on E can be used to build an
Page   32: attack. As before, this is done by giving attack game, which is a protocol between a challenger and
Page   32: Attack Game 2.2 (message recovery). For a given cipher E = (E, D), defined over (K, M, C),
Page   32: and for a given adversary A, the attack game proceeds as follows:
Page   33: efficient adversary A be given, and our goal now is to show that A’s message recovery advantage,
Page   33: of the proof here, and give another way of thinking about it.
Page   34: Another way to approach the proof of the theorem is to prove the contrapositive: if E is not
Page   34: 2.3.3.2   Computing individual bits of a message
Page   34: define parity(m) to be 1 if the number of 1’s in m is odd, and 0 otherwise. Equivalently, parity(m)
Page   34: is the exclusive-OR of all the individual bits of m.
Page   34: We will show that if E is semantically secure, then given an encryption c of a random message
Page   34: when we give A the ciphertext c, it outputs the parity of m. So we could use A to build an SS
Page   34: challenger, obtaining a ciphertext c, which it then forwards to it A. After receiving c, adversary
Page   35: this precise, we give an attack game:
Page   35: Attack Game 2.3 (parity prediction). For a given cipher E = (E, D), defined over (K, M, C),
Page   35: and for a given adversary A, the attack game proceeds as follows:
Page   35: Proof. As in the proof of Theorem 2.7, we give a proof by reduction. In particular, we will show
Page   35: Our adversary B sends the pair m0 , m1 to its own SS challenger, receives a ciphertext c from
Page   36: We have shown that if an adversary can e↵ectively predict the parity of a message, then it can
Page   36: security, he can e↵ectively predict some predicate of the message (see Exercise 3.15).
Page   36: house and a player. The player gives the house 1 dollar. He may place one of two kinds of bets:
Page   36: this encryption before placing his bet, and of course, by doing so, the player could conceivably
Page   37: To motivate and analyze our new adversary B, consider an “idealized” version of Internet
Page   39: roulette is equivalent to physical roulette. Therefore,
Page   39: throughout this text. Intuitively, if we imagine a diagram of the system, at di↵erent points in the
Page   39: 2.3.5    Bit guessing: an alternative characterization of semantic security
Page   39: convenient to work with when one is trying to prove that a given cipher satisfies the definition. In
Page   39: this alternative characterization, we define a new attack game. The role played by the adversary
Page   39: Attack Game 2.4 (semantic security: bit-guessing version). For a given cipher E = (E, D),
Page   39: defined over (K, M, C), and for a given adversary A, the attack game runs as follows:
Page   39: and choosing b̂ at random (or alternatively, always choosing b̂ to be 0, or always choosing it to be
Page   41: • the definitions model our intuitive understanding of these terms only very crudely.
Page   42: Internet roulette by more than 2 100 relative to physical roulette.
Page   42: Even though our intuitive understanding of the term efficient depends on the context, our
Page   42: bilistic) polynomial-time algorithm. For better and for worse, this gives us a formal framework that
Page   42: Intuitively, a negligible function f : Z 0 ! R is one that not only tends to zero as n ! 1, but
Page   42: An alternative characterization of a negligible function, which is perhaps easier to work with,
Page   43: • a security parameter, which is a positive integer, and is denoted by , and
Page   43: The idea is that the system parameter ⇤ (together with ) gives a detailed description of a fixed
Page   43: Example 2.12. Consider the additive one-time pad discussed in Example 2.4. This cipher was
Page   44: Definition 2.9. A system parameterization is an efficient probabilistic algorithm P that given
Page   44: • We say that S has an e↵ective length function if there is an efficient deterministic
Page   44: algorithm that on input 2 Z 1 , ⇤ 2 Supp(P ( )), and s 2 S ,⇤ , outputs a non-negative
Page   44: By not insisting that a probabilistic algorithm halts in a specified time bound with probability 1, we give ourselves
Page   44: An alternative approach would be to bound the expected running time, but this turns out to be somewhat problematic
Page   45: 3. M has an e↵ective length function.
Page   45: Example 2.13. Consider the additive one-time pad (see Example 2.12). In our formal framework,
Page   45: 4. The message space also has an e↵ective length function: just output (say) 0.       2
Page   46: Since this concept will be used extensively throughout the text, we present a more general framework
Page   46: To model these types of interactions, we introduce the notion of an interactive machine.
Page   46: of interactive machine.
Page   46: For any given environment, we can measure the total running time of M by counting the
Page   46: Analogous to the discussion in footnote 1 on page 30, our definition of an efficient interactive machine will not
Page   47: Definition 2.11 (efficient interactive machine). We say that M is an efficient interactive
Page   47: We naturally model an adversary as an interactive machine. An efficient adversary is simply
Page   47: an efficient interactive machine.
Page   47: We can connect two interactive machines together, say M 0 and M , to create a new interactive
Page   47: Definition 2.12 (elementary wrapper). An interactive machine M 0 is called an efficient
Page   48: that would otherwise be too restrictive, and should not be taken too seriously. We will never make
Page   48: an interactive machine, as described above), the function SSadv[A, E]( ) in the security parameter
Page   48: is negligible (as defined in Definition 2.5). Recall that both challenger and adversary receive
Page   50: Alice: if on a particular day the only message that Carol receives is the one from Alice and the only
Page   51: about m given c2 and one of kc or kd .
Page   51: sary is given all but one of the keys k0 , . . . , kn 1 . To make this precise, we define two experiments,
Page   51: • The adversary gives the challenger (m0 , m1 , d) where m0 , m1 2 M are equal length messages
Page   52: 2.1 (multiplicative one-time pad). We may also define a “multiplication mod p” variation of
Page   52: Here, k 1 denotes the multiplicative inverse of k modulo p. Verify the correctness property for this
Page   52: {0, 1}L where the key space K is restricted to all L-bit strings with an even number of 1’s. Give an
Page   53: but assume that the rules are easy to evaluate (given a bet and the number r) and that every bet
Page   53: algorithms yields a semantically secure scheme? Either give an attack or provide a security proof
Page   54: (iii) A3 : Output 1 if HEADS was received from the challenger, else output 0.
Page   54: (iv) A4 : Output 0 if HEADS was received from the challenger, else output 1.
Page   54: (v) A5 : If HEADS was received, output 1. If TAILS was received, randomly output 0 or 1
Page   55: adversary is given one of the keys k0 or k1 .
Page   55: (a) Construct a cipher Ẽ = (Ẽ, D̃) derived from E such that Ẽ is semantically secure, but becomes
Page   55: insecure if the adversary is given Ẽ(k, k). You have just shown that semantic security does
Page   55: (b) Construct a cipher Ê = (Ê, D̂) derived from E such that Ê is semantically and remains
Page   55: semantically secure (provably) even if the adversary is given Ê(k, k). To prove that Ê is
Page   55: by combining compression (such as the Lempel-Ziv algorithm used in the zip and gzip programs)
Page   56: CRIME [108] and BREACH [104] attacks are good representative examples.
Page   56: 2.18 (Voting protocols). This exercise develops a simple voting protocol based on the additive
Page   56: ing semantic security given Bob’s key kb . Denote this 2-way key splitting advantage by
Page   56: so that two of the three shares are needed for decryption. Each share can be given to a di↵erent
Page   56: bank executive, and two of the three must contribute their shares for decryption to proceed. This
Page   56: way, decryption can proceed even if one of the executives is out sick, but at least two executives
Page   57: Hint: The first executive will be given the share p0 := (k0 , k1 ).
Page   57: hidden bit b) with probability 1/2 + ✏, where ✏ is non-negligible. Note that ✏ could be positive or
Page   57: negative (the definition of negligible works on absolute values). Our goal is to show that there is
Page   57: and positive.
Page   58: when A outputs b̂, adversary B outputs b̂ 1. Now, we do not know if ✏ is positive or
Page   58: negative. If it is positive, then A satisfies are requirements. If it is negative, then B satisfies
Page   59: Suppose s is a random `-bit string and r is a random L-bit string. Intuitively, if an adversary cannot
Page   59: e↵ectively tell the di↵erence between G(s) and r, then he should not be able to tell the di↵erence
Page   59: that an adversary cannot “e↵ectively tell the di↵erence between G(s) and r.”
Page   59: is called e↵ective if the probability that it outputs 1 on a pseudo-random input is significantly
Page   59: di↵erent than the probability that it outputs 1 on a truly random input. Even a relatively small
Page   60: How might one go about designing an e↵ective statistical test? One basic approach is the
Page   60: following: given an L-bit string, calculate some statistic, and then see if this statistic di↵ers greatly
Page   60: bias towards either 0-bits or 1-bits, we could e↵ectively detect this with a statistical test that,
Page   60: e↵ective if the PRG G did indeed have some significant bias towards either 0 or 1.
Page   60: The test in the previous example can be strengthened by considering not just individual bits,
Page   60: numbers is less than some specified bound. Alternatively, one could sum up the squares of these
Page   60: there are PRG’s for which the simple tests in the previous two paragraphs are completely ine↵ective,
Page   60: but yet are completely predictable, given sufficiently many output bits; that is, given a prefix of
Page   60: Our definition of security for a PRG formalizes the notion there should be no e↵ective (and
Page   60: given as input a seed s, computes an output r. The seed s comes from a finite seed space S and
Page   60: Our definition of security for a PRG captures the intuitive notion that if s is chosen at random
Page   60: from S and r is chosen at random from R, then no efficient adversary can e↵ectively tell the
Page   60: Attack Game 3.1 (PRG). For a given PRG G, defined over (S, R), and for a given adversary
Page   61: • Given r, the adversary computes and outputs a bit b̂ 2 {0, 1}.
Page   62: Just as in Section 2.4, we give here more of the mathematical details pertaining to PRGs. Just like
Page   63: then chooses a random key s and a random bit b, and encrypts mb under s, giving the resulting
Page   63: Upon receiving m0 , m1 2 {0, 1}v from A, for some v  L, do:
Page   63: Upon receiving m0 , m1 2 {0, 1}v from A, for some v  L, do:
Page   65: receives r 2 {0, 1}L from its PRG challenger, and then plays the role of challenger to A, as follows:
Page   65: Upon receiving m0 , m1 2 {0, 1}v from A, for some v  L, do:
Page   66: is by proving the contrapositive: indeed, if we assume that E is insecure, then there must be an
Page   66: inequality) gives us an efficient adversary B such that PRGadv[B, G] is also non-negligible. That
Page   66: is, if we can break E, we can also break G. While logically equivalent, such a proof has a di↵erent
Page   66: (Fig. 2.4 or Fig. 3.4) that attacked the underlying cryptographic primitive (cipher or PRG) with an
Page   66: advantage equal to this di↵erence. Assuming the underlying primitive was secure, this di↵erence
Page   66: must be negligible; alternatively, one could argue the contrapositive: if this di↵erence were not
Page   66: negligible, the new adversary would “break” the underlying cryptographic primitive.
Page   67: messages m1 and m2 . The naive solution is to encrypt both messages using the same stream cipher
Page   67: given = m1 m2 the adversary can recover both m1 and m2 in the clear. Hence, the construction
Page   67: began an intensive e↵ort to break into the Soviet messages with the cooperation of the
Page   67: exposing Julius and Ethel Rosenberg and helped give evidence of their involvement with the Soviet
Page   68: c0 := c     for some    of the attacker’s choice. Consequently, the decryptor receives the modified
Page   68: both privacy and integrity in Chapter 9.
Page   68: from Alice containing her homework. Molly can e↵ectively steal Alice’s homework, as follows. She
Page   68: simply XORs the appropriate five-character string into the ciphertext in positions 6 to 10, so as
Page   68: Of course, for this attack to be e↵ective, Molly must somehow be able to find the email from Alice
Page   68: the proof technique, which is called a hybrid argument. This proof technique is used pervasively
Page   69: highlighted). Intuitively, under the assumption that G is a secure PRG, the adversary A should
Page   69: Upon receiving r 2 R from its challenger, B1 plays the role of challenger to A, as follows:
Page   70: Upon receiving r 2 R from its challenger, B2 plays the role of challenger to A, as follows:
Page   70: That completes the proof that G0 is secure in the case n = 2. Before giving the proof in the
Page   70: general case, we give another proof in the case n = 2. While our first proof involved the construction
Page   70: upon receiving r 2 R from its challenger, adversary B chooses ! 2 {1, 2} at random,
Page   70: and gives r to B! ; finally, B outputs whatever B! outputs.
Page   71: R. Intuitively, the adversary should not notice any of these replacements, since G is a secure
Page   71: Upon receiving r 2 R from its challenger, B plays the role of challenger to A, as follows:
Page   72: is equivalent to Hybrid j 1, while Experiment 1 of B’s attack game is equivalent to
Page   73: of this construction, suppose G is a PRG defined over ({0, 1}` , {0, 1}t+` ), for some positive integers
Page   74: receives the (r1 , . . . , rn , sn ) in Experiment 0 of Attack Game 3.1. Since s = s0 is random and G is a
Page   75: Upon receiving (r, s) 2 R ⇥ S from its challenger, B plays the role of challenger to A,
Page   75: is equivalent to Hybrid j 1, while Experiment 1 of B’s attack game is equivalent to
Page   77: the (valid) proof that we did give. For each , we defined a sequence of n( ) + 1 hybrid games,
Page   77: valid. In that case, we construct a single, fixed sequence of n + 1 games, with each individual game
Page   78: say, the last bit of G’s output, given the first L 1 bits of G’s output. Intuitively, the existence of
Page   78: such an adversary would imply that G is insecure, since given the first L 1 bits of a truly random
Page   78: that given the first i bits of G’s output, it is hard to predict the next bit (i.e., the (i + 1)-st
Page   78: shall then prove that unpredictability and security are equivalent. The fact that security implies
Page   78: unpredictability is fairly obvious: the ability to e↵ectively predict the next bit in the pseudo-random
Page   78: output string immediately gives an e↵ective statistical test. However, the fact that unpredictability
Page   78: e↵ective statistical test at all, then there is in fact an e↵ective method for predicting the next bit
Page   78: Attack Game 3.2 (Unpredictable PRG). For a given PRG G, defined over (S, {0, 1}L ), and a
Page   78: given adversary A, the attack game proceeds as follows:
Page   79: Upon receiving r 2 {0, 1}L from its challenger, B does the following:
Page   79: • B gives r[0 . . i   1] to A, obtaining A’s output g 2 {0, 1};
Page   79: an efficient adversary that can e↵ectively distinguish a pseudo-random L-bit string from a random
Page   79: L-bit string, then we can construct an efficient adversary B that can e↵ectively distinguish
Page   79: Thus, adversary B can distinguish the pseudo-random bit xj+1 from the random bit rj+1 , given
Page   79: this: given x1 , . . . , xj , we feed B the string x1 , . . . , xj r for a randomly chosen bit r; if B outputs 1,
Page   81: • Generate ! random bits r1 , . . . , r! , and give the L-bit string x k r1 · · · r! to A.
Page   82: generally in the Chapter 5, builds them from a more versatile primitive called a pseudorandom
Page   82: tively, were proposed by Bernstein in 2008. These stream ciphers have been incorporated into
Page   83: G(s, n1 ) for n1 6= n0 is another. The nonce turns the PRG into a more powerful primitive called
Page   84: generator, is completely insecure and we present it to give an example of some beautiful mathematics
Page   84: applications because they are insecure as PRGs. In particular, they are predictable: given a few
Page   84: consecutive outputs of an LCG generator it is easy to compute all subsequent outputs. In this
Page   84: ger q, two constants a, b 2 {0, . . . , q 1}, and a positive integer w  q. The constant a is taken to
Page   84: be relatively prime to q. We use Sq and R to denote the sets:
Page   84: The generator Glcg is clearly insecure since given s0 := as + b mod q it is straight-forward to
Page   84: attacker can easily recover these unknown 22 bits by exhaustive search: for every possible value
Page   85: Even when the LCG parameters are sufficiently large to prevent exhaustive search, say q = 2512 ,
Page   85: few consecutive outputs. Let us see an elegant version of this attack.
Page   85: exhaustive search on the seed s is not possible given its size. Nevertheless, we show how to quickly
Page   85: predict the generator from the output of only two consecutive iterations.
Page   85: Suppose the attacker is given two consecutive outputs of the generator ri , ri+1 2 R. We show
Page   85: where e0 and e1 are the remainders after dividing si and si+1 by w; in particular, 0  e0 , e1 < w <
Page   85: terms to put the terms involving x and s on the left gives
Page   86: a general problem called the closest vector problem: given a lattice L and a vector g, find
Page   86: and a = 2. For these a there may be many lattice vectors in La close to a given g. We leave it as
Page   87: The modular subset problem. Let q be a positive integer and set Sq := {0, . . . , q 1}. Choose n
Page   87: given (q, a, t) as input, output a vector s 2 {0, 1}n such that fa (s) = t, if one exists.
Page   88: gives a PRG whose output is twice the size of the input. We can plug this into the Blum-Micali
Page   88: applications that are not time sensitive.
Page   88: the CSS stream cipher is particularly weak and can be broken in far less time than an exhaustive
Page   88: {0, . . . , n 1}. The elements of V are called tap positions. An LFSR gives a PRG as follows
Page   88: from LFSR are attractive for low-cost consumer electronics such as DVD players, cell phones, and
Page   89: Stream ciphers from LSFRs. A single LFSR is completely insecure as a PRG since given n
Page   89: consecutive bits of its output it is trivial to compute all subsequent bits. Nevertheless, by combining
Page   89: Trivium, one of the eStream portfolio stream ciphers, is built this way.
Page   89: and should not be used: recovering the plaintext takes far less time than an exhaustive search on
Page   90: Insecurity of CSS. Given the PRG output, one can clearly recover the secret seed in time 240
Page   90: by exhaustive search over the seed space. We show a much faster attack that takes only 216 guesses.
Page   90: Suppose we are given the first 100 bytes z̄ := (z1 , z2 , . . .) output by the PRG. The attack is based
Page   90: LFSR, respectively. Then
Page   90: the resulting output to the given sequence z̄. If the sequences do not match, try another guess
Page   90: given z̄, in which case the attacker has the correct secret seed s := s1 ks2 .
Page   90: is much faster than the naive 240 -time exhaustive search attack.
Page   90: The RC4 stream cipher, designed by Ron Rivest in 1987, was historically used for securing Web
Page   91: gives an example of an RC4 state.
Page   91: such as Grain and Trivium, are designed for hardware and perform poorly when implemented in
Page   91: Modern processors operate on 64-bit words, making the 8-bit design of RC4 relatively slow on
Page   92: tion of 0 . . . 255 generated from the given random seed. For now, let us assume that the RC4 setup
Page   92: twice what it should be. This leads to a simple distinguisher for the RC4 PRG. Given a string
Page   92: negligible and sufficient to attack the cipher. They show, for example, that given the encryption of
Page   93: attacker can make the user’s browser repeatedly re-connect to the target site giving the attacker
Page   93: attack of the previous paragraph is ine↵ective. Fluhrer and McGrew [49] gave a direct attack on
Page   93: A pair of consecutive outputs (z1 , z2 ) is called a digraph. In a truly random string, the
Page   94: If the distinguisher finds more (0, 0) pairs in the given string than are likely to be in a random
Page   95: at a relatively slow rate. To generate true random bits at a faster rate, Intel added a hardware
Page   95: random number generator to starting with the Ivy Bridge processor family in 2012. Output from
Page   95: where we discuss the key derivation problem.
Page   95: generator is defective it will not completely compromise the cryptographic application.
Page   95: random” the generator is declared to be defective.
Page   95: 3.11     A broader perspective: computational indistinguishability
Page   95: Our definition of security for a pseudo-random generator G formalized the intuitive idea that an
Page   95: adversary should not be able to e↵ectively distinguish between G(s) and r, where s is a randomly
Page   95: probability distributions on some finite set R. Our goal is to formally define the intuitive notion
Page   95: that an adversary cannot e↵ectively distinguish between P0 and P1 . As usual, this is done via an
Page   95: Attack Game 3.3 (Distinguishing P0 from P1 ). For given probability distributions P0 and
Page   95: P1 on a finite set R, and for a given adversary A, we define two experiments, Experiment 0 and
Page   96: • Given x, the adversary computes and outputs a bit b̂ 2 {0, 1}.
Page   96: that no adversary can e↵ectively distinguish between them, regardless of how much computing
Page   98: by the challenger, and the value t 2 T representing its random choices. For a given t 2 T , let
Page   99: Example 3.3. Suppose we want to generate a pseudo-random number in a given interval
Page  100: The idea is that B takes its challenge value, reduces it modulo m, gives this value to A, and outputs
Page  100: ter; however, from a technical perspective, this is not necessary, as such a system parameter can be
Page  101: A simple solution to their problem makes use of a cryptographic primitive called bit commit-
Page  101: the binding property is based on the security of a given PRG G.
Page  103: (b) Give an example of a cipher that is semantically secure for random messages but that is not
Page  103: 3.3 (Bit guessing definition of semantic security). This exercise develops an alternative
Page  103: cipher, called psuedo-random ciphertext security, which intuitively says that no efficient adversary
Page  103: (c) Give an example of a cipher that is semantically secure, but not pseudo-random ciphertext
Page  104: 3.6 (Another malleability example). Let us give another example illustrating the malleability
Page  104: the given ciphertext is written in hex). What would be the stream cipher encryption of the message
Page  104: bit-strings in {0, 1}n . Which of are the following derived generators are secure?
Page  104: 3.9 (Predicting the next character). In Section 3.5, we showed that if one could e↵ectively
Page  106: defined over (K, M, C), where M = {0, 1}. Show that for every efficient adversary A that receives
Page  106: 3.16 (Previous-bit prediction). Suppose that A is an e↵ective next-bit predictor. That is,
Page  106: Show how to use A to build an explicit, e↵ective previous-bit predictor B that uses A as a black
Page  106: Hint: You can give a direct proof; alternatively, you can use the previous exercise together with
Page  107: G0 (s) := G(s) (0m n k s) derived from G. Show that there is a secure PRG G for which G0 is
Page  107: and suppose A is an adversary that given G(s) outputs s with non-negligible probability. Show
Page  107: random variables, taking values in S and T , respectively, where Y is uniformly distributed over T .
Page  108: This chapter continues the discussion begun in the previous chapter on achieving privacy against
Page  108: we will explore in Chapter 5), as well as many other cryptographic primitives.
Page  108: We will study the internal design of AES in more detail below, but for now, we just give a very
Page  108: ition is the following: an efficient adversary is given a “black box.” Inside the box is a permutation
Page  109: The adversary cannot see inside the box, but he can “probe” it with questions: he can give the
Page  109: Attack Game 4.1 (block cipher). For a given block cipher (E, D), defined over (K, X ), and for
Page  109: a given adversary A, we define two experiments, Experiment 0 and Experiment 1. For b = 0, 1, we
Page  110: The challenger computes yi          f (xi ) 2 X , and gives yi to the adversary.
Page  110: We stress that the queries made by the challenger in Attack Game 4.1 are allowed to be adaptive;
Page  110: queries are adaptive, in the sense that each query may depend on the previous responses. Finally,
Page  112: 4.1.1.3   Key space size and exhaustive-search attacks
Page  112: We can trade success probability for running time using a di↵erent attack, called an exhaustive-
Page  113: We describe a few real-world exhaustive search attacks in Section 4.2.2. We present a de-
Page  113: tailed treatment of exhaustive search in Section 4.7.2 where, in particular, we justify the heuristic
Page  113: f by keeping track of input/output pairs (xi , yi ). When the challenger receives the ith query xi ,
Page  113: upon receiving the ith query xi 2 X from A do:
Page  115: Fig. 4.4 illustrates encryption and decryption. We call E 0 the `-wise ECB cipher derived from E.
Page  116: Therefore, an adversary will not be able to trivially locate positions where individual characters
Page  116: E 0 = (E 0 , D0 ) be the `-wise ECB cipher derived from E, but with the message space restricted to all
Page  117: Proof idea. The basic idea is that if an adversary is given an encryption of a message, which is a
Page  117: sequence of distinct data blocks, then what he sees is e↵ectively just a sequence of random data
Page  117: then chooses a random key k and a random bit b, and encrypts mb under k, giving the resulting
Page  117: upon receiving m0 , m1 2 X⇤` , with v := |m0 | = |m1 |, do:
Page  117: upon receiving m0 , m1 2 X⇤` , with v := |m0 | = |m1 |, do:
Page  117: Intuitively, the fact that E is a secure block cipher implies that the adversary should not notice
Page  118: upon receiving m0 , m1 2 X⇤` from A, with v := |m0 | = |m1 |, do:
Page  118: upon receiving m0 , m1 2 X⇤` , with v := |m0 | = |m1 |, do:
Page  119: Block ciphers are a basic primitive in cryptography from which many other systems are built.
Page  120: Does iteration give a secure block cipher? Nobody knows. However, heuristic evidence
Page  120: appear to give a secure block cipher after a few iterations.
Page  121: the standard ciphers described here. Block-cipher design is non-trivial and many years of analysis
Page  121: To show that ⇡ is one-to-one we construct its inverse, which is given by:
Page  122: Given these functions, the DES round function F (k, x) works as follows:
Page  124: the competitive advantage of the United States enjoyed over other countries in the field
Page  124: These criteria were designed to make DES as strong as possible, given the 56-bit key-size constraints.
Page  125: 4.2.2   Exhaustive search on DES: the DES challenges
Page  125: Recall that an exhaustive search attack on a block cipher (E, D) (Section 4.1.1.2) refers to the
Page  125: following attack: the adversary is given a small number of plaintext blocks x1 , . . . , xQ 2 X and
Page  125: possible keys k 2 K until it finds a key that maps all the given plaintext blocks to the given
Page  125: ciphertext blocks. If enough ciphertext blocks are given, then k is the only such key, and it will be
Page  125: probability there is a unique key mapping the given plaintext blocks to the given ciphertext blocks.
Page  125: suffices to know that given three plaintext/ciphertext blocks an attacker can use exhaustive search
Page  125: In 1974, when DES was designed, an exhaustive search attack on a key space of size 256 was
Page  126: To prove that exhaustive search on DES is feasible, RSA data security setup a sequence of
Page  126: tributed idle cycles on their machines. The person whose machine found the secret-key received
Page  126: a dedicated machine to do DES exhaustive key search. The machine, called DeepCrack, cost
Page  126: 4.2.2.1    Is AES-128 vulnerable to exhaustive search?
Page  126: give some indication as to the complexity of exhaustive search on AES. The minimum AES key
Page  126: exceeds our capabilities. It is fair to conclude that a brute-force exhaustive search attack on AES
Page  127: 4.2.3     Strengthening ciphers against exhaustive search: the 3E construction
Page  127: of analysis the most practical attack on DES is a brute force exhaustive search over the entire key
Page  127: A natural question is whether we can strengthen the cipher against exhaustive search without
Page  127: While Triple-DES is not vulnerable to exhaustive search, its performance is three times slower than
Page  127: exhaustive search. Its performance is much better then Triple-DES.
Page  127: We are given Q plaintext blocks x1 , . . . , xQ and their 2E encryptions yi = E2 (k1 , k2 ), xi for
Page  127: the key space has size |K|2 . As with exhaustive search, a small number of plaintext/ciphertext pairs
Page  128: As discussed above, for relatively small values of Q, with overwhelming probability there will
Page  128: The running time of algorithm A in Theorem 4.2 is about the same as the time to do exhaustive
Page  128: search on E, suggesting that 2E does not strengthen E against exhaustive search. The theorem,
Page  129: be difficult. Alternatively an attacker can trade-o↵ storage space for running time — it is easy to
Page  129: modify A so that at any given time it only stores an ✏ fraction of the table at the cost of increasing
Page  129: NIST received 15 proposals, many of which were developed outside of the United Stated. After
Page  129: holding two open conferences to discuss the proposals, in 1999 NIST narrowed down the list to five
Page  129: in April of 2000, at which a representative of each of the final five teams made a presentation
Page  129: concluded a five year process to standardize a replacement to DES.
Page  132: Plugging these tables into (4.13) gives a fast way to evaluate ⇧AES (A):
Page  133: The AES key expansion method is intentionally designed to be invertible: given the last round
Page  133: • Key recovery: Key recovery attacks refer to an adversary who is given multiple plain-
Page  133: text/ciphertext pairs and is able to recover the secret key from these pairs, as in an exhaustive
Page  133: AES [23]. This is about four times faster than exhaustive search and takes a prohibitively
Page  133: four times faster than exhaustive search. The best known attack on AES-256 takes 2254.42
Page  133: evaluation of AES which is about three times faster than exhaustive search. None of these
Page  133: • Related key attacks: In an `-way related key attack the adversary is given ` lists of
Page  133: AES-256 is vulnerable to a related key attack that exploits its relatively simple key expansion
Page  133: are set to specific values. Then given lists of plaintext/ciphertext pairs generated for each
Page  133: the time it would take to mount an exhaustive search on AES-256. While the attack is quite
Page  134: promise from observing plaintext/ciphertext pairs. Unlike brute-force exhaustive search attacks,
Page  136: pairs are given. The following lemma shows how.
Page  136: Here, Majority takes a majority vote on the given bits; for example, on input (0, 0, 1), the
Page  136: Hence, the attacker can compute k[S2 ] from the given plaintext/ciphertext pairs and obtain one
Page  136: circuit. For a 64-bit plaintext m let mL and mR be the left and right 32-bits of m respectively.
Page  136: Similarly, for a 64-bit ciphertext c let cL and cR be the left and right 32-bits of c respectively. Then
Page  137: This observation lets an attacker recover the 12 bits k (12) of the secret key k as follows. Given
Page  137: • Step 2: sort the 212 candidates by their bias, from largest to smallest. If the list L of given
Page  137: known we can determine the bit k[Se0 ] using Lemma 4.3, giving a total of 13 bits of k.
Page  137: This gives the attacker a total 26 bits of the key. The remaining 56 26 = 30 bits are recovered
Page  137: by exhaustive search.
Page  137: Naively computing the biases in Step 1 takes time 212 ⇥ t: for each candidate for k (12) one has
Page  137: approximately time t. For a given pair (m, c), the left hand side of (4.17) can be computed from only
Page  137: Matsui shows that given a list of 243 plaintext/ciphertext pairs this attack succeeds with proba-
Page  137: likely candidates from Step 1 on average. In other words, the exhaustive search for the remaining
Page  138: 256 evaluations that would be needed in an exhaustive search. However, unlike exhaustive search,
Page  138: on the same machine as the victim, for example, when a low-privilege process tries to extract a
Page  138: secret key from a high-privilege process. In this case, the attacker obtains very accurate timing
Page  138: fastest layer, called the L1 cache, is relatively small (e.g. 64KB). Data is loaded into the L1 cache
Page  139: The attacker is given this final output C.
Page  139: To mount the attack, consider two consecutive entries in the output matrix C, say c0 = S[a0 ]+w0
Page  139: among all ciphertexts in L . Given enough samples, the lowest average running time is obtained
Page  139: the timing procedure above for di↵erent consecutive pairs ci and ci+1 in C reveals the di↵erence
Page  139: in GF(28 ) between every two consecutive bytes of the last round key. Then if the first byte of
Page  140: on a Pentium IV Xeon successfully recovered the AES secret key using about 220 timing measure-
Page  140: Pentium IV Xeon uses 32-byte cache lines so that the S table is split across eight lines.
Page  140: from L1 cache while AES is executing. Ensuring that the tables stay in L1 cache is non-trivial on a
Page  140: given time. In particular, an attacker can measure the amount of power consumed as the AES
Page  141: simple power analysis was an attractive feature of AES.
Page  142: leaks every time the decryption algorithm runs. The goal is to then preemptively re-randomize the
Page  143: given input plaintext. If the check fails, the hardware outputs an error and discards the computed
Page  143: 4.3.4    Quantum exhaustive search attacks
Page  143: (E, D) with key space K. Recall that in a classical exhaustive search the attacker is given a few
Page  143: a key that maps the given plaintexts to the given ciphertexts. On a classical computer this takes
Page  143: Quantum exhaustive search. Surprisingly, on p        a quantum computer the same exhaustive search
Page  143: that exhaustive search will only require about 2 = 264 steps. Computations involving 264 steps
Page  143: The above discussion suggests that for a block cipher to resist a quantum exhaustive search
Page  143: attack its key space |K| must have at least 2256 keys, so that the time for quantum exhaustive
Page  143: breaking the AES-256 block cipher, but at least quantum exhaustive search is out of the question.
Page  143: Grover’s algorithm. The algorithm for quantum exhaustive search is a special case of a more
Page  143: we are given a function f : K ! {0, 1} defined as follows
Page  143: for some k0 2 K. The goal is to find k0 given only “black-box” access to f , namely by only querying
Page  144: To break a block cipher like AES-128 given a few plaintext/ciphertext pairs we would define
Page  144: where m = (m0 , . . . , mQ ) and c = (c0 , . . . , cQ ) are the given ciphertext blocks. Assuming enough
Page  144: blocks are given, there is a unique
Page  144: Intuitively, our notion of security for a pseudo-random function says that for a randomly chosen
Page  144: Attack Game 4.2 (PRF). For a given PRF F , defined over (K, X , Y), and for a given adversary
Page  145: The challenger computes yi          f (xi ) 2 Y, and gives yi to the adversary.
Page  145: adaptive: the adversary is allowed to concoct each query in a way that depends on the previous
Page  146: cipher case, the challenger keeps track of input/output pairs (xi , yi ). When the challenger receives
Page  146: upon receiving the ith query xi 2 X from A do:
Page  146: no efficient adversary can e↵ectively distinguish E from a random permutation. Does this imply
Page  146: that E is also a secure PRF? That is, does this imply that no efficient adversary can e↵ectively
Page  146: it sees that f (x) = f (x0 ) for two distinct values x, x0 2 X (from among the Q values given to the
Page  146: Before proving this theorem, we derive the following simple corollary:
Page  147: Attack Game 4.3 (permutation vs. function). For a given finite set X , and for a given
Page  147: The challenger computes yi             f (xi ) 2 Y, and gives yi to the adversary.
Page  148: In most of our applications of the Di↵erence Lemma, W0 will represent the event that a given
Page  149: upon receiving the ith query xi from A do:
Page  149: upon receiving the ith query xi from A do:
Page  149: Observe that Game 1 is equivalent to Experiment 1 of Attack Game 4.3; in particular, Pr[W1 ]
Page  150: plays the role of challenger to A, giving A the value (y1 , . . . , y` ). Adversary B outputs
Page  151: The above construction gives us another way to build a semantically secure cipher out of a secure
Page  151: As usual, we give a more mathematically precise definition of a PRF, using the terminology defined
Page  153: Given a key (k1 , k2 , k3 ) 2 K3 and a data block (u, v) 2 X 2 , the encryption algorithm E runs as
Page  153: Given a key (k1 , k2 , k3 ) 2 K3 and an data block (x, y) 2 X 2 , the decryption algorithm D runs as
Page  155: Game 4.2 with respect to E, the challenger’s responses e↵ectively “look like” completely random
Page  155: So now, given a query (ui , vi ), the challenger computes its response (xi , yi ) as follows:
Page  155: A rough, intuitive argument goes like this. Suppose that no two wi values are the same. Then
Page  156: A0 and a di↵erent challenger; moreover, the challenger in Game 3 is equivalent to the challenger
Page  156: Game 0. Let us begin by giving a detailed description of the challenger in Game 0 that is convenient
Page  156: upon receiving the ith query (ui , vi ) 2 X 2 (for i = 1, . . . , Q) do:
Page  156: truly random functions f1 , f2 , f3 . Intuitively, since F is a secure PRF, the adversary A0 should not
Page  156: upon receiving the ith query (ui , vi ) 2 X 2 (for i = 1, . . . , Q) do:
Page  157: rather, to set us up so as to be able to make (and easily analyze) a more substantive modification
Page  157: upon receiving the ith query (ui , vi ) 2 X 2 (for i = 1, . . . , Q) do:
Page  157: Since the challenger in Game 2 completely equivalent to that of Game 1, we have
Page  157: upon receiving the ith query (ui , vi ) 2 X 2 (for i = 1, . . . , Q) do:
Page  159: As another consequence of Claim 1, we observe that Game 3 is equivalent to Experiment 1 of
Page  159: It turns out that given a suitable, secure PRG, one can construct a secure PRF with a technique
Page  160: The root is shaded to indicate it is assigned a random label. All other nodes are assigned derived
Page  160: We shall call the PRF F derived from G in this way the tree construction.
Page  160: • the label of any other node is derived from the label t of its parent as follows: if the node is
Page  161: labels, while the unshaded nodes are assigned derived labels. The highlighted paths correspond to
Page  161: Hybrid 0, . . . , Hybrid `. Each of these games is played between a given PRF adversary, attacking
Page  161: • the nodes at levels j + 1 through ` are assigned derived labels.
Page  161: Clearly, Hybrid 0 is equivalent to Experiment 0 of Attack Game 4.2, while Hybrid ` is equivalent
Page  161: to Experiment 1. Intuitively, under the assumption that G is a secure PRG, the adversary should
Page  161: first, third, and fourth nodes at level 2 for the given inputs). The PRG adversary we construct
Page  161: will use a variation of the faithful gnome idea to e↵ectively maintain the relevant random labels at
Page  162: upon receiving a query x = (a1 , . . . , a` ) 2 {0, 1}` from A do:
Page  162: Intuitively, for u 2 {0, 1}j , f (u) represents the random label at the node at level j addressed by
Page  162: are assigned derived labels. Note that in our description of this game, we do not explicitly assign
Page  162: For j = 0, . . . , `, let pj be the probability that A outputs 1 in Hybrid j. As Hybrid 0 is equivalent
Page  162: to Experiment 0 of Attack Game 4.2, and Hybrid ` is equivalent to Experiment 1, we have:
Page  162: We first give an overview of how B 0 works. In playing Attack Game 3.1 with respect to G0 , the
Page  162: Now the details. We implement our lookup table as an associative array Map : {0, 1}⇤ ! Z>0 .
Page  162: upon receiving ~r as in (4.32) from its challenger, B 0 plays the role of challenger to A, as
Page  163: initialize an empty associative array Map : {0, 1}⇤ ! Z>0
Page  163: upon receiving a query x = (a1 , . . . , a` ) 2 {0, 1}` from A do:
Page  163: the one hand, when B 0 is in Experiment 1 of its attack game, it e↵ectively assigns random labels
Page  163: when B 0 is in Experiment 0 of its attack game, it e↵ectively assigns pseudo-random labels to nodes
Page  163: and assigning derived labels at level j; again, the lookup table ensures a consistent labeling.
Page  164: Unfortunately, F̃ is not a secure PRF. The reason is that there is a trivial extension attack.
Page  164: string w. Then given u and v, along with y := F̃ (s, u), we can easily compute F (s, v) as G⇤ (y, w).
Page  164: Of course, for a truly random function, we could not predict its value at v, given its value at u,
Page  164: Theorem 4.11. If G is a secure PRG, then the variable length tree construction F̃ derived from
Page  164: by s, and the labels on all other nodes are assigned derived labels. The only di↵erence now is that
Page  164: at levels 0 through j are assigned random labels, and nodes at other levels are assigned derived
Page  165: upon receiving a query x = (a1 , . . . , an ) 2 {0, 1}` from A do:
Page  165: upon receiving ~r as in (4.32) from its challenger, B 0 plays the role of challenger to A, as
Page  165: initialize an empty associative array Map : {0, 1}⇤ ! Z>0
Page  165: upon receiving a query x = (a1 , . . . , an ) 2 {0, 1}` from A do:
Page  165: are consistent (the same node does not receive two di↵erent labels at di↵erent times). Now, on the
Page  165: one hand, when B 0 is in Experiment 1 of its attack game, it e↵ectively assigns random labels to
Page  165: hand, when B 0 is in Experiment 0 of its attack game, it e↵ectively assigns pseudo-random labels to
Page  166: random permutation on X , and the ⇧k ’s collectively are mutually independent. These random
Page  166: argument for a given construction. We stress the heuristic nature of the ideal cipher model: while
Page  166: modified so that E is e↵ectively replaced by a family of random permutations {⇧k }k 2K , as described
Page  167: 4.7.2    Exhaustive search in the ideal cipher model
Page  167: this k is equal to the secret key k used to generate the given pairs. This exhaustive search
Page  167: Exhaustive search is the simplest example of a key-recovery attack. Since we will present a
Page  167: Attack Game 4.4 (key-recovery). For a given block cipher E = (E, D), defined over (K, X ),
Page  167: and for a given adversary A, define the following game:
Page  167: message xi 2 M. The challenger, given xi , computes yi R E(k, xi ), and gives yi
Page  168: Exhaustive search. The following theorem bounds the number of input/output pairs needed
Page  168: for exhaustive search, assuming the cipher is an ideal cipher. For real-world parameters, taking
Page  168: that there is more than one key consistent with the given (xi , yi ) pairs is at most ✏. We shall show
Page  170: Applying EX to the DES block cipher gives an efficient method to immunize DES against
Page  170: exhaustive search attacks. With P1 = P2 we obtain a block cipher called DESX whose key size
Page  170: is 56 + 64 = 120 bits: enough to resist exhaustive search. Theorem 4.14 shows that attacks in the
Page  171: attacks like di↵erential and linear cryptanalysis still apply to DESX whereas they are ine↵ective
Page  171: the block cipher derived from E as in construction (4.37), where P1 and P2 are each uniformly
Page  171: an ideal cipher gives BCic adv[A, E]  Qic /|K| for all A. Hence, Theorem 4.14 shows that, in the
Page  171: Assuming there are no such interactions, we can e↵ectively realize all of the standard queries
Page  171: Before giving a rigorous proof of Theorem 4.14, we present a technical lemma, called the Do-
Page  172: To motivate the lemma, consider the following two experiments. In the one experiment, called
Page  172: U ! V be a function. For a given adversary A, we define two experiments, Experiment 0 and
Page  173: Before proving the Domain Separation Lemma, it is perhaps more instructive to see how it is
Page  174: independent of the random permutations used in processing ideal cipher queries. E↵ectively, each
Page  175: Finally, observe that Game 1 is equivalent to Experiment 1 of the block cipher attack game in
Page  175: Game 0. This game will be equivalent to the coalesced experiment in Attack Game 4.5, but
Page  176: This game is clearly equivalent to the coalesced experiment in Attack Game 4.5. Let W0 be the
Page  176: Game 1. Now we modify this game to get an equivalent game, but it will facilitate the application
Page  176: f (µ) = f (µ0 ). This is an equivalence relation on U , and we write [µ] for the equivalence class
Page  176: It is not hard to see that the challenger’s behavior in this game is equivalent to that in Game 0,
Page  177: It is clear that this game is equivalent to the split experiment in Attack Game 4.5, and so
Page  177: In this section we describe an important application for PRFs called sub-key derivation. Alice
Page  177: and Alice would rather not do that. Similarly, Bob values his privacy and does not want to tell
Page  177: Think of dividing the surface of the earth into p squares and the numbers a and b indicate what
Page  177: Alice or Bob, that is, it does not reveal private data that Alice or Bob send to it. Clearly, Alice
Page  177: Moreover, Alice and Bob each have a private channel to Sam. The protocol for comparing a and b
Page  178: k0 and k1 , respectively. Therefore, Sam learns nothing. Notice that the only privacy assumption
Page  178: Sub-key derivation. What if Alice wants to repeatedly test proximity to Bob? The solution
Page  178: deriving instance-specific sub-keys using a secure PRF.
Page  178: sends his encrypted location (r, xb ) to Sam he increments cnt b and derives sub-keys (k0 , k1 ) from
Page  179: Because F is a secure PRF, the sequence of derived sub-keys is indistinguishable from random
Page  180: 4.3 (Format preserving encryption). Suppose we are given a block cipher (E, D) operating
Page  180: 4.6 (adaptive vs non-adaptive security). This exercise develops an argument that shows that
Page  180: a PRF may be secure against every adversary that makes its queries non-adaptively, (i.e., all at
Page  180: once) but is insecure against adaptive adversaries (i.e., the kind allowed in Attack Game 4.2).
Page  180: To be a bit more precise, we define the non-adaptive version of Attack Game 4.2 as follows. The ad-
Page  180: while in Experiment 1, f R Funs[X , Y]. Security against non-adaptive adversaries means that all
Page  181: (a) Show that F̃ is not a secure PRF against adaptive adversaries.
Page  181: (b) Show that F̃ is a secure PRF against non-adaptive adversaries.
Page  181: (c) Show that a similar construction is possible for block ciphers: given a secure block cipher
Page  181: cipher (Ẽ, D̃) that is secure against non-adaptive adversaries, but insecure against adaptive
Page  181: 4.7 (PRF security definition). This exercise develops an alternative characterization of PRF
Page  184: after only three levels of the tree, so that there are only eight leaves, as in Fig. 4.15. Give a direct
Page  184: proof, using a sequence of seven hybrids, that outputting the values at all eight leaves gives a secure
Page  184: 4.18 (Augmented tree construction). Suppose we are given a PRG G defined over (K ⇥ S, S 2 ).
Page  184: (a) Given an example secure PRG G for which G⇤ is insecure as a PRF.
Page  186: 4.24 (Alternative proof of Theorem 4.6). Let X and Y be random variables as defined in
Page  187: an adversary is given n black boxes (where n                1 is poly-bounded): the boxes either contain
Page  187: space is Y. Given a key k 0 = (k1 , . . . , kn ), and an input x0 = (s, x), with s 2 {1, . . . , n} and x 2 X ,
Page  187: 4.27 (Universal attacker on PRFs). Let F be a PRF defined over (K, X , Y) where |K| < |X |.
Page  187: Alice is given one share and Bob the other share, then both Alice and Bob are needed to evaluate
Page  187: distributively, that is, without re-constituting the key (k1 , k2 ): to evaluate the PRF at a point x0 ,
Page  187: adversary is given k1 . Argue that the same holds for k2 .
Page  187: can be used evaluate the PRF distributively, but no single share is sufficient to evaluate the
Page  187: a secure PRF when the adversary is given a single share, namely si for some i 2 {1, 2, 3}.
Page  187: (c) Generalize the construction from part (b) to construct a PRF F 000 supporting three-out-of-five
Page  187: sharing of the key: any three shares can be used to evaluate the PRF distributively, but no
Page  188: One possible approach is for Alice to encrypt each individual file using a di↵erent key. This
Page  188: know some bits of a given file? Well, certain files, like email messages, contain standard header
Page  188: information (see Example 2.6), and so if the adversary knows that a given ciphertext is an encryption
Page  189: a chosen plaintext attack, because the adversary forces Alice to give him the encryption of one or
Page  189: While the above discussion motivated the topics in this chapter using the example of the “file
Page  189: encryption” problem, one can also motivate these topics by considering the “secure network com-
Page  190: Attack Game 5.1 (multi-key semantic security). For a given cipher E = (E, D), defined over
Page  190: (K, M, C), and for a given adversary A, we define two experiments, Experiment 0 and Experiment 1.
Page  190: We stress that in the above attack game, the adversary’s queries are adaptively chosen, in the
Page  191: Intuitively, since the key k1 is only used to encrypt the first message, and E is semantically secure,
Page  192: e↵ectively learn nothing about Alice’s files (except possibly some information about their lengths).
Page  192: Notice that this holds even if the adversary plays an active role in determining the contents of some
Page  192: Attack Game 5.2 (CPA security). For a given cipher E = (E, D), defined over (K, M, C), and
Page  192: for a given adversary A, we define two experiments, Experiment 0 and Experiment 1. For b = 0, 1,
Page  193: key is chosen for each encryption. In particular, the adversary’s queries may be adaptively chosen
Page  193: e↵ectively learn nothing about Alice’s files (except possibly some information about their lengths).
Page  193: Again, notice that this holds even if the adversary plays an active role in determining the contents
Page  194: input x for F is chosen, and a key k for E is derived by computing k               F (k 0 , x). Then m is
Page  194: include x as part of c0 so that we can decrypt: the decryption algorithm first derives the key k by
Page  195: Proof idea. First, using the assumption that F is a PRF, we can e↵ectively replace F by a truly
Page  195: between A and a di↵erent challenger; moreover, as we shall see, Game 3 is equivalent to the bit-
Page  195: Game 0. Let us begin by giving a detailed description of the challenger in Game 0 that is convenient
Page  196: upon receiving the ith query (mi0 , mi1 ) 2 M2 :
Page  196: upon receiving the ith query (mi0 , mi1 ) 2 M2 :
Page  197: upon receiving the ith query (mi0 , mi1 ) 2 M2 :
Page  198: upon receiving the ith query (mi0 , mi1 ) 2 M2 :
Page  198: Playing the role of challenger to A, upon receiving the ith query (mi0 , mi1 ) from A,
Page  200: to F to derive a key stream, we use a random starting point, which we then increment to obtain
Page  200: successive inputs to F . The x component of the ciphertext is typically called an initial value, or
Page  200: IV for short.
Page  202: E. First, using the assumption that F is a PRF, we can e↵ectively replace F by a truly random
Page  202: function f . Second, using the assumption that N is super-poly, and the fact that each IV is chosen
Page  202: at the same point twice. But in this case, the challenger is e↵ectively encrypting each message
Page  202: upon receiving the ith query (mi0 , mi1 ), with vi := |mi0 | = |mi1 |:
Page  204: Recall that AES uses a 128 bit block. Rather than picking a random 128-bit IV for every message,
Page  204: RFC 3686 picks the IV as follows:
Page  205: This resulting 128-bit IV is used as the initial value of the counter. When encrypting a message,
Page  205: With this choice of IV the decryptor knows the 32 most significant bits of the IV as well as
Page  205: the 32 least significant bits. Hence, only 64 bits of the IV need to be sent with the ciphertext.
Page  205: The proof of Theorem 5.3 can be adapted to show that this method of choosing IVs is secure.
Page  205: The slight advantage of this method over picking a random 128-bit IV is that the resulting ciphertext
Page  205: is a little shorter. A random IV forces the encryptor to include all 128 bits in the ciphertext. With
Page  205: Here, the first component c[0] of the ciphertext is also called an initial value, or IV. Note that
Page  207: upon receiving the ith query (mi0 , mi1 ), with vi := |mi0 | = |mi1 |:
Page  208: upon receiving the ith query (mi0 , mi1 ), with vi := |mi0 | = |mi1 |:
Page  208: upon receiving the ith query (mi0 , mi1 ), with vi := |mi0 | = |mi1 |:
Page  209: upon receiving the ith query (mi0 , mi1 ), with vi := |mi0 | = |mi1 |:
Page  210: from a secure block cipher gives a CPA secure cipher for messages of arbitrary length.
Page  211: One can immediately see that counter mode has a quantitative security advantage. To make
Page  211: messages. Once Q messages are encrypted with a given key, a fresh key must be generated and
Page  211: • Parallelism and pipelining. Encryption and decryption for counter mode is trivial to paral-
Page  211: naturally when encrypting individual key strokes as in SSH). A counter mode ciphertext need
Page  211: only be one block plus one byte: one block for the random IV plus one byte for the encrypted
Page  211: Remark 5.4. Both randomized counter mode and CBC require a random IV. Some crypto libraries
Page  211: actually leave it to the higher-level application to supply the IV. This can lead to problems if the
Page  211: higher-level applications do not take pains to ensure the IVs are sufficiently random. For example,
Page  211: for counter mode, it is necessary that the IVs are sufficiently spread out, so that the corresponding
Page  212: more is required: it is essential that IVs be unpredictable — see Exercise 5.12.
Page  212: Leaving it to the higher-level application to supply the IV is actually an example of nonce-based
Page  212: essentially same form (x, c); similarly, the CBC mode construction in Section 5.4.3 includes the IV
Page  213: Intuitively, a nonce-based encryption scheme is CPA secure if it does not leak any useful in-
Page  213: Attack Game 5.3 (nonce-based CPA security). For a given cipher E = (E, D), defined
Page  213: over (K, M, C, N ), and for a given adversary A, we define two experiments, Experiment 0 and
Page  214: Fortunately, the fix is easy. Let us assume that ` divides N (in practice, both ` and N will be
Page  215: based encryption scheme. As a first attempt, one might simply try to view the IV c[0] as a nonce.
Page  215: Again, the fix is fairly straightforward. The idea is to map nonces to pseudo-random IV’s by
Page  215: decryption algorithms, the IV is computed from the nonce N and key k 0 as c[0] := F (k 0 , N ).
Page  216: is given a device key kd 2 K, and it embeds this key in every device that it sells. If there are a
Page  216: to the root. This way, every device is given exactly log2 n keys in K.
Page  217: Fig. 5.6 gives an example of a cover of the set of leaves {1, 2, 4, 5, 6}. The figure captures a
Page  218: suggests an efficient recursive algorithm to compute an optimal cover.
Page  218: Proof. We prove the theorem by induction on log2 n. For n = 1 the theorem is trivial. Now, assume
Page  219: 5.3 (An alternate definition of CPA security). This exercise develops an alternative char-
Page  220: (b) Using part (a) and Remark 5.2, give a short proof that randomized counter mode is CPA
Page  221: (d) Give an example of a CPA secure cipher that is not pseudo-random multi-ciphertext secure.
Page  221: 5.8 (Deterministic CPA and SIV). We have seen that any cipher that is CPA secure must
Page  221: encryption then r is the random IV used by algorithm E). Let F be a secure PRF defined over
Page  222: Show that E 0 is deterministic CPA secure. This construction is known as the Synthetic IV (or
Page  222: SIV) construction.
Page  222: 5.12 (Predictable IVs). Let us see why in CBC mode an unpredictable IV is necessary for CPA
Page  222: security. Suppose a defective implementation of CBC encrypts a sequence of messages by always
Page  222: using the last ciphertext block of the ith message as the IV for the (i + 1)-st message. The TLS 1.0
Page  223: as follows. Given a key k 2 K and a message (m1 , . . . , m` ) 2 X ` , the encryption algorithm E
Page  223: output ciphertext contains only the shaded parts of C1 , C2 , C3 , C4 . Note that, ignoring the IV, the
Page  224: given the information given.
Page  224: m      D(ki , c) for some 1  i  n, and correctly decrypts the given c whenever i is in the set S.
Page  226: In this chapter we turn our attention to active adversaries. We start with the basic question
Page  226: of message integrity: Bob receives a message m from Alice and wants to convince himself that the
Page  226: secrecy is not. We give two examples.
Page  226: Example 6.1. Consider the problem of delivering financial news or stock quotes over the Internet.
Page  226: paths from the sender to the receiver so that an attacker cannot block all paths. We will not discuss
Page  227: we will assume that both sender and receiver will share the secret key; later in the book, this
Page  228: sender and receiver. For historical reasons such systems are called Message Authentication Codes
Page  228: MAC system is that it has unique tags: for a given key k, and a given message m, there is a
Page  228: some have a randomized signing algorithm, so that for a given key k and message m, the output of
Page  228: conservative security definitions will imply security for all these systems.
Page  228: We first intuitively explain the definition and then motivate why this conservative definition
Page  229: attack, enables the attacker to collect millions of valid message-tag pairs. Clearly we are giving
Page  229: attack cannot create an existential forgery. This definition gives the adversary more power than it
Page  229: see, this conservative definition is very natural and enables us to use MACs for lots of di↵erent
Page  229: Attack Game 6.1 (MAC security). For a given MAC system I = (S, V ), defined over
Page  229: (K, M, T ), and a given adversary A, the attack game runs as follows:
Page  229: a message mi 2 M. Given mi , the challenger computes a tag ti R S(k, mi ), and
Page  229: then gives ti to A.
Page  230: in this case just means that S is unpredictable, in the sense described in Section 4.1.1; that is, given
Page  230: There may be many valid tags for a given message. Let m be some message and suppose the
Page  230: Definition 6.2 ensures this. To see why, suppose an adversary A can forge the tag for m2 given the
Page  230: message m1 gives no useful information for producing a tag for another message m2 , even when m2
Page  230: Example 6.4. Our definition of secure MACs gives the adversary the ability to obtain the tag for
Page  230: arbitrary messages. This may seem like giving the adversary too much power. In practice, however,
Page  231: Remark 6.1. Just as we did for other security primitives, one can generalize the notion of a secure
Page  231: As usual, we give a more mathematically precise definition of a MAC, using the terminology defined
Page  231: given to both the adversary and the challenger. The advantage MACadv[A, I] is then a function
Page  231: given message-tag pair is valid. In fact, the adversary cannot even tell if it wins the game, since only
Page  231: capable of mounting a chosen message attack can probably also test whether a given message-tag
Page  232: Consequently, it makes sense to extend Attack Game 6.1 by giving the adversary the extra
Page  232: Attack Game 6.2 (MAC security with verification queries). For a given MAC system
Page  232: I = (S, V ), defined over (K, M, T ), and a given adversary A, the attack game runs as follows:
Page  232: mi 2 M. The challenger computes a tag ti R S(k, mi ), and gives ti to A.
Page  232: The two definitions are equivalent. Attack Game 6.2 is essentially the same as the original
Page  233: upon receiving a signing query mi 2 M from A do:
Page  233: upon receiving a verification query (m̂j , t̂j ) 2 M ⇥ T from A do:
Page  233: upon receiving a signing query mi 2 M from A do:
Page  233: upon receiving a verification query (m̂j , t̂j ) 2 M ⇥ T from A do:
Page  234: In summary, we showed that Attack Game 6.2, which gives the adversary more power, is
Page  234: equivalent to Attack Game 6.1 used in defining secure MACs. The reduction introduces a factor of
Page  234: the analogs of Attack Game 6.1 and Attack Game 6.2 are not equivalent (see Exercise 6.7).
Page  234: system I = (S, V ) derived from F as:
Page  235: deterministic MAC system I derived from F is a secure MAC.
Page  235: Proof idea. Let A be an efficient MAC adversary. We derive an upper bound on MACadv[A, I]
Page  235: upon receiving the ith signing query mi 2 M (for i = 1, 2, . . .) do:
Page  235: function f in Funs[X , Y]. Intuitively, since F is a secure PRF, the adversary A should not notice
Page  236: integrity for very short messages. For example, viewing AES as a PRF gives a MAC for 128-bit
Page  236: given a secure PRF on short inputs construct a secure PRF on long inputs.
Page  236: given a secure PRF that operates on single-block (e.g., 128-bit) inputs, we construct a prefix-
Page  237: FCBC does not output any intermediate values along the CBC chain. Second, FCBC uses a fixed IV,
Page  237: namely 0n , where as CBC mode encryption uses a random IV per message.
Page  239: probability that p0 a0 = p a, which is equivalent to
Page  240: surprising about this adversary B: it is essentially the universal PRF attacker from Exercise 4.27.
Page  241: An advantage of cascade is that there is no additive error term in Theorem 6.4. Consequently,
Page  241: We show that the MACs derived from CBC and cascade are insecure. This will imply that CBC
Page  241: Extension attack on cascade.       Given F ⇤ (k, m) for some message m in X ` , anyone can compute
Page  241: The extension property immediately implies that the MAC derived from F ⇤ is terribly insecure.
Page  241: An attack on CBC. We describe a simple MAC forger on the MAC derived from CBC. The
Page  242: Hence, (a1 , a2 ), t is an existential forgery for the MAC derived from CBC. Consequently, FCBC
Page  242: We show how to convert the prefix-free secure PRFs FCBC and F ⇤ into secure PRFs, which will give
Page  245: The argument given after Theorem 6.5 shows that there is an attacker that after Q ⇡ |X |
Page  246: function pf : M ! X ` is a prefix-free encoding if pf is injective (i.e., one-to-one) and the
Page  246: encoding. Define the derived PRF F as
Page  246: Then F is defined over (K, M, Y). We obtain the following trivial theorem.
Page  246: We argue that pf is a prefix-free encoding. Clearly pf is injective. To see that the image of
Page  247: Clearly pf is injective. To see that the image of pf is a prefix-free set let pf (x) and pf (y) be two
Page  247: vice versa). The function rpf (k, ·) need not even be injective.
Page  248: be a randomized prefix-free encoding. Define the derived PRF F as
Page  248: Proof idea. If the adversary’s set of inputs to F give rise to a prefix-free set of inputs to PF , then
Page  248: upon receiving a signing query mi 2 M (for i = 1, 2, . . .) do:
Page  249: upon receiving a signing query mi 2 M (for i = 1, 2, . . .) do:
Page  250: length. That is, given a PRF for messages in X ` we construct a PRF for messages in {0, 1}n` .
Page  250: Let F be a PRF taking inputs in X `+1 . Let inj : {0, 1}n` ! X `+1 be an injective (i.e.,
Page  250: one-to-one) function. Define the derived PRF Fbit as
Page  250: Then we obtain the following trivial theorem.
Page  250: An injective function. For X := {0, 1}n , a standard example of an injective inj from {0, 1}n`
Page  250: 100 . . . 00 to pad the message so its length is the next multiple of n. If the given message length
Page  251: Figure 6.7: An injective function inj : {0, 1}n` ! X `+1
Page  251: To see that inj is injective we show that it is invertible. Given y    inj (m) scan y from right to
Page  251: A common mistake is to pad the given message to a multiple of a block size using an all-0 pad.
Page  251: This pad is not injective and results in an insecure MAC: for any message m whose length is not
Page  251: Injective functions must expand. When we feed an n-bit single block message into inj , the
Page  251: It is natural to look for injective functions from {0, 1}n` to X ` that never add dummy blocks.
Page  251: X ` . Hence, all injective functions must occasionally add a “dummy” block to the output.
Page  251: CMAC avoids adding dummy blocks by using a randomized injective function.
Page  251: has no e↵ect on its security as a PRF. Truncation, however, a↵ects the derived MAC. Theorem 6.2
Page  252: (a) when length(m) is a positive multiple of n                       (b) otherwise
Page  252: generation algorithm is used to derive three keys k0 , k1 , k2 from the MAC key k. Then the three
Page  252: the PRF F . The CMAC signing algorithm is given in Table 6.1 and is illustrated in Fig. 6.8. The
Page  253: Break m into consecutive n-bit blocks so that
Page  253: if |m| is not a positive multiple of n then
Page  253: if |m| is a positive multiple of n
Page  253: positive multiple of n and a message that has been padded to make it a positive multiple of n. This
Page  254: mysterious, but in e↵ect, they simply multiply L by x and by x2 (respectively) in the finite field
Page  254: Clearly the keys k0 , k1 , and k2 are not independent. If they were, or if they were derived as,
Page  255: PMAC0 is a secure PRF and hence gives a secure MAC for large messages. The proof will
Page  256: • PMAC derives the key k as k            F (k1 , 0n ) and sets k2   k1 . Hence PMAC uses a shorter
Page  256: t0 := PMAC0 (k, m0 ) for m0 can be easily derived from the tag t := PMAC0 (k, m) for m as follows:
Page  256: Hence, given the tag on some long message m (as well as the MAC secret key) it is easy to derive
Page  257: let I be the MAC system derived from F , as discussed in Section 6.3. Let A be an adversary
Page  257: This bound is not the best possible. Give a direct analysis that shows that there exists a (Qs + Qv )-
Page  258: (a) In the most trivial solution, Alice shares a MAC key ki with each user Ui . When she broadcasts
Page  259: relative to these weak security notions. In this exercise, you are to show this by giving an explicit
Page  259: to define a CBC-MAC with a randomized IV. This is a MAC with a probabilistic signing algorithm
Page  259: that on input k 2 K and (x1 , . . . , xv ) 2 X ` , works as follows: choose IV 2 X at random; output
Page  259: (IV , t), where t := FCBC (x1 IV , x2 , . . . , xv ). On input (k, (x1 , . . . , xv ), (IV , t)), the verification
Page  259: algorithms tests if t = FCBC (x1 IV , x2 , . . . , xv ). Show that this MAC is completely insecure, and
Page  259: 6.10 (Truncated CBC). Prove that truncating the output of CBC gives a secure PRF for variable
Page  260: hold for the cascade construction, by giving an explicit counter-example. For your counter-example,
Page  260: counter-example, that PRF was constructed precisely to make cascade fail — intuitively, for “typ-
Page  260: 6.13 (Non-adaptive attacks on CBC and cascade). This exercise examines whether variable
Page  260: length CBC and cascade are secure PRFs against non-adaptive adversaries, i.e., adversaries that
Page  260: (a) Show that CBC is a secure PRF against non-adaptive adversaries, assuming the underlying
Page  260: (b) Give a non-adaptive attack that breaks the security of cascade as a PRF, regardless of the
Page  260: block gives a randomized prefix-free encoding. That is, the following function
Page  262: Message integrity from universal
Page  262: 7.1    Universal hash functions (UHFs)
Page  263: Hash functions that satisfy this very weak collision resistance property are called universal
Page  263: hash functions, or UHFs. Universal hash functions are used in various branches of computer
Page  263: cryptography. Before we can analyze the security of the hash-then-PRF paradigm, we first give a
Page  263: more formal definition of UHFs. As usual, to make this intuitive notion more precise, we define an
Page  263: Attack Game 7.1 (universal hash function). For a keyed hash function H defined over
Page  263: (K, M, T ), and a given adversary A, the attack game runs as follows.
Page  264: • We say that H is an ✏-bounded universal hash function, or ✏-UHF, if UHFadv[A, H]  ✏
Page  264: If H is a keyed hash function defined over (K, M, T ), an alternative characterization of the
Page  264: given adversary A, the attack game runs as follows.
Page  265: As usual, we give a more mathematically precise definition of a UHF using the terminology defined
Page  265: in defining ✏-UHFs for individual hash functions with no security or system parameters; in our
Page  265: The challenge in constructing good universal hash functions (UHFs) is to construct a function that
Page  265: depend on the length of the message being hashed. We give three constructions. The first is an
Page  268: We first give some intuition as to how B works. B starts by running the UHF adversary A to
Page  269: direct proof of this fact gives a better security bound.
Page  270: Setting Q := 2 in (7.10)–(7.11) gives the error bounds on FCBC and F ⇤ as UHFs.
Page  272: In Exercise 7.27 we generalize Theorem 7.6 to derive bounds for F           as a multi-query UHF.
Page  273: We derive an upper bound on PRFadv[A, F 0 ]. That is, we bound A’s ability to distinguish F 0 from
Page  274: upon receiving the ith query mi 2 M (for i = 1, 2, . . .) do:
Page  274: upon receiving the ith query mi 2 M (for i = 1, 2, . . .) do:
Page  275: begin by showing that ECBC and NMAC can be described this way and give more examples in the
Page  275: NMAC theorems (Theorems 6.6 and 6.7) are obtained by plugging (7.10) and (7.11), respectively,
Page  277: keys in KH ⇥ KF . The Carter-Wegman MAC derived from F and H works as follows (see
Page  278: which we call the encrypted UHF MAC system derived from E and H.
Page  278: H to satisfy a stronger property than universality (UHF). We refer to this stronger property as
Page  278: (K, M, T ), where T = ZN , and a given adversary A, the attack game runs as follows.
Page  279: When H is a keyed hash function defined over (K, M, T ), an alternative characterization of the
Page  279: We give a simple example of a statistical DUF that is very similar to the hash function Hpoly
Page  280: Carter-Wegman MAC ICW derived from F and H is a secure MAC.
Page  280: ICW . We derive an upper bound on MACadv[A, ICW ]. As usual, we first replace the underlying
Page  281: Proof. We make the intuitive argument above rigorous by considering A’s behavior in three closely
Page  281: upon receiving the ith signing query mi 2 M (for i = 1, . . . , s) do:
Page  281: upon receiving a forgery attempt (m, (r, v)) 2
Page  281: upon receiving the ith signing query mi 2 M (for i = 1, . . . , s) do:
Page  281: upon receiving a forgery attempt (m, (r, v)) 2
Page  283: have to be broken up into blocks of size less than n. Alternatively, we can use a variant of Hxpoly
Page  283: randomizers is that they are distinct. This motivates the study of nonce-based MACs, which are
Page  283: generated by S are always accepted by V , as long as both are given the same nonce. The MAC
Page  283: using a simple counter. Alternatively, nonces can be chosen at random, so long as the nonce space
Page  283: Attack Game 7.4 (nonce-based MAC security). For a given nonce-based MAC system I =
Page  283: (S, V ), defined over (K, M, T , N ), and a given adversary A, the attack game runs as follows:
Page  284: challenger computes ti R S(k, mi , N i ), and gives ti to A.
Page  284: In Chapter 2 we saw that the one-time pad gives unconditional security as long as the key is only
Page  285: Let H be a keyed hash function defined over (K, M, T ). Intuitively, H is a pairwise unpre-
Page  285: dictable function if the following holds for a randomly chosen key k 2 K: given the value
Page  285: (K, M, T ), and a given adversary A, the attack game runs as follows.
Page  285: new hash function H 0 derived from H with the same input and output space as H. The key space,
Page  286: Proof. Let A attack H 0 as a PUF. In response to its query m0 , adversary A receives t0 :=
Page  286: system I = (S, V ) derived from H:
Page  286: Theorem 7.12. Let H be an ✏-PUF and let I be the MAC system derived from H. Then for all
Page  287: 7.2 (Non-adaptively secure PRFs are computational UHFs). Show that if F is a secure
Page  287: PRF against non-adaptive adversaries (see Exercise 4.6), and the size of the output space of F is
Page  287: Note: Using the result of Exercise 6.13, this gives another proof that CBC is a computational
Page  287: 7.3 (On the alternative characterization of the ✏-UHF property). Let H be a keyed hash
Page  287: have Pr[H(k, m0 ) = H(k, m1 )] > ✏, where the probability is over the random choice of k 2 K. Give
Page  288: F to derive the key k0 for H.
Page  289: Hint: Use the fact that FCBC is a prefix-free secure PRF (or, alternatively, the result of
Page  289: where ↵ is a fixed primitive element of GF(2n ). XTS uses ciphertext stealing (Exercise 5.16) to
Page  290: a nonce-based version of the Carter-Wegman MAC. In particular, in Theorem 7.10, we derived the
Page  290: application of the PRF switching lemma (see Theorem 4.4) gives us the security bound
Page  292: Note that H is certainly not a secure PRF, even if we restrict ourselves to non-adaptive or prefix-free
Page  292: adversaries: given H(k, m) for any message m, we can efficiently compute the key k.
Page  292: 7.18 (Optimal collision probability with shorter hash keys). For positive integer d, let
Page  292: (a) Let p be a prime, and let N < p be a positive integer. Consider the keyed hash function H
Page  292: (b) While the construction in part (a) gives a UHF with “optimal” collision probability, the key
Page  292: In particular, let N and ` be positive integers. Let ↵ be a number with 0 < ↵ < 1. Design a
Page  292: (b) Since multiplications can be much more expensive than additions, the following variant of the
Page  293: 7.20 (Division-free hash). This exercise develops a hash function that does not require and
Page  293: division or mod operations, which can be expensive. It can be implemented just using shifts and
Page  293: adds. For positive integer d, let Id := {0, . . . , d 1}. Let n be a positive integer and set N := 2n .
Page  293: integers, and state explicitly the modulus m, as in “an ✏-DUF modulo m”. For positive integer d,
Page  293: positive integer d, we let Id := {0, . . . , d 1}.
Page  294: 7.25 (A PMAC0 alternative). Again, for positive integer d, let Id := {0, . . . , d 1}. Let N = 2n
Page  294: construction, giving a concrete security bound.
Page  295: (b) Show that given any collision for Hpoly under key k, we can efficiently compute k. That is,
Page  295: give an efficient algorithm that takes two inputs m, m0 2 Z2p , and that outputs k̂ 2 Zp , and
Page  295: (c) For positive integer d, let Id := {0, . . . , d 1}. Let n be a positive integer and set N := 2n .
Page  297: In the previous chapter we discussed universal hash functions (UHFs) and showed how they can be
Page  297: We give a precise definition in the next section.
Page  297: To give an example of a collision resistant function we mention a US federal standard called the
Page  297: cations here and give the details later on in the chapter. Many other applications are described
Page  297: Extending cryptographic primitives. An important application for collision resistance is its
Page  297: ability to extend primitives built for short inputs to primitives for much longer inputs. We give
Page  297: a MAC construction as an example. Suppose we are given a MAC system I = (S, V ) that only
Page  297: of the MAC so that it can authenticate much longer inputs. Collision resistant hashing gives a very
Page  298: compute H(m) once and then quickly derive the n tags from this single hash. With a PRF(UHF)
Page  300: use TCR for both file integrity and for extending cryptographic primitives. The downside is that the
Page  300: Attack Game 8.1 (Collision Resistance). For a given hash function H defined over (M, T )
Page  300: cannot simply “hardwire” a fixed collision into an adversary: an e↵ective adversary must be able
Page  300: As usual, we give a more mathematically precise definition of a collision resistant hash function
Page  300: Some authors deal with this issue by have H take as input a randomly chosen key k, and giving k to the adversary
Page  301: the introduction — extending the message space of a MAC. Suppose we are given a secure MAC
Page  301: resistant. Then the derived MAC system I 0 = (S 0 , V 0 ) defined in (8.1) is a secure MAC.
Page  302: It should be intuitively clear that if A produces forgeries of the first type then A can be used to
Page  302: Upon receiving a signing query mi 2 M from A do:
Page  302: Upon receiving the final message-tag pair (m, t) from A do:
Page  303: It should be intuitively clear that the shorter the digest, the easier it is for an attacker to find
Page  305: namely, 384 and 512 bits respectively.
Page  305: function derived from h, denoted HMD and shown in Fig. 8.5, is a hash function defined over
Page  305: partition M̂ into consecutive `-bit blocks so that
Page  305: t0    IV 2 X
Page  305: • The constant IV is called the initial value and is fixed to some pre-specified value. One could
Page  305: take IV = 0n , but usually the IV is set to some complicated string. For example, SHA256
Page  306: t0 := IV        h       t1       h     t2          ts 1        h           ts := H(M )
Page  306: uses a 256-bit IV whose value in hex is
Page  306: IV := 6A09E667 BB67AE85 3C6EF372 A54FF53A 510E527F 9B05688C 1F83D9AB 5BE0CD19.
Page  306: HMD derived from h, defined over ({0, 1}L , X ), is collision resistant.
Page  307: for M 0 . The very last application of h gives the final output digest and since HMD (M ) = HMD (M 0 )
Page  307: is not necessary. Black, Rogaway, and Shrimpton [21] give several examples of compression functions
Page  308: As usual, we let t0 denote the Initial Value (IV) used in the Merkle-Damgård construction.
Page  309: • Compression functions using number theoretic primitives. These are elegant constructions
Page  309: tion gives a collision resistant hash function for arbitrary size inputs. Although this is an elegant
Page  309: collision resistant hash with a clean security proof, it is far less efficient than functions derived from
Page  309: pression function derived from E maps inputs in X ⇥ K to outputs in X . The function is
Page  310: will result in a relatively slow hash function. Instead, one uses a custom block cipher specifically
Page  310: only 264 evaluations of the function. In addition, o↵-the-shelf block ciphers use relatively short
Page  310: or many other such variants. Preneel et al. [105] give twelve di↵erent variants that can be shown
Page  311: is {⇧k }k 2K , where each ⇧k is a truly random permutation on X , and the ⇧k ’s collectively are
Page  311: Theorem 8.4 (Davies-Meyer). Let hDM be the Davies-Meyer hash function derived from a block
Page  312: For q 0  2n 1 this bound simplifies to Pr[Z]  q 0 (q 0 1)/2n . For q 0 > 2n 1 the bound holds trivially.
Page  313: and SHA512. They output larger digests (256 and 512-bit digests respectively) and therefore
Page  313: which are obtained from SHA256 and SHA512 respectively by truncating the output to 224 and
Page  313: Merkle-Damgård Initial Value (IV) in SHA256 is set to:
Page  313: IV := 6A09E667 BB67AE85 3C6EF372 A54FF53A 510E527F 9B05688C 1F83D9AB 5BE0CD19 2 {0, 1}256
Page  314: two exceptions: (1) SHA224 uses a di↵erent initialization vector IV, and (2) SHA224 truncates the
Page  314: each round the cipher uses a round key Wi 2 {0, 1}32 defined recursively during the key setup step.
Page  314: Interestingly, NIST never gave the block cipher ESHA256 an official name. The cipher was given
Page  314: Given a key k 2 {0, 1}512 the SHACAL-2 cipher appends zeros to the key to get a 512-bit key.
Page  314: It then applies ESHA256 to the given 256-bit message block. Decryption in SHACAL-2 is similar to
Page  314: MD4 and MD5. Both cryptographic hash functions were designed by Ron Rivest in 1990–1 [106,
Page  317: under an assumption that is (qualitatively, at least) weaker than collision resistance; in particular,
Page  317: extension attack: given Fpre (k, M ), one can easily compute Fpre (k, M k PB k M 0 ) for any
Page  317: h(IV, M0 ) = h(IV, M1 ), then we have Fpost (k, M0 ) = Fpost (k, M1 ). For these reasons, this
Page  317: a host of other security protocols. TLS and IPsec also use HMAC as a means for deriving session
Page  317: keys during session setup. We will give a security analysis of the two-key nest, and then discuss its
Page  318: IV           h     k10         h                          h    t
Page  318: IV             h   k20           h
Page  318: hbot and htop derived from h:
Page  318: as k10   htop (k1 , IV) and k20  htop (k2 , IV). All of the other evaluations of h in the figure will be
Page  318: The first observation is that the keys k1 and k2 are only used to derive k10 and k20 as k10 =
Page  318: htop (k1 , IV) and k20 = htop (k2 , IV). The assumption that htop is a secure PRF means that in the
Page  318: PRF attack game, we can e↵ectively replace k10 and k20 by truly random n-bit strings. The resulting
Page  319: di↵erence: the keys k1 and k2 are not independent, but rather, are derived in a somewhat ad hoc
Page  319: derive the keys k1 and k2 , which are byte strings of length B, we first make k exactly B bytes long:
Page  320: we cannot justify the claim that the derived keys k10 , k20 are indistinguishable from random. One
Page  320: It remains to justify our assumption that the PRFs hbot and htop derived from h in (8.6) are secure.
Page  320: When E is a secure block cipher, the fact that htop is a secure PRF is trivial (see Exercise 4.1
Page  320: part (c)). The fact that hbot is a secure PRF is a bit surprising — the message m given as input
Page  323: paradigm. Recently, however, an alternative paradigm has emerged, called the sponge construc-
Page  323: tion. Like Merkle-Damgård, it is a simple iterative construction built from a more primitive
Page  323: • On the negative side, it is not known how to reduce the collision resistance of the sponge
Page  323: • On the positive side, the sponge is designed to be used flexibly and securely in a variety of
Page  323: F . We saw, in particular, that the intuitive idea of simply prepending the key, defining
Page  323: A new hash standard, called SHA3, is based on the sponge construction. After giving a de-
Page  323: {0, 1}n , we need to specify two positive integers numbers r and c such that n = r + c. The number
Page  323: just needs to be injective. Just adding a string of the form 10⇤ suffices, although in SHA3 a pad of
Page  323: it takes as input a positive integer v, which specifies the number of output bits.
Page  324: directly tampered with or seen by an attacker. This is what gives the sponge its security, and is
Page  328: strings. We denote by Keccak[c] the sponge derived from Keccak with capacity c, and using the
Page  329: Merkle tree hash H, derived from h, is defined over (X n , Y). For simplicity, let’s assume that n
Page  330: Proving set membership. The remarkable thing about the Merkle tree hash is that given a
Page  330: The verifier can use the quantities provided in ⇡ to re-derive the Merkle hash of T . It does so by
Page  331: element in L, giving a total proof size of |L| log2 n elements in Y. However, many of these Merkle
Page  331: that an active creditcard is revoked. More generally, Merkle trees let us to replicate a data set T
Page  332: Now, given some x 62 T , we wish to produce a proof that x is not in T . The verifier only has
Page  332: Fig. 8.13 gives an example proof that a value x in the interval (x4 , x5 ) is not in T . The proof is
Page  332: that a revoked creditcard is active.
Page  333: ture scheme D = (H, P, V ) defined over (X n , Y), and a given adversary A, the attack game runs
Page  333: set. We leave it as an instructive exercise to state the security definition, and prove that the sorted
Page  334: 8.10     Key derivation and the random oracle model
Page  334: Intuitively, hash functions like SHA256 are designed to “thoroughly scramble” their inputs, and
Page  334: found that it was indeed possible to give a security analysis under reasonable assumptions.
Page  334: In this section, we study another problem, called key derivation. Roughly speaking, the
Page  334: we can use as the key to some cryptographic primitive, like AES. Now, the secret data may be
Page  334: useful not only for analyzing the key derivation problem, but a host of other problems as well.
Page  334: 8.10.1    The key derivation problem
Page  334: Let us look at the key derivation problem in more detail. Again, at a high level, the problem is to
Page  334: to some standard cryptographic primitive, such as AES. The solution in all cases will be to hash
Page  334: the secret to obtain the key. We begin with some motivating examples.
Page  335: N , if x is chosen at random modulo N , and an adversary is given y := x3 mod N , it is
Page  335: Let us now give a formal definition of the security property we are after.
Page  335: finite set S and let I be a function defined in S. For a given adversary A, the attack game runs as
Page  335: side information given to the adversary, and the guessing advantage is 1/|D|, regardless of the
Page  335: In the second example above, it seems very hard to give a meaningful and reliable estimate of
Page  335: Now suppose we use a hash function H : S ! T to derive the key t from s. Intuitively, we
Page  335: want t to “look random”. To formalize this intuitive notion, we use the concept of computational
Page  336: function like SHA256 to derive keys.
Page  336: Sub-key derivation. Before moving on, we consider the following, related problem: what to do
Page  336: with the key t derived from s. In some applications, we might use t directly as, say, an AES key.
Page  336: encrypted messages to Alice). So once we have derived a single key t that “for all intents and
Page  336: purposes” behaves like a random bit string, we wish to derive several sub-keys. We call this the
Page  336: sub-key derivation problem to distinguish it from the key derivation problem. For the sub-key
Page  336: derivation problem, we assume that we start with a truly random key t — it is not, but when t is
Page  336: Fortunately, for sub-key derivation, we already have all the tools we need at our disposal.
Page  336: Indeed, we can derive sub-keys from t using either a PRG or a PRF. For example, in the above
Page  336: example, if Alice and Bob have a shared key t, derived from a secret s, they can use a PRF F as
Page  336: • derive a MAC key kmac          F (t, "MAC-KEY");
Page  336: • derive an Alice-to-Bob encryption key kAB              F (t, "AB-KEY");
Page  336: • derive a Bob-to-Alice encryption key kBA           F (t, "BA-KEY").
Page  336: we can do everything we need — key derivation and sub-key derivation — using a single “o↵ the
Page  336: So once we have solved the key derivation problem, we can use well-established tools to solve
Page  336: the sub-key derivation problem. Unfortunately, the practice of using “o↵ the shelf” hash functions
Page  336: for key derivation is not very well understood or analyzed. Nevertheless, there are some useful
Page  336: applications, including key derivation. As we will see later in the text, this has become a popular
Page  337: the system. Indeed, in the real world, given a choice between two systems, S1 and S2 , where S1
Page  337: modified so that H is e↵ectively replaced by a random function O 2 Funs[M, T ], to which both the
Page  337: gives m 2 M to the challenger, who responds with t = O(m). The adversary may make any
Page  338: that uses a hash function H defined over (M, T ) as an oracle. For a given adversary A, we define
Page  339: Game 0. We write the challenger in Game 0 so that it is equivalent to Experiment 0 of Attack
Page  339: same Fpre -query twice. Also, we use an associative array Map : M ! T to build up the random
Page  339: initialize the empty associative array Map : M ! T
Page  339: Upon receiving an Fpre -query on x 2 {0, 1}L do:
Page  339: Upon receiving an O-query m 2 M do:
Page  339: It should be clear that this challenger is equivalent to that in Experiment 0 of Attack Game 8.4. In
Page  339: if it turns out the oracle has already been sampled at that input; in either case, the associative
Page  339: makes the same Fpre -query twice) that Game 1 is equivalent to Experiment 1 of Attack Game 8.4,
Page  340: Key derivation in the random oracle model. Let us now return to the key derivation problem
Page  340: (I(s), O(s)) from (I(s), t), given oracle access to O. The corresponding advantage is denoted
Page  341: Game 0. We write the challenger in Game 0 so that it is equivalent to Experiment 0 of the
Page  341: associative array Map : S ! T . Here is our challenger:
Page  341: initialize the empty associative array Map : S ! T
Page  341: Upon receiving an O-query ŝ 2 S do:
Page  341: Game 1. We delete the line marked (⇤). This game is equivalent to Experiment 1 of this dis-
Page  341: point s. So our list guessing adversary B simply takes the value I(s) that it receives from its own
Page  341: Merkle-Damgård construction has a very simple, iterative structure which exposes it to “extension
Page  341: HMAC0 is safe to use as a general purpose random oracle? We can only give heuristic evidence.
Page  342: that give rise to a generic attack that treats the underlying compression function itself as a random
Page  342: random oracle O out of a smaller primitive ⇢, where ⇢ could be a random oracle on a small domain,
Page  342: random oracle based on the ideal primitive ⇢.
Page  342: give both the challenger and adversary oracle access to the random function O, and we denote the
Page  343: S = {0, . . . , d 1} for some positive integer d. To realize this, we can use a hash function H
Page  343: We now return to the key derivation problem. Under the right circumstances, we can solve the key
Page  343: derivation problem with no heuristics and no computational assumptions whatsoever. Moreover,
Page  343: the solution is a surprising and elegant application of universal hash functions (see Section 7.1).
Page  343: with probability at most , given whatever side information I(s) is known about s. To apply the
Page  344: unbounded ones. We then hash s using a random hash key k. It is essential that s (given I(s)) and
Page  344: lemma, we must ensure that s (given I(s)) and k are truly independent. If all of these conditions
Page  344: conditions, we can model the situation where the same hash key is used to derive many keys from
Page  344: linearly with the number of derivations, which is not surprising.
Page  344: modeled as random oracles, for key derivation, rather than UHFs. Indeed, if one uses a UHF
Page  344: for key derivation, are also more forgiving.
Page  344: HKDF is a key derivation function specified in RFC 5869, and is deployed in many standards.
Page  344: called key derivation), and expand (which corresponds to what we called sub-key derivation).
Page  344: Using the intermediate key t, along with info, the expand (or sub-key derivation) stage computes
Page  345: we can use the analysis in Section 8.10.2 to show that this is a secure key derivation procedure in
Page  345: The expand stage is just a simple application of HMAC as a PRF to derive sub-keys, as we
Page  345: discussed at the end of Section 8.10.1. The info parameter may be used to “name” the derived
Page  345: the underlying hash is fixed, a simple iterative scheme is used to generate longer outputs. This stage
Page  345: • We say that H is one-way if given t := H(m) as input, for a random m 2 M, it is difficult
Page  345: • We say that H is 2nd-preimage resistant if given a random m 2 M as input, it is difficult
Page  345: m0 that collides with a given m.
Page  346: We mention some trivial relations between these notions when M is at least twice the size of T .
Page  346: be one-way. In other words, it is believed that given x2 mod N it is difficult to find x (as long as the
Page  346: factorization of N is unknown). However, this function H is trivially not 2nd-preimage resistant:
Page  346: given x 2 {1, . . . , N } as input, the value x is a second preimage since x2 mod N = ( x)2 mod N .
Page  346: domain of a MAC and for providing file integrity. To give some intuition, consider the file integrity
Page  346: detected. The malware is given F as input and must come up with a 2nd-preimage of F , namely
Page  347: Attack Game 8.5 (Target collision resistance). For a given keyed hash function H over
Page  347: Casting the definition in our formal mathematical framework is done exactly as for universal
Page  348: The input m given to B is uniformly distributed in M. Therefore, the key k given to A in
Page  348: preimage resistant function directly gives a TCR function. If we assume that the SHA256 compres-
Page  349: IV          L         h         L         h        L          L         h           t
Page  349: power of 2. We build a derived TCR hash H that hashes messages in {0, 1}`L using keys in
Page  349: ⌫(x) := largest n 2 Z>0 such that 2n divides x.
Page  349: The derived TCR hash H is similar to Merkle-Damgård. It uses the same padding block PB
Page  349: as in Merkle-Damgård and a fixed initial value IV. The derived TCR hash H is defined as follows
Page  349: Break M into consecutive `-bit blocks so that
Page  349: t0    IV
Page  349: work. Plugging h(k1 , ·) directly into Merkle-Damgård can fail to give a TCR hash.
Page  350: Security of the derived hash. The following theorem shows that the derived hash H is TCR
Page  350: for any bounded L, the derived function H is a TCR hash for messages in {0, 1}`L .
Page  350: similar to Exercise 8.8 gives a TCR hash using logarithmic size keys that is more suitable for a
Page  350: come up with a new file F 0 such that t = H(r, F 0 ). In other words, the malware is given as input
Page  350: logarithmic in the size of the files being protected. Using a recursive construction (see Exercise 8.24)
Page  351: Then the derived MAC system I 0 = (S 0 , V 0 ) defined in (8.19) is a secure MAC.
Page  352: Upon receiving the ith signing query mi 2 M from A do:
Page  352: Bh receives a random key r̂ 2 K from its challenger
Page  352: Upon receiving the final message-tag pair (m, (t, r) ) from A do:
Page  352: from BH ’s challenger, but no matter what u is, the key ri given to A is always uniformly random.
Page  354: (i) Let i be the smallest positive integer satisfying H (i) (x0 ) = H (2i) (x0 ).
Page  354: (ii) Let j be the smallest positive integer satisfying H (j) (x0 ) = H (j+i) (x0 ). Notice that j  i.
Page  354: given time.
Page  354: 8.8 (A parallel Merkle-Damgård). The Merkle-Damgård construction in Section 8.4 gives a
Page  355: be the compression function, let H be the resulting hash function, and let IV be the prescribed
Page  355: a preimage of IV under h.
Page  355: cipher as an ideal cipher, then for any fixed IV, it is hard to find a preimage of IV under h.
Page  356: The next exercise gives an application for fixed points.
Page  356: {0, 1}` ! {0, 1}n . Recall that HMD pads a given message with a padding block that encodes the
Page  356: (a) Let s ⇡ 2n/2 . You are given a message M that consists of s random `-bit blocks. Show that
Page  356: Hint: Repeatedly choose random blocks x in {0, 1}` until h(IV, x) is the same as one of
Page  357: Section 8.10.3) and Theorem 8.9. However, you are to give a direct proof of this fact.
Page  358: SPR, if no efficient adversary, given a random x in X as input, can output y, x0 , y 0 such that
Page  358: SPR hash function. If X is relatively small and Y is much larger, we obtain a TCR for long
Page  358: advantage: the adversary outputs m 2 M, is given random k 2 K, and outputs (k 0 , m0 ) such that
Page  359: Discussion: The small domain MAC (S, V ) in this construction is only given h as the
Page  359: input message, where as when using a TCR, the small domain MAC was given (r, h) as the
Page  359: secure MAC is WCR, (2) give an example of a secure WCR that is not a secure MAC.
Page  360: Discussion: Although this is a contrived example, it shakes our confidence in the random oracle
Page  361: ensure both data secrecy (confidentiality) and data integrity, even against very aggressive attackers
Page  361: that can interact maliciously with both the sender and the receiver. Such systems are said to
Page  361: combine these two primitives and not all combinations are secure. We briefly consider two examples.
Page  362: an interface for CPA-secure encryption (such as counter mode with a random IV) and a separate
Page  362: combine these two primitives to provide authenticated encryption. Every system did it di↵erently
Page  362: Attack Game 9.1 (ciphertext integrity). For a given cipher E = (E, D) defined over (K, M, C),
Page  362: and a given adversary A, the attack game runs as follows:
Page  363: message mi 2 M. The challenger computes ci R E(k, mi ), and gives ci to A.
Page  363: texts it was given, i.e.,
Page  363: attacks. In Section 9.3, we give a more high-level justification for the definition.
Page  364: implies. Consider a sender, Alice, and a receiver, Bob, who have a shared secret key k. Alice sends
Page  364: Now consider a more aggressive adversary A that attempts to make Bob receive a message that
Page  364: shows that A cannot cause Bob to receive any messages that were not sent by Alice. The more
Page  364: 9.2.1   Chosen ciphertext attacks: a motivating example
Page  364: We now consider an even more aggressive type of attack, called a chosen ciphertext attack for
Page  364: To motivate chosen ciphertext attacks suppose Alice sends an email message to Bob. For
Page  365: server. When the ciphertext c is received at the mail server it will be decrypted and the resulting
Page  365: receives ĉ it will decrypt it and (incorrectly) place the plaintext into Mel’s inbox where Mel can
Page  365: To successfully carry out this attack, Mel must first solve the following problem: given an encryp-
Page  365: c[0] and c[1] are the first and second blocks of c where c[0] is the random IV. Mel constructs ĉ as
Page  366: attack game at all meaningful, it may also seem a bit unintuitive: if the adversary can decrypt
Page  366: Attack Game 9.2 (CCA security). For a given cipher E = (E, D) defined over (K, M, C), and
Page  366: for a given adversary A, we define two experiments. For b = 0, 1, we define
Page  368: upon receiving the ith encryption query (mi0 , mi1 ) from A do:
Page  368: upon receiving the jth decryption query ĉj from A do:
Page  369: Putting equations (9.5)–(9.7) together gives us (9.4), which proves the theorem. 2
Page  369: To further motivate the definition of authenticated encryption we show that it precisely captures
Page  369: an intuitive notion of secure encryption as an abstract interface. AE-security implies that the real
Page  369: literally jump from sender to receiver, without going over the network at all (even in encrypted
Page  369: Suppose a sender S and receiver R are using some arbitrary Internet-based system (e.g, gam-
Page  369: On the receiving end, when a ciphertext ĉ is received at R’s end of the wire, it is decrypted
Page  369: delivered to R was rejected could be useful.
Page  369: ideal implementation of this interface that captures in an intuitive way the guarantees ensured by
Page  370: but does not contain any information about mi (other than its length). When ci arrives at R, the
Page  370: corresponding message mi is magically copied from S’s out-box to R’s in-box. If a ciphertext arrives
Page  370: practical purposes — equivalent to the real implementation. Therefore, a protocol designer need
Page  370: arrives on R’s end, the list of ciphertexts c1 , c2 , . . . previously generated by S is scanned, and
Page  370: • Second, we modify the implementation on R’s in-box again, so that if a ciphertext ĉ arrives
Page  372: upon receiving a query mi 2 M from Aci do:
Page  372: Recall that our definition of a secure MAC from Chapter 6 requires that given a message-tag
Page  372: IV. When implementing encrypt-then-MAC EEtM = (EEtM , DEtM ) the encryption algorithm is
Page  372: c; the IV is not protected by the MAC. This mistake completely destroys ciphertext integrity:
Page  372: given a ciphertext (r, c, t) an attacker can create a new valid ciphertext (r0 , c, t) for some r0 6= r.
Page  372: The decryption algorithm will not detect this modification of the IV and will not output reject.
Page  373: a faulty encrypt-then-MAC where the HMAC was not applied to the encryption IV [97].
Page  373: yet this combination is badly broken: an attacker can e↵ectively decrypt all traffic using a chosen
Page  374: message and then encrypt in CBC mode using key ke and a random IV. Thus, the following
Page  374: Both SSL 3.0 and TLS 1.0 use a defective variant of randomized CBC encryption, discussed in
Page  374: IV           encryption of m               encrypted tag       encrypted pad
Page  375: We leave it as an instructive exercise to recast this attack in terms of an adversary in a chosen
Page  375: Now, suppose the attacker obtains another encryption of m, call it c0 , using a di↵erent IV.
Page  375: If these four values are distinct they give the attacker four chances to learn the last byte of m[0].
Page  375: all of m. We show next that this gives a real attack on SSL 3.0.
Page  375: cause the browser to repeatedly issue the request (9.10) giving the adversary the fresh encryptions
Page  376: This gives the attacker a block of ciphertext, call it c1 [2], where the cookie is shifted one byte to the
Page  376: server’s response, gives the attacker the means to mount the desired chosen ciphertext attack. The
Page  376: A padding oracle timing attack. Despite the defenses in TLS 1.0 a naive implementation of
Page  376: applies CBC decryption to the received ciphertext; next it checks that the pad structure is valid
Page  377: Informative error messages. To make matters worse, the TLS 1.0 specification [39] states
Page  377: that the server should send one type of error message (called bad record mac) when a received
Page  377: against an adversary that makes a single chosen message query. Intuitively, the reason we can
Page  378: challenger gives to Aci a ciphertext ci = (xi , ui ), where xi is a random IV, and ui is a one-time
Page  378: pad encryption of the pair mi k ti using a pseudo-random pad ri derived from xi using the PRF
Page  378: that u decrypts to m k t using a pseudo-random pad r derived from x, and t is a valid tag on m.
Page  378: e↵ectively replace the pseudo-random ri ’s (and r) with truly random pads, without a↵ecting Aci ’s
Page  379: upon receiving the ith query mi 2 Y `m for i = 1, 2, . . . do:
Page  379: (2)     xi R X                  // Choose a random IV
Page  379: upon receiving c = (x, u) 2
Page  380: Game 2. Now we restrict the adversary’s winning condition to require that the IV used in the
Page  380: final ciphertext c is the same as one of the IVs given to Aci during the game. In particular, we
Page  380: challenger in Game 2 e↵ectively encrypts all of the tags ti generated in line (1) with a one-time
Page  380: forgery use the IV from ciphertext number ! given to Aci . Here ! is a random number in {1, . . . , Q}
Page  380: the tags are encrypted using one-time pads the adversary cannot tell that he is given encryptions
Page  381: upon receiving the ith query mi 2 {0, 1}`m for i = 1, 2, . . . do:
Page  381: xi R X               // Choose a random IV
Page  381: Given all the past mistakes in implementing these modes it is advisable that developers not
Page  382: Second, we extend the encryption algorithm by giving it an additional input message, called
Page  382: by D, as long as both are given the same nonce and associated data. That is, for all keys k, all
Page  382: If the message m given as input to the encryption algorithm is the empty message then cipher
Page  383: Attack Game 9.3 (ciphertext integrity). For a given AD cipher E = (E, D) defined over
Page  383: (K, M, D, C, N ), and a given adversary A, the attack game runs as follows:
Page  383: E(k, mi , di , N i ), and gives
Page  383: that is not among the triples it was given, i.e.,
Page  384: are given the same associated data. That is,
Page  385: respective field. If the input nonce N is not 96-bits long, then N is padded to the closest multiple
Page  386: and a nonce N . It operates as in encrypt-then-MAC: it first derives km  E(k, 0128 ) and checks the
Page  386: thing. Recall that Hxpoly (k, z) works by evaluating a polynomial derived from z at the point k. We
Page  386: the message are guaranteed to be distinct from the inputs used to derive the GHASH key and pad.
Page  387: make GCM just slightly more expensive than pure counter mode, which is the best one can hope
Page  388: This high entropy master secret is used to derive two keys kb!s and ks!b . The key kb!s encrypts
Page  388: derives the two keys by using the master secret and other randomness as a seed for a key derivation
Page  388: function called HKDF (Section 8.10.5) to derive enough pseudo-random bits for the two keys. This
Page  388: algorithm is given the following arguments:
Page  388: XORing this padded sequence number with a random string (called client write iv or
Page  388: server write iv, depending on who is encrypting) that was derived from the master secret
Page  388: equivalent and slightly easier to comprehend method: choose the initial nonce value at random
Page  388: and associated data d. This opens up the system to an exhaustive search attack for the key k
Page  389: When a record is received, the receiving party runs the AEAD decryption algorithm to decrypt c.
Page  389: show that the lengths of encrypted records can reveal considerable information about private data
Page  389: be given as input to the encryption algorithm. This does not compromise security: a secure AEAD
Page  389: delivery so that the recipient already knows what sequence number to expect without any additional
Page  389: decryption algorithm will be given the wrong nonce as input causing it to reject the ciphertext.
Page  389: particular, an active attacker can close the network connection mid-way through a session, and to
Page  390: In e↵ect, the adversary was able to make the browser receive a message that the server did not
Page  390: send: the server sent both frames, but the browser only received one and accepted it as a valid
Page  390: process headers as soon as they are received, resulting in the vulnerability above. Every application
Page  390: that uses TLS must be aware of this issue, and defend against it using an EOM or equivalent
Page  390: initial value (IV) to 0. Consequently, an attacker can tell when two SSHv1 packets contain
Page  390: the same prefix. Recall that for CPA security one must choose the IV at random.
Page  391: either ku!s or ks!u , depending on the encrypting party. SSHv2 uses a defective version of
Page  391: When an encrypted packet is received the decryption algorithm works as follows: first it decrypts
Page  392: encryption algorithm encrypts the packet length field, as shown in Fig. 9.3. The motivation for
Page  392: Hiding message boundaries between consecutive encrypted messages is outside the requirements
Page  392: to detect boundaries between consecutive encrypted records. Enhancing authenticated encryption
Page  392: received and this most likely fails causing the server to send back an error message. Thus, once `
Page  392: bytes are read the attacker receives an error message. This tells the attacker the value of ` which
Page  392: for every user keystroke. This gives rise to an interesting traffic analysis attack reported in [114].
Page  392: By measuring timing di↵erences between consecutive packets, the eavesdropper obtains timing
Page  392: information between consecutive keystrokes. This exposes information about the user’s password:
Page  393: a large timing gap between consecutive keystrokes reveals information about the keyboard position
Page  393: first message byte to SSH MSG IGNORE and are ignored by the receiver. The eavesdropper cannot
Page  393: tion (WiFi). Security is provided by a Wired Equivalent Privacy (WEP) encapsulation of 802.11b
Page  393: data frames. The design goal of WEP is to provide data privacy at the level of a wired network.
Page  393: WEP, however, completely fails on this front and gives us an excellent case study illustrating how
Page  393: sequence generated by RC4 given the seed s.
Page  393: an 802.11b frame m the sender picks a 24-bit IV and computes:
Page  393: c     m k CRC(m)        RC4(IV k k)
Page  393: cfull  (IV, c)
Page  393: The WEP encryption process is shown in Fig. 9.4. The receiver decrypts by first computing
Page  393: c RC4(IV k k) to obtain a pair (m, s). The receiver accepts the frame if s = CRC(m) and rejects
Page  393: Attack 1: IV collisions. The designers of WEP understood that a stream cipher key should
Page  393: never be reused. Consequently, they used the 24-bit IV to derive a per-frame key kf := IV k k.
Page  393: The standard, however, does not specify how to choose the IVs and many implementations do so
Page  393: poorly. We say that an IV collision occurs whenever a wireless station happens to send two frames,
Page  393: say frame number i and frame number j, encrypted using the same IV. Since IVs are sent in the
Page  393: clear, an eavesdropper can easily detect IV collisions. Moreover, once an IV collision occurs the
Page  393: So, how likely is an IV collision? By the birthday paradox, an implementation
Page  393: a random IV for each frame will cause an IV collision after only an expected 2 = 212 = 4096
Page  394: RC4( IV k k )
Page  394: IV                             encrypted frame
Page  394: Alternatively, an implementation could generate the IV using a counter. The implementation
Page  394: will exhaust the entire IV space after 224 frames are sent, which will take about a day for a wireless
Page  394: reset the counter to 0 during power-up. As a result, these cards will frequently reuse low value IVs,
Page  394: frame i to ki := F (k, IV) — the resulting keys would be indistinguishable from random, independent
Page  394: solve the IV collision problem discussed above, or the malleability problem discussed next.
Page  394: The attack uses the linearity of CRC. That is, given CRC(m) for some message m, it is easy to
Page  394: ever being detected by the receiver. Let c be a WEP ciphertext, namely
Page  394: c = m, CRC(m)          RC4(IV k k)
Page  395: c0 = RC4(IV k k)            m, CRC(m)            , L( ) =
Page  395: RC4(IV k k)         m      , CRC(m)      L( ) =
Page  395: RC4(IV k k)         m      , CRC(m           )
Page  395: Hence, c0 decrypts without errors to m      . We see that given the encryption of m, an attacker
Page  395: Virtual private networks (VPNs) are an important application for IPsec. A VPN enables two
Page  395: over the public channel. The east gateway decrypts each received packet and forwards it to its
Page  395: our motivating example for IPsec.
Page  396: Figure 9.5: A virtual private network (VPN) between east and west office branches
Page  397: the packet using the secret key specified in the SA. When the packet arrives at its destination, the
Page  397: 1. First, look for an SA matching the received (SPI, dest address, source address);
Page  397: If no SA exists for the received packet, the packet is discarded. Otherwise, the gateway decrypts the
Page  398: sending a packet with the same sequence number. Note that multiple hosts can receive packets for
Page  398: number that was previously contained in an earlier packet. Since packets can arrive out of order,
Page  398: represents the highest, validated sequence number value received on this SA. Packets that contain
Page  398: sequence numbers lower than the “left” edge of the window are discarded. Received packets falling
Page  398: within the window are checked against the list of received packets within the window, and are
Page  398: with a sequence number on the “right” of the current window is received. Consequently, the receiver
Page  398: If more than 232 consecutive packets are lost, then the 64-bit sequence numbers at the sender
Page  398: and receiver will go out of sync — the 32 MSBs implicitly maintained by the two will di↵er. As
Page  399: AES-CBC, and AES counter mode. For CBC modes the IV is prepended to the encrypted
Page  400: Security. IP packets can arrive at any order, be duplicated, and even modified. By relying on
Page  400: an unintended destination, thus causing a serious privacy breach. This and other dangers of the
Page  400: 9.12     A fun application: private information retrieval
Page  400: lowing derived ciphers:
Page  401: and let (Ecbc , Dcbc ) be the cipher derived from (E, D) using randomized CBC mode, as in Sec-
Page  401: Show that (E 0 , D0 ) is not AE-secure by giving a chosen-ciphertext attack on it. This construction
Page  401: 9.4 (Redundant message encoding does not give AE). The attack in the previous exercise
Page  401: some m, and g(m0 ) = ? if m0 is not in the image of f . Intuitively, f represents an “error detecting
Page  401: Show that (E2 , D2 ) is not AE-secure by giving a chosen-ciphertext attack on it.
Page  401: encrypted, the sender appends a parity bit to the end of the plaintext. After the receiver decrypts,
Page  402: 9.6 (Nested encryption). Let (E, D) be an AE-secure cipher. Consider the following derived
Page  402: where r is the random IV. Use RawCBC built from (E, D) as the secure MAC. This MAC is secure
Page  403: denote the encryption of message m with key k using r 2 X as the IV. Let F be a secure PRF
Page  403: Discussion: This construction is related to the authenticated SIV cipher (Exercise 9.11) and
Page  403: 9.11 (Authenticated SIV). We discuss a modification of the SIV construction, introduced in
Page  403: call this the authenticated SIV construction. With E = (E, D), F , and E 0 = (E 0 , D0 ) as in
Page  404: 9.14 (GCM analysis). Give a complete security analysis of GCM (see Section 9.7). Show that
Page  405: middlebox ensures that no sensitive information is accidentally sent out. Towards this goal let us
Page  405: that derives a sub-key k 0 from the primary key k (i.e., k 0 R K(k)), and D0 (k 0 , c) is the decryption
Page  406: when the adversary is given a sub-key k 0 R K(k), but again knows nothing about k.
Page  406: third requirement says that the receiving end-point will only decrypt authentic ciphertexts,
Page  406: (b) Give a construction that satisfies your definition from part (a). You can use an AE secure
Page  408: a passive eavesdropping adversary cannot feasibly guess their shared key. The adversary can listen
Page  408: chapter we develop the full machinery needed for key exchange in the presence of an active attacker
Page  409: and a given adversary A, the attack game runs as follows.
Page  409: transcript TP . It gives TP to A.
Page  409: Given all the tools we developed in Part 1, it is natural to ask if anonymous key exchange can
Page  410: property, which basically says that given pk and F (pk , x) for random x 2 X , it is hard to compute
Page  410: Attack Game 10.2 (One-way trapdoor function scheme). For a given trapdoor function
Page  410: scheme T = (G, F, I), defined over (X , Y), and a given adversary A, the attack game runs as
Page  410: • Upon receiving pk from Alice, Bob computes x R X , y            F (pk , x), and sends y to Alice.
Page  411: • Upon receiving y from Bob, Alice computes x           I(sk , y).
Page  411: We give a more mathematically precise definition of a trapdoor function scheme, using the termi-
Page  412: after its inventors, Rivest, Shamir, and Adleman. Recall that a trapdoor permutation is a special
Page  412: it follows that gcd(e, (p 1)(q 1)) = 1, and hence e has a multiplicative inverse modulo (p 1)(q 1).
Page  412: • For a given public key pk = (n, e), and x 2 Zn , we define F (pk , x) := xe 2 Zn .
Page  412: • For a given secret key sk = (n, d), and y 2 Zn , we define I(sk , y) := y d 2 Zn .
Page  413: Thus, xed x is divisible by the distinct primes p and q, and must therefore be divisible by their
Page  413: algorithm that given n and xe , where x 2 Zn is chosen at random, can e↵ectively compute x. It is
Page  413: Attack Game 10.3 (RSA). For given integers ` > 2 and odd e > 2, and a given adversary A,
Page  414: and gives the input (n, y) to the adversary.
Page  414: can e↵ectively solve the RSA problem.
Page  414: • Upon receiving (n, e) from Alice, Bob computes x R Zn , y       xe , and sends y to Alice.
Page  414: • Upon receiving y from Bob, Alice computes x        yd.
Page  414: We give a more mathematically precise definition of the RSA assumption, using the terminology
Page  414: Second, the specification of RSAGen requires that we generate random prime numbers of a given
Page  415: a bit of motivation and intuition.
Page  415: 2. given ↵ and E( ), it should be easy to compute F (↵, );
Page  415: 3. given E(↵) and , it should be easy to compute F (↵, );
Page  415: 4. given E(↵) and E( ), it should be hard to compute F (↵, ).
Page  415: the shared key F (↵, ) using the algorithm from Property 2 and her given data ↵ and E( ). Bob
Page  415: computes the same key F (↵, ) using the algorithm from Property 3 and his given data E(↵) and
Page  416: Suppose p is a large prime and that q is a large prime dividing p 1 (think of p as being very large
Page  416: elements of Zp . An essential fact is that since q divides p 1, Z⇤p has an element g of order q (see
Page  416: 3. Upon receiving v from Bob, Alice computes w           v↵
Page  416: 4. Upon receiving u from Alice, Bob computes w           u
Page  417: given g ↵ , g 2 G, where ↵ R Zq and         R
Page  417: concept of a group may wish to refer to Appendix A; alternatively, for the time being, the reader
Page  418: by g 2 G. For a given adversary A, define the following attack game:
Page  418: and gives the value u to the adversary.
Page  418: can e↵ectively solve the DL problem.
Page  418: for selecting groups and generators give rise to di↵erent DL assumptions (and the same applies to
Page  418: q generated by g 2 G. For a given adversary A, the attack game runs as follows.
Page  418: and gives the pair (u, v) to the adversary.
Page  419: no efficient algorithm that can e↵ectively solve the CDH problem.
Page  419: to even recognize correct solutions to the CDH problem, that is, given an instance (u, v) of the CDH
Page  419: problem, and a group element ŵ, to determine if ŵ is a solution to the given problem instance.
Page  419: This is in contrast to the RSA problem: given an instance (n, e, y) of the RSA problem, and an
Page  419: element x̂ of Z⇤n , we can efficiently test if x̂ is a solution to the given problem instance simply
Page  419: random group elements is hard. It turns out that this stronger assumption is equivalent to the
Page  419: generated by g 2 G. For a given adversary A, we define two experiments.
Page  419: and gives the triple (u, v, wb ) to the adversary.
Page  419: DH-triple. The DDH assumption says that there is no efficient algorithm that can e↵ectively
Page  420: Clearly, the DDH assumption implies the CDH assumption: if we could e↵ectively solve the
Page  420: CDH problem, then we could easily determine if a given triple (u, v, ŵ) is a DH-triple by first
Page  420: given discrete-log instance to a random discrete-log instance. Such a reduction is called a random
Page  421: must be hard on average. This implication makes such problems attractive for cryptography.
Page  421: One can also give random self reductions for both the CDH and DDH problems, as well as for
Page  421: As in previous sections, we give the mathematical details pertaining to the DL, CDH, and DDH
Page  422: q is a prime dividing p 1, and p itself is prime. Here the system parameterization algorithm P
Page  422: one can check that a given bit string properly encodes an element u of Z⇤p ; second, one can check
Page  422: by the security parameter . In that game, the adversary is given the security parameter and
Page  422: a group description ⇤ = (⇤1 , q, g), where g is a generator for the group G ,⇤ . It is also given a
Page  423: primitives
Page  423: For u 2 G, a representation (relative to g and h) of u is a pair (↵, ) 2 Z2q such that
Page  423: g h = u. For a given u 2 G, there are many representations. In fact, there are precisely q of
Page  423: The key to our hash function design is the following fact: given two di↵erent representations of
Page  423: a multiplicative inverse in Zq , which we can in fact efficiently compute (see Appendix A). Raising
Page  423: Fact 10.3 (Computing DL from two representations). Suppose we are given (↵, ) and
Page  423: (↵0 , 0 ), which are two di↵erent representations (relative to g and h) of the same group element.
Page  424: Proof. We use the given collision-finding adversary A to build a DL adversary B as follows. When
Page  424: B receives its challenge h 2 G from its DL-challenger, B runs A using Hdl , which is defined using
Page  424: G, g, and the given h. Suppose A finds a collision. This is a pair of distinct inputs (↵, ) 6= (↵0 , 0 )
Page  424: In other words, (↵, ) and (↵0 , 0 ) are distinct representations (relative to g and h) of the same
Page  425: Proof. Let A be a given adversary. Here is how B works. Adversary B receives a random element
Page  425: y 2 Zn . If y 2 Z⇤n , then B gives y to A and outputs whatever A outputs. Otherwise, B computes
Page  425: We also need the following technical result, which says that given y 2 Z⇤n , along with an integer
Page  425: f that is relatively prime to e, and an eth root of y f , we can easily compute an eth root of y itself.
Page  425: where n is a positive integer, e and f are relatively prime integers, and w and y are elements of Z⇤n
Page  426: Proof. We construct an adversary B 0 that plays the alternative RSA attack game considered in
Page  426: Our RSA adversary B 0 runs as follows. It receives (n, y) from its challenger, where n is an RSA
Page  426: apply Theorem 10.6 with n, e, and y as given, and w := a/a0 and f := b0 b. 2
Page  426: The Diffie-Hellman key exchange is secure against a passive eavesdropper. Usually, however, an
Page  426: completely falls apart in the presence of an active adversary who controls the network. The main
Page  426: the secret is shared. The same holds for Bob. An active attacker can abuse this to expose all traffic
Page  426: against active attackers.
Page  427: Can we build a secure key exchange protocol using symmetric-key primitives? The answer is yes,
Page  428: tity ` sent by Bob. Since the adversary does not know which puzzle Bob picked, intuitively, he
Page  428: the protocol, while each participant spends time O(L). This gives a quadratic gap between the
Page  430: 10.6 (An alternative DDH characterization). Let G by a cyclic group of prime order q
Page  431: and m be positive integers. Define the following two distributions over Gn+2nm :
Page  432: n  m be positive integers. Define the following two distributions over Gn·m+n+m :
Page  432: Hint: First give a proof for the case n = 1 using the results of Exercise 10.6 and Exercise 10.7,
Page  432: Discussion: This result gives us a DDH-based PRG G defined over (Zn+m            q    , Gn·m+n+m ), with a
Page  432: nice expansion rate, given by
Page  432: m be positive integers, and assume n  m. For A = (↵ij ) 2 Zn⇥mq   (i.e., A is an n ⇥ m matrix with
Page  433: Remark: This result gives us a kind of trapdoor test. Suppose a group element u 2 G is given (it
Page  433: a “trapdoor” ( , ⌧ ). Using this trapdoor, given group elements v, w, w̄ 2 G (possibly adversarially
Page  433: whether (u, v, w) and (ū, v, w̄) are individually DH-triples. This rather technical result has several
Page  434: • We say that A and B are deterministic poly-time equivalent if A is deterministic
Page  434: 10.15 (Problems equivalent to CDH). Consider a specific cyclic group G of prime order q
Page  434: generated by g 2 G. Show that the following problems are deterministic poly-time equivalent:
Page  434: (a) Given g ↵ and g , compute g ↵ (this is just the Computational Diffie-Hellman problem).
Page  434: (b) Given g ↵ , compute g (↵ ) .
Page  434: (c) Given g ↵ with ↵ 6= 0, compute g 1/↵ .
Page  434: (d) Given g ↵ and g with         6= 0, compute g ↵/ .
Page  434: advantage ✏(⇤0 ) given that ⇤ = ⇤0 , which is a probability just over the random choice of ↵ 2 Zq
Page  434: implementations. Conceivably, such a g could be a “weak” generator that makes it easier for an
Page  434: (a) the rDL and DL assumptions are equivalent;
Page  434: (b) the rCDH and CDH assumptions are equivalent;
Page  435: Give an efficient, deterministic algorithm that takes as input p, x, y as above, and computes a
Page  435: is identical to Attack Game 10.6. Give an efficient adversary that has advantage 1/2 in solving the
Page  436: that the DDH assumption is false in this group. Exercise 10.20 gives another reason to restrict
Page  436: and outputs an integer y 2 X , computed as follows. Divide x by n to obtain the integer quotient
Page  436: (a) Show that F ⇤ (pk , ·) is a permutation on X , and give an efficient inversion function I ⇤ that
Page  437: ↵ R Z⇤q , and gives
Page  437: the 2nd-preimage resistance of Hdl . That is, given (↵, ) as input, along with the trapdoor,
Page  437: can invert Hrsa . That is, given z 2 Zn as input, one can find (a, b) such that Hrsa (a, b) = z.
Page  438: In this chapter, we consider again the basic problem of encryption. As a motivating example,
Page  438: The basic idea of public-key encryption is that the receiver, Bob in this case, runs a key gener-
Page  438: She then sends c to Bob, using his email address. At some point later, Bob receives the ciphertext
Page  438: delivery protocols do not allow any interaction beyond delivery of the message.
Page  439: Public-key encryption is used in many real-world settings. We give two more examples.
Page  439: the owner of the file can selectively allow others to read the unencrypted contents of the file. This
Page  440: Attack Game 11.1 (semantic security). For a given public-key encryption scheme E =
Page  440: (G, E, D), defined over (M, C), and for a given adversary A, we define two experiments.
Page  441: We give a more mathematically precise definition of a public-key encryption scheme, using the
Page  442: 2. M has an e↵ective length function.
Page  442: receive as a common input, and that the challenger generates ⇤ and sends this to the adversary
Page  442: • A receives a public key pk from its challenger.
Page  443: However, for public-key encryption schemes, semantic security does imply CPA security. Intuitively,
Page  443: knowledge of any secret key material. The adversary does so using the given public key and never
Page  443: Attack Game 11.2 (CPA security). For a given public-key encryption scheme E = (G, E, D),
Page  443: defined over (M, C), and for a given adversary A, we define two experiments.
Page  444: Upon receiving the ith query (mi0 , mi1 ) 2 M2 from A do:
Page  445: • For a given public key pk , and a given message m 2 M, the encryption algorithm runs as
Page  445: • For a given secret key sk , and a given ciphertext (y, c) 2 Y ⇥ C, the decryption algorithm
Page  446: as a random oracle, then intuitively, the only way the adversary can learn anything at all about
Page  446: the random oracle as a “faithful gnome.” This is done using an associative array Map : X ! K.
Page  447: initialize an empty associative array Map : X ! K
Page  447: upon receiving an encryption query (m0 , m1 ) 2 M2 :
Page  447: upon receiving a random oracle query x̂ 2 X :
Page  448: point. More precisely, we derive an efficient SS adversary Bs based on Game 1 that uses A as a
Page  448: modulus, and the encryption exponent e, which is an odd, positive integer. Recall that the RSA
Page  448: • for a given public key pk = (n, e), and message m 2 M, the encryption algorithm runs as
Page  448: • for a given secret key sk = (n, d), and a given ciphertext (y, c) 2 X ⇥ C, where y represents
Page  449: • for a given public key pk = u 2 G and message m 2 M, the encryption algorithm runs as
Page  449: • for a given secret key sk = ↵ 2 Zq and a ciphertext (v, c) 2 G ⇥ C, the decryption algorithm
Page  450: a random oracle, then intuitively, the only way the adversary can learn anything at all about the
Page  450: associative array Map : G ! K. The details are in Fig. 11.3. At line (3), we e↵ectively set the
Page  451: initialize an empty associative array Map : G ! K
Page  451: upon receiving an encryption query (m0 , m1 ) 2 M2 :
Page  451: upon receiving a random oracle query ŵ 2 G:
Page  451: random, and output it — with probability at least Pr[Z]/Q, this will be the solution to the given
Page  452: the hash function H : G ! K, namely that H is a secure key derivation function, or KDF for
Page  452: short. We already introduced a very general notion of a key derivation function in Section 8.10.
Page  452: Intuitively, H : G ! K is a secure KDF if no efficient adversary can e↵ectively distinguish
Page  452: Attack Game 11.3 (secure key derivation). For a given hash function F : X ! Y, and for a
Page  452: given adversary A, we define two experiments.
Page  453: Definition 11.5 (secure key derivation). A hash function F : X ! Y is a secure KDF if for
Page  453: Section 8.10.4 based on a universal hash function and the leftover hash lemma yields an uncondi-
Page  453: tionally secure KDF. Even though this construction is theoretically attractive and quite efficient,
Page  454: upon receiving (m0 , m1 ) 2 M2 :
Page  454: We may easily derive an efficient KDF adversary Bkdf that uses A as a subroutine, such that
Page  456: The combiner sends the given ciphertext c to all five key servers. Three servers respond,
Page  456: Figure 11.5: Threshold decryption using three responses from five key servers.
Page  456: sends back a “partial decryption.” Once t responses are received from the key servers, the combiner
Page  457: given ciphertext, but a single share cannot. The scheme can be generalized so that k can be split
Page  457: nothing about ↵. This sharing lets Alice give one share to each of her s friends, so that any t
Page  457: Intuitively, a secret sharing scheme is secure if every set of t 1 shares output by G(s, t, ↵)
Page  458: non-zero elements have a multiplicative inverse. Such a domain is called a field. When q is prime,
Page  458: Given t shares ↵i0 = (x0i , yi0 ) for i = 1, . . . , t, define t polynomials:
Page  459: Using (11.20) we can now describe algorithm Csh in more detail. Given a set of t 1 shares,
Page  459: requires division, but since q is prime, this is always well defined. It then computes ↵ using the
Page  459: reconstruct the secret key and decrypt a given ciphertext. However, this creates a single point of
Page  459: i = 1, . . . , s, are the shares of the decryption key ↵, and each key server is given one share.
Page  459: partial decryption (xi , v yi ) 2 Zq ⇥ G to the combiner. Once the combiner receives t partial
Page  460: • for a given secret key share sk i = (x, y) 2 Zq ⇥ G and a ciphertext (v, c) 2 G ⇥ C, the partial
Page  460: • given a ciphertext (v, c) 2 G ⇥ C, and t partial decryptions c0i = (xi , wi ) for i = 1, . . . , t, the
Page  460: puted on line (⇤) satisfies w = v ↵ , which is then used to derive the symmetric encryption key k
Page  460: Our security definition, given below, allows the adversary to eavesdrop on all traffic sent to the
Page  461: decryption scheme E = (G, E, D, C) defined over (M, C), and for a given adversary A, we define
Page  461: • Setup: the adversary chooses a set S ✓ {1, . . . , s} of size t 1 and gives it to the challenger.
Page  461: Proof. We design B to play the role of challenger to A. When A receives pk = u = g ↵ from its own
Page  462: Let (x0i , yi0 ) for i = 1, . . . , t 1 be the key shares that were given to A. Let m 2 M be a combiner
Page  462: Another enhancement, called proactive security, further strengthens the system by forcing the
Page  462: the adversary gets nothing. This is done by having the key servers proactively refresh the sharing
Page  462: 11.7      Fun application: oblivious transfer from DDH
Page  463: 11.3 (Oblivious PRF from DDH). Your proof that the PRF F presented in Exercise 11.1
Page  463: protocol that allows F to be evaluated obliviously. This means that if Bob has a key k 2 Zq and
Page  464: 11.5 (Multiplicative ElGamal). Let G be a cyclic group of prime order q generated by g 2 G.
Page  464: • for a given public key pk = u 2 G and message m 2 G:
Page  464: • for a given secret key sk = ↵ 2 Zq and a ciphertext (v, e) 2 G2 :
Page  464: (c) Show that EMEG has the following property: given a public key pk , and two ciphertexts
Page  464: encryption of m1 · m2 . This property is called a multiplicative homomorphism.
Page  464: 11.6 (An attack on multiplicative ElGamal). Let p and q be large primes such that q divides
Page  464: 11.8 (Encrypting many messages with multiplicative ElGamal). Consider again the mul-
Page  464: tuplicative ElGamal scheme in Exercise 11.5. To increase the message space from a single group
Page  465: • for a given public key pk = (u1 , . . . , un ) 2 Gn and message m = (m1 , . . . , mn ) 2 Gn :
Page  465: • for a given secret key sk = (↵1 , . . . , ↵n ) 2 Znq and a ciphertext c = (v, e1 , . . . , en ) 2 Gn+1 :
Page  466: 11.11 (A tight reduction for multiplicative ElGamal). We proved in Exercise 11.10 that
Page  466: multiplicative ElGamal encryption scheme EMEG from Exercise 11.5. You are to show a tight
Page  467: (a) Show that Gn is a multiplicative subgroup of Z⇤n2 of order n.
Page  467: • for a given public key pk = n and message m 2 {0, . . . , n      1}, set g := [n + 1]n2 2 Z⇤n2 . The
Page  467: an additive homomorphism: for ciphertexts c0 R E(pk , m0 ) and c1 R E(pk , m1 ), the product
Page  468: (a) Define a security model that captures this requirement. The adversary should be given t
Page  468: public keys pk 1 , . . . , pk t and it then selects the message m that Alice sends. Upon receiving
Page  468: and decryption should be possible only if the combiner receives at least t1 responses from the set
Page  468: of the given shares. Such schemes, called linear secret sharing schemes (LSSS), are surveyed in [8].
Page  469: (a) Suppose pk alice = g ↵ and pk bob = g ↵ . Show that giving ⌧ := ↵/↵0 to the mail server
Page  469: security for Alice, even if it is given Bob’s public key g ↵ along with the translation key ⌧ .
Page  470: Attack Game 12.1 (CCA security). For a given public-key encryption scheme E = (G, E, D),
Page  470: defined over (M, C), and for a given adversary A, we define two experiments.
Page  472: The definition of CCA security may seem rather unintuitive at first. Indeed, one might ask: in the
Page  472: malleable. That is, given an encryption c of some message m, the attacker cannot create a di↵erent
Page  472: erates a public key/secret key pair (pk , sk ) for a public-key encryption scheme, and gives pk to all
Page  473: and give Molly credit for it.
Page  473: succeed if the public-key encryption scheme were actually CCA secure. Indeed, if given (y, c) it is
Page  474: receives (y, c0 , t0 ), and believes the authenticity of the ciphertext. When Bob decrypts (y, c0 ), the
Page  474: policy, based on the given metadata, along with the identity or credentials of the requesting entity.
Page  475: input called associated data. The point is that decryption reveals no useful information if the given
Page  475: To conclude our motivational discussion of CCA security we show that it abstractly captures a
Page  475: The setting is as follows. We have a sender S and receiver R, who are participating in some
Page  476: the receiving end, when a ciphertext ĉ is received at R’s end of the wire, it is decrypted using sk ,
Page  476: determine if a given ciphertext delivered to R was rejected.
Page  476: length). When ci arrives at R, the corresponding message mi is magically copied from S’s out-box
Page  476: to R’s in-box. If a ciphertext ĉ arrives at R that is not among the previously generated ci ’s, the
Page  476: equivalent to the real implementation. In the ideal implementation, we see that messages magically
Page  476: arrives on R’s end, the list of ciphertexts c1 , c2 , . . . previously generated by S is scanned, and
Page  476: real implementation. Note that in this modification, any ciphertext that arrives at R’s end
Page  477: tion schemes. Using the result in this section, all these trapdoor functions give us CCA-secure
Page  477: explicitly check that the given value y 2 Y is actually in the image of F (pk , ·). So the scheme we
Page  478: assumption: that T is one-way even given access to an “image oracle”. Essentially, this means that
Page  478: given pk and y = F (pk , x) for randomly chosen x 2 X , it is hard to compute x, even given access
Page  478: to an oracle that will answer arbitrary questions of the form “does a given ŷ 2 Y lie in the image of
Page  478: F (pk , ·)?”. We formalize this notion by giving an attack game that is similar to Attack Game 10.2,
Page  478: given trapdoor function scheme T = (G, F, I), defined over (X , Y), and a given adversary A, the
Page  478: We define the adversary’s advantage in inverting T given access to an image oracle, denoted
Page  478: Definition 12.3. We say that a trapdoor function scheme T is one way given an image oracle
Page  478: scheme can be easily converted into one that is one way given an image oracle.
Page  478: The next theorem proves the CCA security of ETDF  0   , assuming T is one-way given an image ora-
Page  478: we explore an alternative analysis of this scheme under di↵erent assumptions.
Page  478: Theorem 12.2. Assume H : X ! K is modeled as a random oracle. If T is one-way given an
Page  479: given a decryption query (ŷ, ĉ), where y 6= ŷ = F (pk , x̂).
Page  479: We also have to deal with decryption queries of the form (y, ĉ), where ĉ 6= c. Intuitively, under
Page  479: one-way given an image oracle — in the reduction, we need this image oracle to reject ciphertexts
Page  480: processing decryption queries. This will motivate a somewhat nontrivial strategy for implementing
Page  480: As usual, we will make use of an associative array to implement the random oracle. In the
Page  480: by using an associative array Map : X ! K. We could do the same thing here, but because we want
Page  480: will represent the random oracle using associative array Map 0 : Y ! K, with the convention that
Page  480: will also make use of an associative array Pre : Y ! X that is used to track explicit random oracle
Page  481: initialize empty associative arrays Pre : Y ! X and Map 0 : Y ! K
Page  481: upon receiving an encryption query (m0 , m1 ) 2 M2 :
Page  481: upon receiving a decryption query (ŷ, ĉ) 2 X ⇥ C, where (ŷ, ĉ) 6= (y, c):
Page  481: upon receiving a random oracle query x̂ 2 X :
Page  482: playing the 1CCA attack game against Es at this point. More precisely, we can easily derive an
Page  482: the image oracle in Attack Game 12.2 is trivial to implement, and so we end up back with Attack
Page  483: be e↵ectively used by the adversary to answer questions of the form “is (u, v̂, ŵ) a DH-triple?” for
Page  483: Intuitively, the interactive CDH assumption states that given a random instance (g ↵ , g )
Page  483: of the DH problem, it is hard to compute g ↵ , even when given access to a “DH-decision oracle”
Page  483: Attack Game 12.3 (Interactive Computational Diffie-Hellman). Let G be a cyclic group
Page  483: of prime order q generated by g 2 G. For a given adversary A, the attack game runs as follows.
Page  483: and gives (u, v) to the adversary.
Page  483: is of the form (ṽ, w̃) 2 G2 . Upon receiving such a query, the challenger tests if ṽ ↵ = w̃; if so,
Page  483: We define A’s advantage in solving the interactive computational Diffie-Hellman prob-
Page  484: Definition 12.4 (Interactive Computational Diffie-Hellman assumption). We say that the
Page  484: interactive computational Diffie-Hellman (ICDH) assumption holds for G if for all efficient
Page  484: that the symmetric key k is derived by hashing both v and w, instead of just w; that is, the hash
Page  484: insist that given a ciphertext (v, c), the decryption algorithm verifies that v 2 G. For example, if G
Page  484: groups (elliptic curves) where group membership verification can be much less expensive. 2
Page  485: we use a somewhat nontrivial strategy for implementing the decryption and random oracle queries.
Page  485: equivalent to the actual attack game.
Page  485: As usual, we will implement the random oracle using an associative array Map : G2 ! K.
Page  485: However, we will also make use of an auxiliary associative array Map 0 : G ! K. The convention
Page  485: Map[v̂, ŵ] = Map 0 [v̂] = k̂. However, in processing a decryption query (v̂, ĉ), we may speculatively
Page  486: another associative array. The idea is that Sol records solutions to Diffie-Hellman instances
Page  486: playing the 1CCA attack game against Es at this point. More precisely, we can easily derive an
Page  487: initialize three empty associative arrays
Page  487: upon receiving an encryption query (m0 , m1 ) 2 M2 :
Page  487: upon receiving a decryption query (v̂, ĉ) 2 G ⇥ C, where (v̂, ĉ) 6= (v, c):
Page  487: upon receiving a random oracle query (v̂, ŵ) 2 G2 :
Page  488: G where the ICDH assumption is equivalent to the CDH assumption. In such groups there is no
Page  488: in groups where ICDH is not known to be equivalent to CDH. Is it reasonable to assume ICDH
Page  488: we develop a more modular analysis of EEG0   based on a new assumption, called the interactive hash
Page  488: 12.5.1    Universal projective hash functions
Page  488: generality would take us too far afield. Rather, we give just an intuitive description of this tool
Page  488: The tool is called a projective hash function. It can perhaps be best understood as a form
Page  488: the ability to evaluate f to Bob — but not entirely. Specifically, she wants to give Bob just enough
Page  488: denote by h the information about f that Alice gives to Bob. In our applications, L will always
Page  488: Such a scheme is called a projective hash function. Given the auxiliary information h, the
Page  488: is satisfied, then we say this scheme is a universal projective hash function.
Page  488: A concrete instantiation. We now give a concrete example of the above idea. Suppose G is a
Page  489: So if Alice chooses , ⌧ 2 Zq at random, which defines f , and gives h to Bob, then for any
Page  489: So this is a projective hash function. To show that it is universal, it suffices to show that h and
Page  490: Attack Game 12.4 (Universal distinguishing game). For a given adversary A, we define two
Page  490: 12.5.2     Universal2 projective hash functions
Page  490: universal, which is called universal2 . Again, we present the intuitive idea in terms of function
Page  490: Alice has a function f 0 : Y ⇥ T ! Z, and she wants to give Bob auxiliary information h0 that will
Page  490: with f 0 (y, t) and f 0 (ŷ, t̂) each uniformly distributed over Z. In particular, given h0 and f 0 (y, t), the
Page  490: We can easily extend our universal projective hash function scheme for Lu ✓ G2 in Section 12.5.1
Page  490: to obtain a universal2 projective hash function scheme for Lu . In this scheme, our “tags” will be
Page  491: It should be clear that if Alice chooses 1 , ⌧1 , 2 , ⌧2 2 Zq at random, which defines f 0 , and gives
Page  491: as (h1 h⇢2 ) . The universal2 independence property is established by the following lemma, which
Page  491: Attack Game 12.5 (Universal2 guessing game). For a given adversary A, the game runs as
Page  492: • for a given public key pk = (u, h, h1 , h2 ) 2 G4 and message m 2 M, the encryption algorithm
Page  492: • for a given secret key sk = ( , ⌧, 1 , ⌧1 ,                       6                                   3
Page  493: projective hash functions defined in Sections 12.5.1 and 12.5.2.
Page  493: information in the public key. A symmetric key is then derived from z using H, which is used
Page  493: passes, the algorithm then computes z = f (v, w), derives a symmetric key from z using H,
Page  494: upon receiving an encryption query (m0 , m1 ) 2 M2 :
Page  494: upon receiving a decryption query (v̂, ŵ, ẑ 0 , ĉ) 2 G3 ⇥ C, where (v̂, ŵ, ẑ 0 , ĉ) 6= (v, w, z 0 , c):
Page  494: queries. The game is described using the terminology of projective hash functions, as discussed
Page  495: The motivation for making this change is that now, the only place where we use the exponents
Page  495: Game 1, but using the given values u, v, w. If (u, v, w) is a random DH-triple, then this is equivalent
Page  495: to Game 1, and if (u, v, w) is a random triple, this is equivalent to Game 2. At the end of the game,
Page  496: game to evaluate f 0 , as needed. That challenger gives us f 0 (v, w, ⇢), along with h1 and h2 , at the
Page  497: Remark 12.1, it is essential that given a ciphertext (v, w, z 0 , c), the decryption algorithm for ECS
Page  497: achieve CCA security in the random oracle model under the interactive CDH assumption, and with
Page  497: The answer is yes. In the random oracle model it is possible to give a simple and efficient transfor-
Page  497: is CCA-secure in the random oracle model. It is possible, in principle, to give a similar transfor-
Page  497: a variant of ElGamal encryption, gives a public key encryption scheme that is CCA-secure in the
Page  497: random oracle model under the ordinary CDH assumption, rather than the stronger, interactive
Page  498: even given an image oracle (as in Definition 12.3), starting from any one-way, probabilistic public-
Page  498: To prove that TFO is one way given an image oracle, in addition to modeling U as a random
Page  498: 1. Ea is one way, which basically means that given an encryption of a random message x 2 X ,
Page  498: Attack Game 12.6 (One-way encryption). For a given public-key encryption scheme Ea =
Page  498: (Ga , Ea , Da ) with message space X , ciphertext space Y, and randomizer space R, and a given
Page  499: Definition 12.6 (Unpredictable encryption). Let Ea = (Ga , Ea , Da ) be a given public-key
Page  499: one way given an image oracle.
Page  499: the random oracle at its output value: this is a reasonable assumption, and we can always trivially
Page  499: oracle queries. We make use of an associative array Map : X ! R to implement the random oracle
Page  499: can make any number of random oracle queries and any number of image queries. The associative
Page  500: initialize empty associative arrays Map : X ! R and Pre : Y ! X
Page  500: upon receiving an image oracle query ŷ 2 Y:
Page  500: upon receiving a random oracle query x̂ 2 X :
Page  501: upon receiving an image oracle query ŷ 2 Y:
Page  503: We called this scheme multiplicative ElGamal in Exercise 11.5, where we showed that it is seman-
Page  503: same advantage. Given an instance (u, v) 2 G2 of the CDH problem, adversary B plays the
Page  503: G, and gives A the public key u and the ciphertext (v, y);
Page  503: Clearly, if x is the decryption of (v, y), then w = y/x is the solution to the given instance
Page  504: ordinary CDH assumption, that scheme requires the stronger, interactive CDH assumption. See
Page  504: one might presume that given a ciphertext (v, y, c), the decryption algorithm for EFO
Page  505: generated by E are correctly decrypted by D, as long as both are given the same associated data.
Page  505: • All of the CCA-secure public-key encryption schemes presented in this chapter can be triv-
Page  505: also Exercise 12.18 for an alternative approach.
Page  506: m 2 M, the encryptor “encodes” the given message as an element of X , and then applies the
Page  506: As a first naive attempt, suppose X := {0, 1}t and M := {0, 1}s , where, say, t = 2048 and
Page  506: This naive scheme uses deterministic encryption and is therefore not even CPA secure. It should
Page  507: For a given padding scheme (P, U ) defined over (M, R, X ), let us define the following pubic-key
Page  507: encryption scheme Epad = (G, E, D) derived from the trapdoor function T = (G, F, I):
Page  508: • When the server receives a client key exchange message it extracts the ciphertext c and
Page  509: all of x with several million queries to the server. Exercise 12.20 gives a simple example of this
Page  509: are not possible even given a full decryption oracle, let alone a partial decryption oracle like Px .
Page  509: This devastating attack lets the attacker eavesdrop on any SSL session of its choice. Given the
Page  510: immune to Bleichenbacher’s attack. E↵ectively, the old SSL 2.0 implementation compromises the
Page  510: the derived public-key encryption scheme was standardized in the PKCS1 version 2.0 standard. It
Page  511: SHA256 is used as the function H and we set h := 256. The function W is derived from SHA256
Page  511: (see Section 8.10.3 for recommended derivation techniques).
Page  512: the adversary is given pk and y     F (pk , x), for some pk and random x 2 X , and is asked to produce
Page  512: x. In the game defining a partial one-way function, the adversary is given pk and y, but is only
Page  512: Attack Game 12.7 (Partial one-way trapdoor function scheme). For a given trapdoor
Page  512: function scheme T = (G, F, I), defined over X , Y , a given efficiently computable function f :
Page  512: X ! Z, and a given adversary A, the attack game runs as follows:
Page  513: Given Theorem 12.13 the question is then: is RSA a partial one-way function? We typically
Page  513: way. More precisely, suppose there is an efficient adversary A that given an RSA modulus n
Page  513: However, for other one-way trapdoor functions, the derived scheme EOAEP may not be CCA-secure.
Page  513: trapdoor function, gives a CCA-secure scheme in the random oracle model? The answer is yes,
Page  513: a simple alternative padding scheme for RSA.
Page  514: 12.1 (Insecurity of multiplicative ElGamal). Show that multiplicative ElGamal from Exer-
Page  514: security. More formally, we assume that for each key pair (pk , sk ), there is an equivalence relation
Page  514: Moreover, we assume that given pk , c, c0 , it is easy to tell if c ⌘pk c0 . Note that the relation ⌘pk is
Page  514: query is not equivalent to (as opposed to not equal to) any ciphertext arising from a previous
Page  514: EEG  should verify that in a given ciphertext (v, c), the element v actually belongs to the group G.
Page  514: algorithm checks that v 2 Z⇤p (which is typically quite trivial to do), but does not check that v 2 G
Page  514: and uses v, w, c to decrypt the given ciphertext. Here, we treat ↵ as an integer in the range [0, q),
Page  515: CCA secure, E 2 is not CCA secure. For this, you should assume M is non-trivial (i.e., contains at
Page  515: (in the random oracle model, assuming T is one way given an image oracle).
Page  516: (e) Give examples that show that if one of Ekem and Es is 1CCA secure, while the other is only
Page  517: 0                            0 , except that instead of deriving the symmetric key as
Page  517: k = H(v, w), we derive it as k = H(u, v, w). Consider the security of xEEG0  in the multi-key CCA
Page  517: texts, which means that there is an efficient algorithm that given a public key pk , along with x 2 X
Page  518: mark 12.3. Consider the concrete instantiation EFO of Fujisaki-Okamoto using the multiplicative
Page  518: variant of the multiplicative ElGamal encryption scheme, where the plaintext space is G0 and the
Page  518: secure assuming the trapdoor function scheme T is one-way given access to an image oracle, and Es
Page  518: without assuming it is one-way given access to an image oracle), provided that Es is 1AE secure
Page  518: in Theorem 12.2 is una↵ected by this side-channel leak: the adversary is given an image oracle
Page  519: (G, F 0 , I 0 ) is one way given an image oracle.
Page  519: first given pk , then makes a series of decryption queries, followed by one encryption query, followed
Page  521: where 0  0 , 1 < T . Show an efficient algorithm that given such r, z0 , z1 , outputs x, 0 , 1 ,
Page  521: for a given secret key sk = (↵, , 1 , 2 ) 2 Z4q and a ciphertext (v, w, z 0 , c) 2 G3 ⇥ C, the
Page  522: 12.25 (Stronger properties for projective hash functions). We can strengthen Attack
Page  522: Games 12.4 and 12.5, allowing the adversary to choose the values (v, w) (and ⇢) adaptively.
Page  522: 12.26 (Multiplicative Cramer-Shoup encryption). Consider the following multiplicative ver-
Page  522: is defined over (G, D, G4 ) as follows. Key generation is exactly as in ECS . For a given public key
Page  522: For a given secret key sk = ( , ⌧, 1 , ⌧1 , 2 , ⌧2 ) 2 Z6q and a ciphertext (v, w, e, z 0 ) 2 G4 , and associ-
Page  522: 12.27 (Non-adaptive CCA security and Cramer-Shoup lite). One can define a weaker
Page  523: encryption query. Let us call the corresponding security notion non-adaptive 1CCA security.
Page  523: For a given public key pk = (u, h0 , h1 ) 2 G3 and message m 2 G, the encryption algorithm runs as
Page  523: for a given secret key sk = ( 0 , ⌧0 ,                  4                                   4
Page  523: (a) Show that EMCSL is non-adaptive 1CCA secure, provided the DDH assumption holds for G.
Page  523: 12.28 (Generalizing universal projective hash functions). This exercise develops a construc-
Page  523: tion for universal projective hash functions that generalizes the one presented in Section 12.5.1. Let
Page  523: (a) Show how to efficiently compute v , given 1 , . . . , k 2 Zq such that v = u1 1 · · · uk k , along
Page  524: 12.29 (A universal projective hash function for EMCS ). Consider the encryption scheme
Page  524: Design a universal projective hash function for L with outputs in G. The algorithm to evaluate
Page  524: 12.30 (Interactive hash Diffie-Hellman). Let G be a cyclic group of prime order q generated
Page  524: by g 2 G. Let H : G2 ! K be a hash function. We say that the Interactive Hash Diffie-Hellman
Page  524: Each query is of the form ṽ 2 G2 . Upon receiving such a query, the challenger computes
Page  524: interactive CDH (ICDH) assumption (see Definition 12.4). In this exercise and the next, we show
Page  524: is this: given
Page  525: is called Twin DH (2DH) tuple. The interactive Twin CDH (I2CDH) assumption is this:
Page  525: it is hard to solve a random instance (g ↵1 , g ↵2 , g ) of the 2DH problem, given access to an oracle
Page  525: (a) Flesh out the details of the I2CDH assumption by giving an attack game analogous to Attack
Page  526: exactly the same as E2cdh , except that instead of deriving the symmetric key as k = H(v, w1 , w2 ),
Page  526: we derive it as k = H(u1 , u2 , v, w1 , w2 ). Consider the security of xE2cdh in the multi-key CCA
Page  527: motivate digital signatures with three examples.
Page  527: check that the hash of the received file U matches the hash value on the read-only server.
Page  527: • A customer Bob, given the update (U, ) and the public key pk , checks validity of this message-
Page  528: Example 2: Authenticated email. As a second motivating example, suppose Bob receives an
Page  528: When sending an email m to Bob, Alice generates a signature on m derived using her secret
Page  528: key. She then sends (m, ) to Bob. Bob receives (m, ) and verifies that m is from Alice in two
Page  528: delivered, otherwise it is dropped. DKIM is widely used as a mechanism to make it harder for
Page  528: Example 3: Certificates. As a third motivating example for digital signatures, we consider
Page  528: To generate a certified public key, Alice first generates a public/private key pair (pk , sk ) for
Page  529: but have little to do with the legal system. Several legislative e↵orts in the U.S. and Europe at-
Page  529: Now that we have an intuitive feel for how digital signature schemes work, we can define them
Page  530: The definition of a secure signature scheme is similar to the definition of secure MAC. We give the
Page  530: Attack Game 13.1 (Signature security). For a given signature scheme S = (G, S, V ), defined
Page  530: over (M, ⌃), and a given adversary A, the attack game runs as follows:
Page  530: message mi 2 M. Given mi , the challenger computes i R S(sk , mi ), and then
Page  530: gives i to A.
Page  531: security primitives, one can generalize the notion of a secure signatures to the multi-key setting,
Page  531: In contrast, for MAC security we insisted that given a message-tag pair (m, t) the adversary
Page  531: Attack Game 13.2. For a given signature scheme S = (G, S, V ), and a given adversary A, the
Page  532: We require that the attacker can produce both pk 0 and sk 0 . Exercise 13.4 gives examples of
Page  533: As usual, we give a more mathematically precise definition of a signature, using the terminology
Page  533: given to both the adversary and the challenger. The advantage SIGadv[A, S] is then a function of .
Page  533: Suppose we are given a secure digital signature scheme with a small message space, say M =
Page  534: resistant. Then the derived signature scheme S 0 = (G, S 0 , V 0 ) defined in (13.1) is a secure signature.
Page  534: TCR. Then the derived signature scheme S 0 = (G, S 0 , V 0 ) defined in (13.2) is secure.
Page  535: We show that a trapdoor permutation T gives a simple signature scheme. The only other
Page  535: M ! X be a hash function. Then the derived FDH signature scheme SFDH is a secure signature
Page  536: as a random oracle, this e↵ectively means that to break the signature scheme, the adversary must
Page  536: Unique signatures. The SFDH scheme is a unique signature scheme: for a given public key,
Page  536: first hashing the message, the system is trivially insecure. To see why, suppose we incorrectly define
Page  537: For a given hash function H : M ! Y, the SRSA-FDH signature scheme works as follows:
Page  537: • for a given secret key sk = (n, d), and message m 2 M, algorithm S runs as follows:
Page  537: • for a given public key pk = (n, e) the verification algorithm runs as follows:
Page  537: This makes RSA very attractive for applications where a signature is generated o✏ine, but needs
Page  537: where fast verification is attractive. We discuss ways to speed-up the RSA signing procedure in
Page  538: universally forgeable and thus should never be used.
Page  538: electronic voting. In both applications blind signatures are the main ingredient for ensuring privacy
Page  538: hash SFDH (Theorem 13.3) was very loose: an adversary A with advantage ✏ in attacking SFDH gives
Page  538: that an honest user sign a message. Concretely, a conservative bound on Qro could perhaps be as
Page  539: Let f be a one-way function over (X , Y). Briefly, this means that given y         f (x) for a random
Page  539: Consider the following, seemingly easier, problem: we give the adversary f (x1 ), . . . , f (xt ) and
Page  539: Attack Game 13.3 (t-repeated one-way problem). For a given positive integer t and a given
Page  539: Given j, the challenger sends xj to A.
Page  539: The following lemma shows that the repeated one-way problem is equivalent to the standard
Page  539: one-way problem given in Definition 8.6. That is, winning in Attack Game 13.3 is not much easier
Page  540: Proof. In more detail, our adversary B is given y⇤ := f (x⇤ ) for a random x⇤ 2 X , and then plays
Page  540: Upon receiving a query j 2 {1, . . . , t} from A:
Page  541: any adversary, the respective advantages in the corresponding attack games are equal. Technically,
Page  541: When f is derived from the RSA function we can obtain a tighter reduction using the random
Page  541: and require that the images y1 , . . . , yt given to A lie in a certain large subset of Zn denoted Y. For
Page  541: Attack Game 13.4 (t-repeated RSA). For given RSA parameters ` and e, a given positive
Page  541: integer t, and a given adversary A, the game runs as follows:
Page  541: Given j, the challenger sends xj := yjd 2 Zn to A.
Page  541: We show that the t-repeated RSA problem is equivalent to the basic RSA problem, but with a
Page  542: Upon receiving a reveal query j 2 {1, . . . , t} from A:
Page  542: Proof. We describe an adversary B that is given (n, e) and a random y⇤ 2 Zn , and then attempts
Page  542: root is 0; otherwise, gcd(y⇤ , n) gives us the prime factorization of n, which allows us to compute
Page  543: The claim is trivially true if Q = 0; otherwise, we have:
Page  544: with a relatively loose security reduction. In particular, let A be an adversary attacking SRSA-FDH
Page  544: Surprisingly, a small modification to SRSA-FDH gives a signature scheme that has a tight reduc-
Page  544: • For a given secret key sk = (k, n, d) and m 2 M, the signing algorithm S runs as follows:
Page  545: • For a given public key pk = (n, e) and signature (b, ), the verification algorithm does:
Page  545: and y⇤    xe⇤ 2 Zn . Algorithm B is given n, y⇤ and its goal is to output x⇤ . First B sends the public
Page  545: signature produced by A seems to give B no new information.
Page  545: • upon receiving a random oracle query (b, m) 2 M0 from A do:
Page  546: • Upon receiving a signing query m 2 M from A, respond as follows. First, compute b    f (m)
Page  547: the two given signatures. Hence, the attacker obtains an existential forgery by issuing two chosen
Page  547: (⇤)     given an RSA modulus n, output a pair (y, x) where y is uniformly
Page  548: Implementing cryptography is not easy. In this section, we give a clever attack on a once-popular
Page  549: cryptographic primitives. A simple misunderstanding in reading the PKCS1 specification resulted
Page  549: for Bob, and Bob receives and decrypts it at a later time. The ciphertext she sends to Bob must
Page  549: Since anyone can generate public-private key pairs, signcryption only makes sense in an envi-
Page  549: public-private key pair and convince Bob that this public key belongs to Alice, then the goals of
Page  550: can be reasonably confident that only Bob knows the corresponding private key. Abstractly, one
Page  550: sender’s public-private key pair by pk S and sk S and the recipients key pair by pk R and sk R . To
Page  550: shared secret key. Signcryption is intended for a non-interactive setting where no shared secret key
Page  551: to derive more intuitive security properties of signcryption in a multi-user setting. It is precisely
Page  551: these implications that give us confidence that the basic definition in Section 13.7.1 is sufficiently
Page  551: In both games the adversary is active. In addition to asking Alice to encrypt messages intended
Page  551: may also be receiving messages from other users. Therefore, the adversary is free to ask Alice to
Page  551: Attack Game 13.5 (ciphertext integrity). For a given signcryption scheme SC = (G, E, D)
Page  551: defined over (M, C, I), and a given adversary A, the attack game runs as follows:
Page  551: • The adversary chooses two distinct identities id S (the sender identity) and id R (the receiver
Page  551: identity), and gives these to the challenger. The challenger runs G twice to obtain (pk S , sk S )
Page  551: and (pk R , sk R ) and gives pk S and pk R to A.
Page  551: The challenger computes c R E(sk S , id S , pk R , id R , m), and gives c to A.
Page  552: Attack Game 13.6 (CCA security). For a given signcryption scheme SC = (G, E, D), defined
Page  552: over (M, C, I), and for a given adversary A, we define two experiments.
Page  552: • The adversary chooses two distinct identities id S (the sender identity) and id R (the receiver
Page  552: identity), and gives these to the challenger. The challenger runs G twice to obtain (pk S , sk S )
Page  552: and (pk R , sk R ) and gives pk S and pk R to A.
Page  552: The challenger computes c R E(sk S , id S , pk R , id R , mb ), and gives c to A.
Page  552: The challenger computes m̂ R D(pk S , id S , sk R , id R , ĉ), and gives ĉ to A.
Page  553: same c to Bob. Bob receives the replayed ciphertext c and, because it is a valid ciphertext, he
Page  553: Statically vs adaptively chosen user IDs. Our definition of secure signcryption is subject to
Page  553: the adversary to choose the user IDs of the sender and receiver (that is, id S and id R ), this choice
Page  553: would allow a more “adaptive” strategy, in which the adversary gets to choose these IDs after seeing
Page  553: but it is possible to dream up contrived schemes where it does (see Exercise 13.18). We have
Page  554: and may have some knowledge of messages received by honest users.
Page  554: with the given user IDs). The resulting ciphertext is sent out to the network.
Page  554: using the public key of id S and the secret key id R (along with the given user IDs). If the ciphertext
Page  555: out-box is safe (i.e., user id R is an honest user), instead of encrypting the given message, a dummy
Page  555: We hope that it is intuitively clear that this ideal implementation provides all the security one
Page  555: senders to honest receivers: the attacker cannot tamper with or glean any information about
Page  557: already touched on this issue back in Section 12.2.2 as one of the motivations for studying CCA-
Page  557: given a challenge ciphertext (c, ), can produce a new valid signature 0 on the same data, then
Page  558: To process an encryption query, Bsig begins by encrypting the given message m using the
Page  558: Bsig answers decryption queries from Aci by simply running algorithm DEtS on the given data
Page  558: queries. Namely, given an S ! R decryption query (ĉ, ˆ ), where ˆ is a valid signature on (ĉ, id R ),
Page  558: pair (m0 , m1 ) by issuing an encryption query for (m0 , m1 ) to its challenger, relative to the associated
Page  559: To answer an X ! Y encryption query, Bcca runs algorithm EEtS on the given data in the query.
Page  559: Finishing up. Eventually, Acca outputs a guess b̂ 2 {0, 1}. This guess gives Bcca the same
Page  560: Our next signcryption construction does not use signatures at all. Instead, we use a non-interactive
Page  560: G of prime order q with generator g 2 G. This variant is said to be non-interactive because once
Page  560: Alice publishes g ↵ and Bob publishes g , their shared secret is derived from g ↵ . The signcryption
Page  560: scheme we describe can be built from any non-interactive key exchange, but here we present it
Page  560: Given these ingredients, the system SC DH is defined over (M, C, I) and works as follows:
Page  560: • E ↵S , id S , hR , id R , m works by first deriving the Diffie-Hellman secret between users S and
Page  560: with a key derived from hSR . More precisely, encryption works as follows, where hS := g ↵S :
Page  561: a new assumption, called the double-interactive CDH assumption. The assumption is related to,
Page  561: but a little stronger than, the interactive CDH assumption introduced in Section 12.4.
Page  561: Intuitively, the double-interactive CDH assumption states that given a random instance (g ↵ , g )
Page  561: of the DH problem, it is hard to compute g ↵ , even when given access to a DH-decision oracle that
Page  561: Attack Game 13.7 (Double-Interactive Computational Diffie-Hellman). Let G be a cyclic
Page  561: group of prime order q generated by g 2 G. For a given adversary A, the attack game runs as
Page  561: and gives (u, v) to the adversary.
Page  561: ↵-query: given (ṽ, w̃) 2 G2 , the challenger tests if ṽ ↵ = w̃;
Page  561: -query: given (ũ, w̃) 2 G2 , the challenger tests if ũ = w̃.
Page  561: We define A’s advantage in solving the double-interactive computational Diffie-Hellman
Page  561: Definition 13.9 (Double-Interactive computational Diffie-Hellman assumption). We say
Page  561: that the double-interactive computational Diffie-Hellman (I2 CDH) assumption holds for G
Page  562: The proof of Theorem 13.10 follows from the analysis of Diffie-Hellman as a non-interactive key
Page  562: giving the adversary the public keys pk S and pk R , the challenger gives the adversary the sender’s
Page  562: Indeed, from the concrete security bound given in Theorem 13.9, one can see that the bound on
Page  563: Forward secrecy for SC DH . The SC DH signcryption system is not forward secure: given the
Page  563: In this scheme, the symmetric encryption key is derived from the long term secret key hSR = g ↵S ·↵R
Page  564: Interestingly, the proof of CCA security for SC 0DH only relies on the simpler interactive Diffie-
Page  564: Hellman assumption from Section 12.4, not the double-interactive assumption I2 CDH that we used
Page  564: proof of CCA security with forward secrecy, where the adversary is given the sender’s secret key, is
Page  564: at the beginning of the chapter that such evidence is inherently limited in its persuasive powers:
Page  565: to Attack Game 13.5 except that we change the setup step as follows: in addition to giving the
Page  565: adversary the public keys pk S and pk R , the challenger gives the adversary the receiver’s secret key
Page  565: anything. Indeed, in the concrete security bound given in Theorem 13.8, one can see that the
Page  565: then-encrypt construction. Observe that in the concrete security bound given in Theorem 13.9,
Page  565: have defined it. Indeed, given the decryption key, one can always decrypt a ciphertext encrypting
Page  565: receiver. In real-world settings this deniability property may be considered a feature rather than a
Page  565: Exercise 13.19 is a variation of encrypt-then-sign that is also an attractive option to ensure both
Page  566: Once the CA receives the CSR, it checks that Alice is who she claims to be. In some cases this
Page  566: check is as naive as sending a challenge email to Alice’s address and verifying that she can read the
Page  566: gives an example X.509 certificate that binds a public key to an entity identified in the subject
Page  566: becomes active, and a time when the certificate expires. A certificate is considered invalid outside
Page  566: the private key is stolen by an attacker, that attacker can only abuse the key for a limited period
Page  566: are thousands of active CAs issuing certificates.
Page  567: CA. This process can repeat recursively, resulting in a chain of certificates where every certificate
Page  568: • Verisign in 2001 erroneously issued a Microsoft code-signing certificate to an individual mas-
Page  568: querading as a Microsoft employee [88]. This certificate enabled that individual to distribute
Page  570: received during that day to the log. It then computes a hash of the entire log and signs the hash
Page  571: downloads the log, it is given the version of the log with the rogue certificate. To the auditor, all
Page  571: it is given the version without the rogue certificate. This prevents Facebook from discovering the
Page  571: SCT from a trusted certificate log. This will e↵ectively force universal adoption of certificate
Page  571: been issued in error, as discussed in the previous subsection. The private key corresponding to
Page  571: Given the need to revoke certificates, we next describe a few techniques to do so.
Page  572: Short-lived certificates. Recall that every certificate has a validity period and the certificate
Page  572: certificates are called short-lived certificates because each is valid for only one day.
Page  572: short-lived certificates for its domain. This e↵ectively makes the stolen private key useless after
Page  572: at most one week. If faster revocation is needed, the CA can be told to release each short-lived
Page  572: The use of short-lived certificates is the simplest and most practical technique for certificate
Page  573: browser, sends to the CA the serial number of every certificate it encounters, the CA can e↵ectively
Page  573: learn what web sites the user is visiting. This is a breach of user privacy. The problem can be
Page  573: legislative e↵orts that try to articulate this notion. This discussion shows that a cryptographic
Page  574: Clearly, the first five examples are easily forgeable and thus provide little means of identifying
Page  574: the first five examples should be treated as the legal equivalent of signing with an ‘X’.
Page  574: pean Parliament adopted the Electronic Signatures Directive. The directive addresses three forms
Page  574: directive is technology neutral but, in practice, AES refers mainly to a cryptographic digital signa-
Page  574: 13.10      A fun application: private information retrieval
Page  575: non-binding: for a given (pk , sk ), the signer can find two distinct messages m0 and m1 where the
Page  575: Give an example of a secure signature that is non-binding.
Page  576: (pk 0 , sk 0 ), where pk 0 6= pk , such that at least one of the given message-signature pairs verifies
Page  576: The benefit over the construction in Section 13.2.1 is that r is not part of the message given to the
Page  576: 13.8 (Selective security). Selective security is a weak notion of signature security, where the
Page  576: (G, S, V ) be a signature scheme defined over (M, ⌃). The selective security game begins with the
Page  576: a valid signature on m, and the scheme (G, S, V ) is selectively secure if no efficient adversary
Page  577: Show that if (G, S, V ) is selectively secure, and H is modeled as a random oracle, then (G, S 0 , V 0 )
Page  577: (G, S 0 , V 0 ) there exists a selective forgery adversary B against S = (G, S, V ) such that
Page  577: advantage in winning the selective security game against S.
Page  577: (a) Let n = pq such that neither 3 nor 5 divide (p 1)(q 1). We are given p, q and y1 , y2 2 Zn .
Page  577: that given t1/15 2 Zn , it is possible to compute both x1 and x2 using a constant number of
Page  578: (c) Show that just given (m0 , ), where is a valid signature on the message (m0 , m1 ), it is
Page  578: (a) Show that just given (m0 , ), where       is a valid signature on the message (m0 , m1 ), it is
Page  578: output by G, and all x 2 X , given only I(sk , x) as input, one can easily compute I(sk , x 1n ).
Page  578: be adapted to give blind signatures. A blind signature scheme lets one party, Alice, obtain a
Page  578: private key. As usual, let H : M ! Zn be a hash function. Alice wants Bob to sign a message
Page  579: (a) We say that a blind signature protocol is secure if the adversary, given a public key and the
Page  579: key can be split into three shares, so that two shares are needed to decrypt a given ciphertext,
Page  579: Show that this system is an insecure signcryption scheme by giving a CCA attack. At one point, a
Page  580: 13.18 (Signcryption: statically vs adaptively chosen user IDs). In the discussion following
Page  580: the adversary is allowed to choose the sender and receiver user IDs adaptively, after seeing one or
Page  580: (b) Give an example of a signcryption scheme that satisfies Definition 13.8 but does not satisfy
Page  580: cryptographic primitives, as convenient.
Page  581: the additional property that anyone can verify that the PRF value at a given point is computed
Page  581: VRF security is defined using two experiments, analogous to the characterization of a PRF given
Page  581: in Exercise 4.7. In both experiments, the challenger generates (pk , sk ) using G, and gives pk to the
Page  581: (b) Given a secure VRF (G, F, V ) defined over (X , Y), where |Y| is super-poly, show how to
Page  581: (r, c), without revealing anything else. Simply give the verifier the proof ⇡ that m c is the value
Page  582: tion like RSA. In this chapter we return to more basic primitives, and construct signature schemes
Page  582: attacks, as explained in Section 17.5. The post-quantum security of hash-based signatures drives
Page  583: Hence, just given pk , the adversary cannot forge a signature on either one of the two messages
Page  584: of a more general system. Alternatively, one can view this v-bit system as v independent instances
Page  585: • S 0 (sk , M ): given M 2 M as input, do:
Page  585: • V 0 pk , M, (r,     0 ) : given M 2 M and (r,       0 ) as input, do:
Page  585: Post-quantum security. In Section 4.3.4 we discussed quantum exhaustive search attacks.
Page  585: hashing the given message using a collision resistant function or an enhanced TCR. The general
Page  586: on m also gives a signature on m0 . Hence, for security we must insist that it be difficult for the
Page  586: Containment free functions are easy to build: take P to be an injective function that always
Page  586: The following theorem shows that every containment free P gives a secure one-time signature
Page  587: The repeated one-way game starts with the repeated one-way challenger C giving B a list of n
Page  587: give q-time signatures for small q. The only di↵erence is that the function P must satisfy a stronger
Page  587: The function is clearly injective: if Popt (m0 ) = Popt (m1 ) then m0 = m1 . The following lemma
Page  588: Proof. Let m0 , m1 be distinct messages and let c0 , c1 be the checksums for m0 , m1 respectively
Page  588: Hash chains. Let f : X ! X be a function. For a non-negative integer j we let f (j) (x) denote
Page  589: The secret key sk is used to derive x1 , . . . , x9 2 X . The public key pk is the hash of y1 , . . . , y9 2 X .
Page  590: scheme is equivalent to the Lamport framework.
Page  590: to forge signatures: given a signature on m the adversary can compute everything needed for a
Page  590: signature on m0 . For example, the signature on the message m in Fig. 14.3 can be used to derive
Page  590: messages m and m0 such that P (m0 ) dominates P (m). This motivates the following definition:
Page  590: Attack Game 14.1 (One-way on d iterates). For a given function f : X ! X and a given
Page  591: Taking, for example, d = 15 gives n ⇡ (v/4) + 1. Since a Winternitz signature contains n elements
Page  591: When d + 1 is a power of two this is done by simply partitioning m 2 {0, 1}v into consecutive blocks
Page  592: When d = 1 this function is equivalent to the function Popt . The following lemma shows that it is
Page  592: Proof. Let m0 , m1 be distinct messages and let c0 , c1 be the checksums for m0 , m1 respectively,
Page  592: as defined in algorithm P . Because P is injective, P (m0 ) 6= P (m1 ). Suppose P (m1 ) dominates
Page  592: Suppose we had an injective and efficiently computable function Phors : {0, 1}v ! Sets[n, `] for some
Page  592: large parameters n and `. Exercise 14.4 gives another approach.
Page  592: Concrete parameters. Because the function Phors is injective, it must be the case that its range
Page  593: of shaded nodes. The secret key sk is a short PRF key from which x1 , . . . , x16 2 X are derived.
Page  593: Merkle tree and sets the public-key pk to be the root of the Merkle tree after iteratively hashing
Page  593: signatures for small q. Exercise 14.6 shows how HORST gives an efficient q-time signature scheme.
Page  594: Their speed makes them useful for several applications. We give two examples here.
Page  594: given we quickly output a signature on m. We call this the online phase. Our goal is minimize
Page  594: message m is given, we quickly sign m using the one-time signature. Thus, the online signing work
Page  594: special token that is sent to the user’s web browser. This signed token then gives the user access
Page  595: Recipients want to play the packets as they are received. One option is for the radio station
Page  595: single expensive RSA signature over many packets.
Page  595: sender or the receiver is needed.
Page  596: Any one-time signature gives a q-indexed signature. Let S1 = (G1 , S1 , V1 ) be a one-time signa-
Page  596: ture. The derived q-indexed signature S = (G, S, V ) works by generating q one-time public/private
Page  597: can each sign two messages giving a total of four messages that can be signed. For example, the
Page  597: generated by Gq () and lives at the root of the tree. The secret key is sk 0 . To sign a message m do:
Page  597: 2. Next, generate two public/private key pairs (pk 1 , sk 1 ) and (pk 2 , sk 2 ) using Gq () for internal
Page  598: generates a public/private key pair for an internal node, that same key pair is used for all future
Page  598: a leaf to sign two distinct messages would completely compromise security of the q-indexed private
Page  599: The output of F will be used as the random bits given to algorithm Gq . Therefore, we need w
Page  599: specified, algorithm Gq (r) is deterministic. The PRF F assigns a public/private key pair to every
Page  599: the same message twice with the same private key always results in the same signature. This
Page  599: q-indexed signature. Then the derived Merkle signature SMerkle is a secure signature.
Page  599: We construct adversary B to break Sq using a basic “plug-and-pray” argument. B is given a Sq
Page  599: public-key pk and its goal is to forge a pk signature. It starts by generating ` = Qd public/private
Page  600: pk . Now B knows the private keys for all ` instances of Sq except for one. It has a signing oracle
Page  600: from v to the root of the tree. Similarly, for each of the Q signatures given to A, visualize the
Page  601: space N . The system remains secure as long as algorithm S is never activated twice using the
Page  601: multiple entities can issue signatures for a particular private key. For example, a heavily loaded
Page  601: using the authority’s private key. A nonce-based signature in these settings would be harder to use
Page  602: This gives much shorter signatures than in the stateless scheme where we needed q d to be much
Page  603: algorithm G generates public-keys in some set X . We show a generic transformation that gives a
Page  603: resistance: namely, given (pk , sk ) as generated by G, it is hard find pk ⇤ 6= pk such that
Page  603: of these keys, an adversary can forge the signature for one of the given public keys with
Page  603: probability 1/2. This gives the adversary advantage 1/2 in winning the multi-key security
Page  603: 14.3 (An injective mapping to `-size subsets). Recall that Sets[n, `] is the set of all `-size
Page  603: subsets of {1, . . . , n}. In Section 14.4 we needed an injective mapping Phors : {0, 1}v ! Sets[n, `]
Page  603: In fact, it injectively maps any integer in 0, ` to an element of Sets[n, `].
Page  604: Prove that the function computed by this algorithm always outputs a set in Sets[n, `] and is injective.
Page  604: a single value, namely n` 11 , and quickly derive from it the n binomial coefficients needed for a
Page  604: multiplication and one integer division per iteration.
Page  604: 14.4 (Another injective mapping to `-size subsets). Let us see another injective function
Page  605: ` / ` . Therefore, for a given q, one can choose
Page  605: gives is a strongly secure one-time signature scheme in the sense of Definition 14.2, assuming the
Page  605: the Winternitz construction in Section 14.3 gives a strongly secure one-time signature, under an
Page  606: • Given a secret key sk = (↵, , ↵t ,          t   ) 2 Z4q and a message m 2 Zq , the signing algorithm S
Page  606: • Given a public-key pk = (u, ut ) 2 G2 , a message m 2 Zq , and a signature                    = (↵z ,     z   ) 2 Z2q ,
Page  606: tations (relative to g and h) of the same group element, and hence can be used to solve the
Page  606: (c) Show that (G, S, V ) is not two-time secure: given signatures on two distinct messages m0 and
Page  606: are relatively short and signing is fast. In this exercise we show an even better approach. Let G be
Page  607: tions. Consider the following generalization of Attack Game 13.3 for given parameters n and d and
Page  607: • Eventually, A outputs (a, b, x), where a, b are positive integers and x 2 X .
Page  607: Discussion: This means that inverting f (d) by exhaustive search takes about a factor of (d + 1)/2
Page  607: the overall time to invert f (d) by exhaustive search is about the same as the time to invert f .
Page  607: Exercise 14.16 gives a better algorithm for inverting f (d) .
Page  607: Let f  (d) be its d-th iterate, for some 0 < d < N / log2 N . Give an algorithm A that makes Q
Page  608: every leaf 1  i  q there is a set of log2 q nodes in the Merkle tree that authenticate leaf i relative
Page  609: in a finite cyclic group G. Our primary example for the group G was the multiplicative group (or
Page  609: the multiplicative group of a finite field extension, the class group of a number field, and various
Page  609: beyond what can be built in the multiplicative group of the integers modulo a prime. Some exam-
Page  610: Diophantus, a greek mathematician who lived in Alexandria in the third century AD. Diophantus
Page  610: was interested in the following problem: given a bivariate polynomial equation, f (x, y) = 0, find
Page  610: called the Arithmetica, of which six survived. Fourteen centuries later, Fermat scribbled his famous
Page  610: equivalent to the following question: find rational points (x, y) 2 Q2 satisfying the equation
Page  610: He proceeded to derive new rational points from the six he already had. Here is one way to do
Page  610: three points. To see why, observe that if we substitute 3x for y in (15.1) we obtain the univariate
Page  611: This technique for building rational points is called the cord method. It is quite general: given
Page  611: this to the points P and R gives two new points ( 56          3          56
Page  611: R = (9, 27). Defining addition as in (15.2) makes this operation associative, when it is well
Page  611: defined. Recall that associativity means that (U V ) W = U (V W ).
Page  611: to build a new rational point from a given rational point (x1 , y1 ), when y1 6= 0. As we will see, it
Page  611: E defined over Fp is given by an equation
Page  612: on the points of an elliptic curve. The group operation is written additively using the symbol “ ”
Page  612: infinity. Every point O 6= P = (x1 , y1 ) 2 E(Fpe ) has an additive inverse, namely P = (x1 , y1 ).
Page  612: Finally, it can be shown that this addition law is associative. The group law is clearly commutative,
Page  612: more generally, ↵P := (↵ 1)P P for any positive integer ↵. Note that ↵P can be computed
Page  613: equivalent ways of describing an elliptic curve and some are better suited for computation than the
Page  613: Weierstrass form. We give two examples.
Page  613: Montgomery curve, |E(Fpe )|, is always divisible by four. Exercise 15.4 explores the computational
Page  613: number of points on an Edwards curve, |E(Fpe )|, is always divisible by four.
Page  613: E(Fpe ) is the problem of computing ↵ given a pair of points P and ↵P as input, for a random ↵ in
Page  613: • Suppose there is a small integer ⌧ > 0 such that |E(Fp )| divides p⌧ 1. Then discrete-log on
Page  615: One system that operates this way is the oblivious PRF in Exercise 11.3. Before responding, Bob
Page  615: had better check that the given point P is in E(Fp ); otherwise, the response that Bob sends back
Page  615: never sent. In this case, checking that the given x1 2 Fp is valid requires a full exponentiation to
Page  615: expensive check. Then an attacker could send Bob an x1 2 Fp that is the x-coordinate of a point
Page  615: The curve P256 was not designed to be twist secure. The size p         of its twist is divisible by
Page  616: The smallest positive choices for A are 358990, 464586, and 486662. I rejected A =
Page  617: In Remark 12.1 we stressed that algorithm D must check that the given point V is in E(Fp ), which
Page  617: (a) Suppose that |E1 (Fp )| is divisible by t. Show that the adversary can learn ↵ mod t, with
Page  618: (b) Use part (a) to give an algorithm, similar to repeated squaring, for computing x↵ from x1 ,
Page  618: form is given as By 2 = x3 + Ax2 + x for some A, B 2 Fp . Work out a formula for the group law for
Page  620: identification protocol, which is one of the fundamental tools provided by cryptography. We give a
Page  620: few illustrative applications that will be used as motivation throughout the chapter.
Page  620: later use the credential to authenticate as Alice. We call this an active adversary. We aim to design
Page  620: identification protocols that ensure that even this active adversary cannot succeed.
Page  620: the adversary can play an active role while interacting with Alice. The adversary tries to steal
Page  621: The motivating examples above suggest three attack models for ID protocols, ordered from
Page  621: • Active attacks: The last two examples, a fake ATM and online banking, illustrate an active
Page  621: secure against such active attacks require interaction between the prover and verifier. They
Page  621: Active attacks also come up when Alice tries to login to a local infected computer. The malware
Page  621: mounting an active attack. Malware that steals user passwords this way is called a Trojan horse.
Page  622: communicating with Alice. The examples above, such as opening a door lock, give a few settings
Page  622: 18.1      Interactive protocols: general notions
Page  622: mean by an interactive protocol in general.
Page  622: An interactive protocol can be carried out among any number of parties, but in this text, we will
Page  622: focus almost exclusively on two-party protocols. Regardless of the number of parties, a protocol
Page  622: tocol instance runs, parties will send and receive messages, and update their local configurations.
Page  622: each party in a protocol instance in terms of an interactive protocol algorithm, which is an
Page  622: the party receives a message over the network (presumably, from one of its peers), algorithm I
Page  623: In general, a given party may run many protocols, and even several instances of the same
Page  623: quite straightforward: along with the inputs described above, an interactive protocol algorithm I
Page  624: • P is an interactive protocol algorithm called the prover, which takes as input a secret key sk ,
Page  624: • V an interactive protocol algorithm called the verifier, which takes as input a verification
Page  624: protocol, it remains to specify how the verifier checks that the given password is correct.
Page  624: verifier then simply checks that the password it receives from the prover is equal to vk . This naive
Page  624: Fortunately, we can easily avoid this problem by giving the verifier a hash of the password,
Page  624: 2. V outputs accept if the received pw satisfies H(pw ) = vk ;
Page  625: Attack Game 18.1 (Secure identification: direct attacks). For a given identification protocol
Page  625: I = (G, P, V ) and a given adversary A, the attack game runs as follows:
Page  625: necessarily following the prover’s algorithm P (indeed, A does not receive the secret key sk ).
Page  625: Note that the adversary in Attack Game 18.1 is given the verifier’s key vk . As a result, a
Page  625: naive password protocol where cleartext passwords are stored on the server does not satisfy Defi-
Page  625: Figure 18.3 summarizes the results of a study [37] conducted in 2016 that examined five million
Page  626: and in particular, a good percentage of passwords belong to a relative small dictionary of common
Page  626: Non-cryptographic defenses are fairly e↵ective at blocking these online attacks. However, a
Page  626: This gives the attacker a large list of hashed passwords, one password for each user registered with
Page  626: server. One study, for example, showed that used hard drives purchased on eBay can contain a lot
Page  627: Quantum o✏ine password attacks. To make matters worse, the exhaustive search attack in
Page  627: Put di↵erently, because 8 character passwords are insecure due to classical exhaustive search, 16
Page  627: passwords are known, and an attack phase that cracks a given hashed password vk . Our goal is
Page  628: O(|F |) once preprocessing is done. E↵ectively, this attack can expose millions of cracked passwords
Page  629: the exhaustive search approach in (18.1) is the best possible attack.
Page  629: taking |S| = 2128 is sufficient in practice. This salt is hashed along with the password to derive the
Page  629: 2. V outputs accept if the received pw satisfies H(pw , salt) = y;
Page  630: • The second strategy is to run an exhaustive password search as in (18.1) for every password
Page  630: derive the required bound on the size of S, we first define more precisely what it means to invert
Page  630: Note that the adversary A1 is given both L and the salt s. It needs to find a pre-image of y
Page  630: with salt s. The following theorem gives a bound on the time to invert a salted function H in the
Page  630: up from preprocessing we should set |S| ⌦(`). This will ensure that exhaustive search is the best
Page  631: 2. V outputs accept if the received pw satisfies H(pw , salt, p) = y for some p 2 Sp ;
Page  632: Definition 18.4. A password-based key derivation function, or PBKDF, is a function H
Page  632: password based key derivation function version 2. Let F be a PRF defined over (P, X , X ) where
Page  632: X := {0, 1}n . The derived PBKDF, denoted PBKDF2F , is defined over (P, X , X ) and works as
Page  632: where all b salts are derived from the provided salt by setting salt i        salt k bin(i). Here bin(i) is
Page  633: implementation of SHA256 is relatively compact, making it possible to pack a large number of
Page  634: practice, the function h is derived from the Salsa 20/8 permutation (Section 3.6). The difficulty d is
Page  635: is given the responses to all its queries and it then moves to the next state. This process is repeated
Page  635: for some positive integer p, and operates as follows:
Page  635: We record the data given to A in step i as st i := (si , z̄i ). We call st i the input state at time i.
Page  635: Definition 18.5. Let A be a parallel random oracle algorithm taking inputs in X . The cumulative
Page  635: where X = {0, 1}n , has cumulative memory complexity of O(nd2 ). The following theorem shows
Page  635: cumulative memory complexity of A must be ⌦(d2 n) for almost all choices of h. This shows that
Page  636: must be ⌦(d↵). Otherwise its cumulative memory complexity would violate the lower bound.
Page  636: again, its cumulative memory complexity would violate the lower bound.
Page  636: with probability close to 1, then the cumulative memory complexity of A must be ⌦(d2 np). This
Page  636: 18.4.4.1    Password oblivious memory-hard functions
Page  636: with Scrypt. Suppose the adversary gains low-privilege access to this server; the adversary can
Page  636: page was read when Step (5) was first executed. This gives the adversary an approximate value ja
Page  637: the salt is not secret. Such functions are called data-oblivious memory-hard functions. An
Page  638: Attack Game 18.2 (Secure identification: eavesdropping attack). For a given identification
Page  638: protocol I = (G, P, V ) and a given adversary A, the attack game runs as follows:
Page  639: Keeping vk secret. The adversary in Attack Game 18.2 is given the verification key vk , meaning
Page  639: we present requires the verifier to keep vk secret. This motivates a weaker version of Attack
Page  639: definition of security rules out some trivially insecure protocols, as discussed in Exercise 18.10. We
Page  640: • Algorithm P given sk , and algorithm V given vk , interact as follows:
Page  640: 2. V vk = (k, i) : if the received r from P satisfies r = F (k, i) output accept and
Page  640: and sends the derived one-time password to the car, along with the counter i. The car maintains
Page  641: its own counter and verifies the received one-time password and counter value. Note that the car
Page  641: given a security token that looks something like the token in Fig. 18.8a and displays a 6-digit one-
Page  642: key at token setup time and uses that key to derive the 6-digit one-time passwords. The server
Page  642: • Algorithm P given sk , and algorithm V given vk , interact as follows:
Page  642: 2. V (vk ): if the received t from P satisfies vk = H(t) output accept
Page  642: Definition 14.5. To review, this means that for all j = 1, . . . , n, given y    H (j) (k) as input,
Page  643: 18.6     Challenge-response: security against active attacks
Page  643: We now consider a more powerful attack in which the adversary actively impersonates a legitimate
Page  643: We say that the ID protocol is secure against active attacks if the adversary still cannot fool the
Page  643: active attacks. By impersonating a verifier, the adversary will learn a fresh one-time password
Page  644: Figure 18.10: An example active attack as in Attack Game 18.3
Page  644: reflection shows that no single flow protocol is secure against active attacks.
Page  644: We first define active attacks and then construct simple a two flow protocol that is secure against
Page  644: active attacks. For simplicity, in this section we only consider protocols where both the prover and
Page  644: Attack Game 18.3 (Secure identification: active attacks). For a given identification proto-
Page  644: col I = (G, P, V ) and a given adversary A, the attack game, shown in Fig. 18.10, runs as follows:
Page  644: • Active probing phase. The adversary requests to interact with the prover. The challenger
Page  644: Definition 18.8. We say that an identification protocol I is secure against active attacks if for all
Page  645: Concurrent vs sequential attacks. Note that in the active probing phase of the attack game,
Page  645: secret. This motivates a weaker version of Attack Game 18.3 where the challenger does not send
Page  645: about vk . Therefore, in the active probing phase, we allow the adversary to interact concurrently
Page  645: Definition 18.9. We say that an identification protocol I is weakly secure against active
Page  645: We present two (stateless) ID protocols, called challenge-response, that are secure against active
Page  646: • Algorithm P given sk = k, and algorithm V given vk = k, interact as follows:
Page  646: is super-poly. Then ID protocol ChalRespmac is weakly secure against active attacks.
Page  646: the probability that the adversary receives a challenge message that it has seen before (in a previous
Page  646: Case study: CRYPTOCard. Fig. 18.12 gives an example of a Challenge-Response token.
Page  646: is sent to the server to complete the protocol. The MAC is implemented as a PRF derived from
Page  646: be convenient to deploy this protocol where the key k is derived from a user generated password
Page  646: pw as k     H(pw ) where H is a key derivation function as in Section 8.10.
Page  646: This can be quite dangerous. If pw is a weak password, belonging to some relatively small
Page  647: |M|, is super-poly. Then ChalRespsig is secure against active attacks.
Page  647: Let pw R P and let y    h(pw ). Clearly an exhaustive search over all of P will find a preimage
Page  647: probability close to 1. This is much faster than exhaustive search over P.
Page  648: it gives t ⇡ N 2 . This is much worse than simple exhaustive search that only takes time N . It
Page  648: positive constants ⌧ and `. Recall that for ⌧ > 0 the function f (⌧ ) is the ⌧ -th iterate of f as defined
Page  649: as shown in the figure. Once we find the end of that chain, the table L would give its starting
Page  649: point pwf . The the traversal on line (4) would then give an inverse of y. The total running time to
Page  650: trivially invert h in constant time.
Page  651: Squaring both sides gives `2 ⇥ t N 2 /2, which is the time-space tradeo↵ promised in (18.9). Note
Page  651: due to Fiat and Naor [46] gives a time-space tradeo↵ for inverting an arbitrary function h : P ! Y.
Page  652: one pair for each side. Each participant is given the peer’s verification key. The participants then
Page  652: (a) Security against direct attacks is defined using an attack game where the adversary is given
Page  652: cessfully complete the protocol by playing the role of the other side. Give a precise security
Page  652: (c) Define an attack game that captures active attacks, similar to Attack Game 18.3, but applies
Page  652: • The adversary A sends to the challenger a positive difficulty d 2 Z. The challenger chooses a
Page  654: let N := |X |. For a given `, construct an adversary A = (A0 , A1 ) where A0 preprocesses ⇡ and
Page  654: Discussion: Your solution gives a time-space tradeo↵ satisfying ` ⇥ t N for inverting a random
Page  654: permutation and let ⇡ (d) be its d-th iterate, for some d > 0. Let N := |X |. Give an algorithm that
Page  654: secure against eavesdropping (and even secure against active attacks) if the adversary can only
Page  654: • Algorithm P given sk , and algorithm V given vk , interact as follows:
Page  655: 18.11 (Why interact with the verifier for active security). In this exercise we show that
Page  655: when vk is kept secret, it is necessary to allow an active adversary in Attack Game 18.3 to interact
Page  655: cannot interact with the verifier during the probing phase, but is trivially insecure otherwise. The
Page  655: • Algorithm P given sk , and algorithm V given vk , interact as follows:
Page  655: (a) Show that this ID protocol is (weakly) secure against an active adversary playing Attack
Page  655: (b) Show that the protocol is insecure against an active adversary playing Attack Game 18.9
Page  655: • Algorithm P given sk , and algorithm V given vk , interact as follows:
Page  656: Show that this protocol is secure against active attacks, assuming that the nonce space R is super-
Page  656: poly, and the encryption scheme is non-adaptive CCA secure, as defined in Exercise 12.27.
Page  656: Discussion: This scheme is an attractive option for login to a remote web site (the verifier) from
Page  656: see why non-adaptive CCA is necessary for security. Give an example public-key system (G0 , E, D)
Page  656: is not secure against active attacks.
Page  656: • Algorithm P given sk , and algorithm V given vk , interact as follows:
Page  656: Show that this protocol provides weak security against active attacks (Definition 18.9), assuming
Page  656: password h      H(pw ). We treat the hashed password h as a string of bytes. Given a password pw 0
Page  658: scheme that provided the highest level of security, namely, security against active attacks (Defini-
Page  658: eavesdropping attacks. Instead, Schnorr’s protocol is a cleverly designed interactive protocol that
Page  660: Intuitively, if A can generate a valid response to one such random challenge with probability ✏, it
Page  660: given verification key u and with matching first flows ut . Moreover, with overwhelming probability,
Page  660: we have c0 6= c (this is where the assumption that C is super-poly comes in). Given this information,
Page  660: Dividing the first equation by the second, the ut ’s cancel, and we have
Page  661: representations (relative to g and u) of ut , and Fact 10.3 tells us how to compute Dlogg u from these
Page  661: This theorem is qualitatively di↵erent than all of the other security theorems we have presented
Page  661: to basically run A twice. In addition, this theorem is quantitatively di↵erent as well, in that the
Page  662: DL adversary B, with advantage ✏0 , as follows. Adversary B is given an instance u = g ↵ of the
Page  662: In the first stage of its computation, B plays the role of challenger to A, giving A the value u
Page  663: could have efficiently generated these conversations by himself, given vk (but not sk ). If we can
Page  663: not some arbitrary, “dishonest” verifier, such as may arise in an active attack on the identification
Page  664: the messages of the conversation in the given order, as in a real conversation between P and V .
Page  664: over C and ↵z uniformly distributed over Zq ; moreover, given c and ↵z , the value ut is uniquely
Page  665: At first blush, our results about Schnorr’s protocol may seem counter-intuitive, or perhaps even
Page  665: carrying out an impersonation attack, the verifier V is actively involved in the conversation, and
Page  665: Thus, it is trivial to break Schnorr’s identification protocol with advantage 1/|C|; therefore, the
Page  665: It is an open question as to whether Schnorr’s identification protocol is secure against active
Page  665: attacks as in Attack Game 18.3: there are no known e↵ective, active attacks, but there is also no
Page  665: a slight variation on Schnorr’s identification that can be proven secure against active attacks under
Page  665: protocol, and the challenge c is computed as c          H(m, ut ). Intuitively, the hash function H is
Page  666: for either direct, eavesdropping, or active attacks, but we shall just consider eavesdropping attacks
Page  666: Attack Game 19.1 (r-impersonation eavesdropping attack). For a given identification pro-
Page  666: tocol I = (G, P, V ), positive integer r, and adversary A, the attack game runs as follows. The key
Page  666: The following lemma shows that the r-impersonation eavesdropping attack is equivalent to the
Page  667: forges a signature, he can be e↵ectively used in an r-impersonation attack on Isch . Again, we
Page  668: implement the random oracle using an associative array Map : M ⇥ G ! C. We also maintain an
Page  668: associative array Explicit : M ⇥ G ! Z that keeps track of those points at which the random oracle
Page  668: application of the union bound gives the overall bound Qs (Qs + Qro + 1)/q on the probability that
Page  669: initialize empty associative arrays Map : M ⇥ G ! C and
Page  669: upon receiving the ith signing query mi 2 M:
Page  669: upon receiving the jth random oracle query (m
Page  669: upon receiving a forgery attempt (m, ut , ↵z ):
Page  670: initialize empty associative arrays Map : M ⇥ G ! C and
Page  670: upon receiving the ith signing query mi 2 M from A:
Page  670: upon receiving the jth random oracle query (m               bj ) 2 M ⇥ G:
Page  670: upon receiving a forgery attempt (m, ut , ↵z ):
Page  671: Game 19.1 gives to A a verification key u 2 G for Schnorr’s identification protocol. Second, the
Page  671: challenger gives to A several transcripts of conversations. Third, A enters the impersonation phase,
Page  671: challenge cj 2 C. After receiving all of these challenges, A either outputs fail or a pair (i, ↵z ) such
Page  671: We now describe our DL adversary B, which is given u 2 G, and is tasked to compute Dlogg u.
Page  671: As usual, B plays the role of challenger to A. First, B gives u to A as the verification key. Second,
Page  671: B generates transcripts of conversations, using the simulator from Theorem 19.4, and gives these
Page  673: Schnorr signature is equivalent to forging a regular Schnorr signature. As a further optimization,
Page  674: Exercise 19.12), the ECDSA scheme is not. Given an ECDSA signature = (r, s) on a message m,
Page  674: heuristic) are secure against active attacks. Recall that for Schnorr’s identification protocol
Page  674: Consider again Schnorr’s identification protocol. Intuitively, that protocol allows a prover P to
Page  674: Definition 19.2 (E↵ective relation). An e↵ective relation is a binary relation R ✓ X ⇥ Y,
Page  674: Definition 19.3 (Sigma protocol). Let R ✓ X ⇥ Y be an e↵ective relation. A Sigma protocol
Page  675: • P is an interactive protocol algorithm called the prover, which takes as input a witness-
Page  675: • V an interactive protocol algorithm called the verifier, which takes as input a statement
Page  675: – Upon receiving P ’s commitment t, V chooses a challenge c at random from a finite
Page  675: – Upon receiving V ’s challenge c, P computes a response z, and sends z to V ;
Page  675: – Upon receiving P ’s response z, V outputs either accept or reject, which must be computed
Page  676: (which includes its order q and the generator g 2 G). In general, we allow e↵ective relations that
Page  676: (called a witness extractor) with the following property: given as input a statement y 2 Y, along
Page  677: Let (P, V ) be a Sigma protocol for R ✓ X ⇥ Y. Intuitively, what we want to say is that for
Page  677: skeptical verifier that it “knows” the discrete logarithm of a given group element, without revealing
Page  678: representation of u (relative to g and h) is a pair (↵, ) 2 Z2q such that g ↵ h = u.
Page  678: tation of a given u 2 G, without revealing anything about that representation to the verifier. More
Page  679: and dividing the first equation by the second, the ut ’s cancel, and we have
Page  679: Zq ; moreover, given c, ↵z , and z , the value ut is uniquely determined by the equation
Page  680: The Chaum-Pedersen protocol allows a prover to convince a skeptical verifier that a given triple is
Page  680: that for ↵, , 2 Zq , we say that (g ↵ , g , g ) is a DH-triple if = ↵ . Equivalently, (u, v, w) is a
Page  680: The Chaum-Pedersen protocol (P, V ) is given in Fig. 19.7. The challenge space C is a subset of
Page  681: moreover, given c and z , the values vt and wt are uniquely determined by the equations
Page  681: The generic linear protocol (P, V ) for such a relation R is given in Fig. 19.8. The prover
Page  683: described succinctly using matrix notation. Let us write the group operation in G additively. That
Page  683: the map that sends x 2 Z⇤n to y = xe 2 Z⇤n is bijective. Therefore, every statement has a unique
Page  683: The GQ protocol (P, V ) is given in Fig. 19.10. The challenge space C is a subset of {0, . . . , e 1}.
Page  684: Dividing the first equation by the second, we obtain
Page  684: with c uniformly distributed over C and xz uniformly distributed over Z⇤n ; moreover, given c and
Page  684: erty: given a public key pk = y 2 Y output by G, it should be hard to compute x̂ 2 X such that
Page  685: R ✓ X ⇥ Y. For a given adversary A, the attack game runs as follows:
Page  685: A Sigma protocol (P, V ) with a key generation algorithm G gives an identification scheme
Page  685: Theorem 19.13. Let (P, V ) be a Sigma protocol for an e↵ective relation R with a large challenge
Page  685: build an adversary B that breaks the one-wayness of G, as follows. Adversary B is given a public
Page  685: In the first stage of its computation, B plays the role of challenger to A, giving A the value
Page  685: (t, c0 , z 0 ) for y with c 6= c0 . In more detail, B awaits A’s commitment t, gives A a random challenge
Page  685: just after which it generated t, gives A another random challenge c0 , and awaits A’s response z 0 .
Page  686: Theorem 19.3 obviously applies to identification protocols derived from special HVZK Sigma
Page  686: Theorem 19.14. Let (P, V ) be a Sigma protocol for an e↵ective relation R. Let G be a key
Page  686: The Fiat-Shamir signature scheme derived from G and (P, V ) works as follows:
Page  687: Shamir signature scheme S derived from G and (P, V ) is secure.
Page  687: G, the Fiat-Shamir signature construction gives us a secure signature scheme (that is, if we model
Page  688: gives us a new signature scheme based on RSA. The scheme makes use of an RSA public key (n, e)
Page  689: In other words, for a given pair of statements y0 2 Y0 and y1 2 Y1 , this AND protocol allows a
Page  690: • Both protocols are special HVZK, with simulators Sim 0 and Sim 1 , respectively.
Page  690: In other words, for a given pair of statements y0 2 Y0 and y1 2 Y1 , this OR protocol allows a
Page  691: For a given statement there may be several witnesses. Roughly speaking, witness independence
Page  691: witness will be unrelated to P ’s witness. Of course, this property is only interesting if a given
Page  691: identification protocols that are secure against active attacks, rather than just eavesdropping at-
Page  692: Y. For a given adversary A, we define an experiment (x, y) for each (x, y) 2 R. Experiment (x, y)
Page  692: • Initially, the adversary is given the value y.
Page  693: One can rewrite (19.24) in a number of di↵erent ways. For example, it is equivalent to saying
Page  694: 19.8.3     Actively secure identification protocols
Page  694: As promised, we now show how to use witness independence to design actively secure identification
Page  694: additional assumptions, we can build an identification scheme that is secure against active attacks
Page  695: We now prove that the identification protocol I 0 := (G0 , P 0 , V 0 ) is secure against active attacks.
Page  695: Theorem 19.21. Let (P, V ) be a Sigma protocol for an e↵ective relation R with a large challenge
Page  695: scheme I 0 := (G0 , P 0 , V 0 ) defined above is secure against active attacks.
Page  695: In particular, suppose A is an impersonation adversary attacking I 0 via an active attack as in
Page  695: Proof. Let us begin by reviewing how an active impersonation attack against (P 0 , V 0 ) works. There
Page  695: Active probing phase. The adversary interacts with the prover P 0 (sk 0 ). Here, the challenger
Page  695: with, B’s challenger computes (y ⇤ , (x⇤ , y ⇤ )) R G() and gives y ⇤ to B. The goal of B is to compute
Page  696: challenger (as verifier) gave A its random challenge, and gives to A a fresh random challenge. If
Page  696: that the active probing phase reveals nothing more about the type of X to A. Therefore, for any
Page  696: Concrete instantiations. The above construction immediately gives us two concrete identifica-
Page  696: tion protocols that are secure against active attacks. One, derived from Schnorr, whose security is
Page  696: based on the DL assumption, and the other, derived from GQ, whose security is based from the
Page  696: RSA assumption. These two actively secure protocols are roughly twice as expensive (in terms of
Page  696: We just saw how to build an identification protocol whose security against active attacks is based
Page  697: Zq , and outputs pk = u and sk = ((↵, ), u) where u := g ↵ h 2 G. This gives us the
Page  697: the concept of witness independence, it is not hard to show that IO is secure against active attacks.
Page  697: Then IO is secure against active attacks, assuming the DL assumption holds for G.
Page  697: In particular, suppose A is an impersonation adversary attacking IO via an active attack as in
Page  697: Suppose A has advantage ✏ in attacking IO in Attack Game 18.3. Our DL adversary B receives
Page  697: Active probing phase. A interacts (possibly concurrently) with several instances of the prover
Page  697: verifier gave A its random challenge, and gives to A a new, random challenge. If this results in
Page  697: ↵, ˆ), then we have two distinct representations (relative
Page  697: witnesses for u that B is using, and witness independence says that the active probing phase reveals
Page  698: dependent values for ↵t in consecutively issued signatures. In particular, when signing a message m0
Page  698: Discussion: This attack illustrates why it is important to derandomize signature schemes derived
Page  698: positive integer. Define a new Sigma protocol (P k , V k ) as follows. Here, the prover P k takes as
Page  699: prover P̂ that is initialized with a statement y 2 Y (but is not given the corresponding witness
Page  699: that is only given u = g ↵ 2 Z⇤n (but is not given ↵) can fool the verifier with probability 1/q.
Page  699: b > 1. Show that a prover that is only given y = xe 2 Z⇤n (but is not given x) can fool
Page  699: Ext would give an efficient algorithm to compute an eth root of y in Z⇤n . This would violate
Page  700: rived from a Sigma protocol (P, V ) as in Section 19.6.1. Assume (P, V ) is special HVZK. Suppose
Page  701: More precisely, for a given adversary A, we define cSKSadv[A, ⇧, Ext] to be the probability
Page  702: oracle. Derive a concrete security bound as a part of your analysis.
Page  702: AND-proof and OR-proof constructions derived from (P0 , V0 ) and (P1 , V1 ) (see Section 19.7).
Page  702: signatures can be applied to Fiat-Shamir signatures derived from most Sigma protocols. Consider
Page  702: the Fiat-Shamir signature scheme derived from a Sigma protocol (P, V ) for a relation R ✓ X ⇥ Y,
Page  702: f : Y ⇥ C ⇥ Z ! T be the corresponding function that computes a commitment from a given
Page  702: commitment from a given statement, challenge, and response. Also assume that (P, V ) provides
Page  703: For (c, z) 2 C ⇥ Z, and a given system parameter y 2 Y, we define H(c, z) := f (y, c, z) 2 T .
Page  703: design actively secure identification protocols. This exercise generalizes these results, establishing
Page  703: more general conditions under which a Sigma-protocol based ID scheme can be proved actively
Page  703: that G is second-preimage resistant (relative to the function type) if it is hard for any efficient
Page  703: This is equivalent to saying that Y and type(X) are independent, with type(X) uniformly distributed
Page  703: the identification protocol (G, P, V ) is secure against active attacks.
Page  703: (G, P, V ) is secure against active attacks, under the RSA assumption.
Page  704: 19.17 (Public-key equivalence). We can use the notion of witness independence to simplify
Page  704: algorithms for R. We say that these two algorithms are public-key equivalent if the public keys
Page  704: Show that if (P, V ) is witness independent and G0 and G1 are public-key equivalent, then the
Page  704: active attacks.
Page  704: for R, and that the identification protocol (G, P, V ) is secure against active attacks. Further,
Page  704: suppose that G0 is a key generation algorithm that is public-key equivalent to G, as in the
Page  704: active attacks, in the sense that any impersonation adversary that breaks the security of
Page  704: identification protocol (G00 , P 0 , V 0 ) is just as secure against active attacks.
Page  704: protocol (G0 , P, V ) is just as secure against active attacks. Describe the resulting scheme in
Page  704: resulting identification protocol (G0 , P, V ) is just as secure against active attacks. Describe
Page  704: • Given a secret key sk ⇤ as above, and a message c 2 C, the signing algorithm S ⇤ feeds c to the
Page  705: • Given a public key pk ⇤ = (y, t) 2 Y ⇥ T , a message c 2 C, and a signature z 2 Z, the
Page  705: and is special HVZK. Further, assume that G0 is public-key equivalent (see Exercise 19.17) to
Page  705: convince a verifier that he knows a witness for one of two given statements. In this exercise,
Page  705: witnesses for n given statements.
Page  706: Suppose the prover P 0 is given the witness (x1 , . . . , xn ) and the statement (y1 , . . . , yn ), and the
Page  706: verifier V 0 is given the statement (y1 , . . . , yn ). Let I denote the set of indices i such that (xi , yi ) 2 R.
Page  706: operation in the group Z⇤n is written multiplicatively. For two vectors v, w 2 (Z⇤n )1⇥` , we write
Page  707: property of these associated matrices is the following: given two distinct challenges c and c0 in C,
Page  708: and knowledge soundness, we could e↵ectively extract a witness from any convincing prover.
Page  708: Pedersen protocol (Section 19.5.2) allows a prover to convince a verifier that a given triple of
Page  708: In Section 20.1, we begin by defining the language of true statements associated with an e↵ective
Page  708: In Section 20.3, we show how to turn Sigma protocols into non-interactive proofs, using a variant
Page  708: Definition 20.1 (The language of true statements). Let R ✓ X ⇥ Y be an e↵ective relation.
Page  708: of interesting relations R and the languages LR defined by them. To give an example from the
Page  709: X ⇥ Y. For a given adversary A, the attack game runs as follows:
Page  709: • The adversary chooses a statement y 2 Y and gives this to the challenger.
Page  710: Section 19.6.1 to turn interactive identification protocols into signatures. That is, instead of using
Page  710: In our examples, it is convenient to use the multiplicative variant of the ElGamal encryption
Page  711: for some 0 , 1 2 Zq and m 2 G. Dividing the first equation by the third, and the second by the
Page  711: need not have been the party that generated these ciphertexts. In fact, she could have received
Page  711: group element g b 2 G, and then encrypt g b using multiplicative ElGamal. So suppose Alice has
Page  711: The Chaum-Pedersen protocol in Section 19.5.2 allows a party to prove that a given triple is a
Page  711: DH-triple. We combine this with the OR-proof construction in Section 19.7.2. This gives us a
Page  711: statement ((u, v, e), (u, v, e/g)) and the witness (b, ). For completeness, we give the entire Sigma
Page  712: be used for relatively small B. We will see how to handle larger B in Section 20.4.1. 2
Page  713: So this gives us a Sigma protocol for R. To run the protocol, Alice runs the generic linear
Page  714: will see, the protocol for polynomial evaluation in Example 20.6 can be easily derived as a special
Page  714: case of this construction. This same general construction could also be used to derive protocols for
Page  715: Polynomial evaluation, again. The protocol in Example 20.6 can be derived using this trans-
Page  715: Encrypted bits, yet again. The protocol in Example 20.5 can be derived using this transfor-
Page  716: of either xj or xk using multiplicative ElGamal. Later, in Section 20.4.3, we will see how to drop
Page  716: 20.3     Non-interactive proof systems
Page  716: protocol into a non-interactive proof system.
Page  716: we use a hash function H to derive the challenge from the statement and the commitment. If we
Page  716: (i) if the Sigma protocol is existentially sound, then so is the non-interactive proof system;
Page  716: (ii) if the Sigma protocol is special HVZK, then running the non-interactive proof system does
Page  716: to the non-interactive setting. The second property is a new type of “zero knowledge” property
Page  716: Before getting into the formalities, we illustrate the utility of non-interactive proofs by showing
Page  716: as we would like to allow voters to keep their votes private. To this end, some voting protocols
Page  716: A convenient scheme to use for this purpose is the multiplicative variant of the ElGamal scheme,
Page  716: Here is an initial attempt at a voting protocol that provides some privacy to the voters.
Page  717: If all the voters and the VTC correctly follow the protocol, then, at least intuitively, the semantic
Page  717: corrupt, both the correctness of the election result and the privacy of the votes may be compromised.
Page  717: equivalent to casting 100 1-votes, which would allow the voter to unfairly influence the outcome of
Page  718: To verify such a proof, one derives the values vt0 , wt0 , vt1 , wt1 from the verification equations (com-
Page  718: 20.3.2     Non-interactive proofs: basic syntax
Page  718: We now get down to the business of defining non-interactive proofs in general, their security prop-
Page  718: We begin by defining the basic syntax of a non-interactive proof.
Page  718: Definition 20.3 (Non-interactive proof system). Let R ✓ X ⇥ Y be an e↵ective relation. A
Page  718: non-interactive proof system for R is a pair of algorithms (Gen, Check ), where:
Page  718: interactive proof system.
Page  718: Fiat-Shamir non-interactive proof system FS-⇧ = (Gen, Check ), with proof space PS = T ⇥ Z, as
Page  719: 20.3.4    Non-interactive existential soundness
Page  719: We next adapt our definition of existential soundness to the non-interactive setting. Essentially,
Page  719: Attack Game 20.2 (Non-interactive Existential Soundness). Let = (Gen, Check ) be a
Page  719: non-interactive proof system for R ✓ X ⇥ Y with proof space PS. To attack , an adversary A
Page  719: tentially sound non-interactive proof system, if we model the hash function as a random oracle.
Page  719: Shamir non-interactive proof system derived from ⇧ with hash function H. If ⇧ is existentially
Page  719: 20.3.5    Non-interactive zero knowledge
Page  719: Let = (Gen, Check ) be a non-interactive proof system for a relation R ✓ X ⇥ Y with proof space
Page  719: PS. We wish to define a useful notion of “zero knowledge”. Intuitively, we want this notion to
Page  720: to make this idea work without giving the simulator some kind of “insider advantage”. Indeed,
Page  720: We shall only attempt to formulate non-interactive zero knowledge in the random oracle model,
Page  720: and the “insider advantage” that we give to our simulator is that it is allowed to simultaneously
Page  720: random oracle. A simulator for         is an interactive machine Sim 1 that responds to a series of
Page  720: Our definition of non-interactive zero knowledge (niZK) says that an efficient adversary cannot
Page  720: Attack Game 20.3 (Non-interactive zero knowledge). Let                = (Gen, Check ) be a non-
Page  720: interactive proof system for a relation R ✓ X ⇥ Y with proof space PS. Suppose that makes use
Page  720: as above. For a given adversary A, we define two experiments, Experiment 0 and Experiment 1.
Page  721: initialize an empty associative array Map : Y ⇥ T ! C;
Page  721: upon receiving the ith unjustified proof query yi 2 Y:
Page  721: upon receiving the jth random oracle query (b   yj , b
Page  721: Definition 20.5. We say     provides non-interactive zero knowledge (niZK) in the ran-
Page  721: unpredictable commitments, and let FS-⇧ be the Fiat-Shamir non-interactive proof system derived
Page  721: signature scheme in Theorem 19.7. Our niZK simulator is given in Fig. 20.2. Here, we assume
Page  721: get an efficient Sigma protocol. We will motivate and illustrate the idea with an example.
Page  722: We again use the multiplicative ElGamal encryption scheme that we used in the examples in
Page  723: sense that the encryptions of the bits of x could conceivably leak information about x to Charlie.
Page  723: Intuitively, under the DDH assumption, these encryptions should not leak any information. So the
Page  723: with challenge space C. Let Sim be a simulator for ⇧, as above. For a given adversary A, we
Page  723: • In Experiment 0, the challenger runs the protocol between P (x, y) and V (y), and gives the
Page  723: and gives the simulated conversation (t, c, z) to A.
Page  724: concrete security bound degrades with an extra additive term of Qp · cHVZKadv[B, ⇧, Sim 1 ],
Page  724: verifier are both given , and the prover is also given an assignment (↵1 , . . . , ↵n ) to the variables
Page  725: Given these auxiliary group elements, the verifier can reconstruct the formula 0 , and now both
Page  725: Range proofs, again. It is easy to see that our range proof protocol can be derived using this
Page  725: 20.6        Succinct non-interactive zero-knowledge proofs (SNARKs)
Page  726: ing properties on encrypted data, as in Section 20.2, using the multiplicative ElGamal encryption
Page  726: foil traffic analysis. In this setting, Alice receives two ciphertexts (v0 , e0 ) and (v1 , e1 ), which encrypt
Page  726: More precisely, for a given adversary A, we define cSSadv[A, ⇧] to be the probability that A
Page  727: alternative Sigma protocol for the relation R defined in (20.10). This new Sigma protocol is uncon-
Page  727: to generalize the encrypted bits protocol from Example 20.3 to give an existentially sound, special
Page  727: Alternatively, you could trade computational zero knowledge for computational soundness, as in
Page  728: Sigma protocol for this problem (or alternatively, you can trade computational zero knowledge for
Page  728: proving to Charlie that 0 = f ( ), Alice proves that 0 = k , for some specific, large, positive integer
Page  728: alternatively, you can trade computational zero knowledge for computational soundness).
Page  728: are using the multiplicative ElGamal encryption scheme, as in Section 20.2. So Alice knows 2 Zq
Page  728: in the previous exercise. Suppose she also presents to Charlie a non-interactive proof ⇡ that the
Page  728: Section 20.3.3) derived from the Sigma protocol of the previous exercise.
Page  728: (b) Using the soundness property of the Fiat-Shamir non-interactive proof system, argue that
Page  728: (c) Using the zero-knowledge property of the Fiat-Shamir non-interactive proof system, argue
Page  728: into a non-interactive proof system by computing the challenge as c := H(y, t), where y is the
Page  729: Chaum-Pedersen protocol (see Section 19.5.2) into a non-interactive proof by deriving the challenge
Page  729: from the hash of the commitment only, the resulting non-interactive proof system is not sound.
Page  729: 20.14 (Optimized Fiat-Shamir proofs). We can optimize Fiat-Shamir non-interactive proof
Page  729: Fiat-Shamir proof system scheme derived from a Sigma protocol (P, V ) for a relation R ✓ X ⇥ Y.
Page  729: Y ⇥C ⇥Z ! T be the corresponding function that computes a commitment from a given statement,
Page  729: covert the Sigma protocol to a corresponding non-interactive proof system using the optimized
Page  729: space C. Let be the optimized Fiat-Shamir proof system derived from ⇧, as in Exercise 20.14,
Page  730: Exercise 13.20. Give a concrete security bound (which should be fairly tight).
Page  730: yet y 6= F (k, m). Give a concrete security bound.
Page  730: in the random oracle model. Give a concrete security bound.
Page  730: (b) Prove that S is secure in the random oracle model under the CDH assumption. Give a
Page  730: More precisely, for a given adversary A, we define cSSSadv[A, ⇧] to be the probability that A
Page  731: (a) Let    be an non-interactive proof system. Show that for every r-attempt adversary A at-
Page  731: (b) Let be the non-interactive proof derived using the Fiat-Shamir transform from a Sigma pro-
Page  731: 20.20 (Simulation soundness). This exercise develops a security notion for non-interactive
Page  731: zero knowledge (see Section 20.3.5) in a way that is perhaps a bit unintuitive, but that has a number
Page  731: Let be a non-interactive proof system for a relation R ✓ X ⇥ Y. Suppose that makes use of a
Page  731: defined in Section 20.3.5, which is an interactive machine that responds to unjustified proof queries
Page  732: Now consider the optimized version      of the non-interactive proof system obtained by applying
Page  732: m is ignored by ⇧, it is not ignored by , as it is included in the hash used to derive the challenge.
Page  733: with an extra additive term of Qk /q, also holds in the multi-key setting.
Page  733: Let us also assume that            = (Gen, Check ) is a simulation sound ZK non-interactive proof system
Page  733: is sk 0 . Given a message m, the encryption algorithm G0 computes
Page  733: vious exercise with the multiplicative ElGamal encryption scheme in Section 20.2, along with the
Page  733: optimized Fiat-Shamir non-interactive proof system derived from the Sigma protocol of Exam-
Page  733: enhance the non-interactive proof so that it not only proves that the two ciphertexts encrypt the
Page  734: and    = (Gen, Check ) is a non-interactive proof system for the relation
Page  734: optimized Fiat-Shamir construction to an appropriate Sigma protocol for R. Also, derive
Page  735: (b) Show how to make the partial decryption algorithm D robust using a non-interactive proof
Page  735: system derived by applying the Fiat-Shamir transform to an appropriate Sigma protocol. This
Page  736: packets are delivered in order and without duplicates. However, this begs the question: how do
Page  736: execution of the protocol). A secure AKE protocol should ensure that P ’s session key is e↵ectively
Page  736: be built using only symmetric key primitives, without public-key tools. In addition, key revocation
Page  736: is relatively simple with an online TTP. However, there are many disadvantages to online TTP
Page  736: Multiple user instances and freshness of keys. A given user may run an AKE protocol
Page  736: many times. We shall refer to each such run as an instance of that user. While a given user has
Page  737: sessions are e↵ectively independent of one another.
Page  740: each user verifies the certificate it receives; in addition, P verifies the signature it receives, and
Page  742: signature (see Section 19.2) are leaked, then the adversary can trivially compute the long-term
Page  742: ing sense. When P finishes the protocol, he can be confident that Q was “alive” during the run of
Page  742: not be an instance of P with a matching session key, but P may not have even been “alive” during
Page  742: To appreciate why this protocol is designed the way it is, it is instructive to consider minor variations
Page  743: message. Alternatively, if P receives the first message in the conversation, the adversary can make
Page  743: made by the customer can be read by the adversary. Obviously, such a request may contain private
Page  745: (r, Cert P ), the adversary intercepts this message, and instead delivers the message (r, Cert R )
Page  745: • when Q sends the message (c, , Cert Q ), the adversary delivers this message to P .
Page  747: assume that this is a stream cipher. With these assumptions, given a ciphertext c that encrypts
Page  747: some unknown bit string m, and given an arbitrary bit string , one can easily compute a ciphertext
Page  747: sending to P “trick” ciphertexts derived from c, as in Bleichenbacher’s attack, the attacker could
Page  748: certificates and signatures it receives.
Page  749: Forward secrecy. Intuitively, protocol AKE2 is PFS secure because user long-terms keys are used
Page  750: scheme is semantically secure. It is instructive to see why this is the case. Suppose the adversary lets
Page  750: mented, and fail to securely erase this data. Alternatively, the user’s machine could be temporarily
Page  751: f (LTS P , x). That is, given x, the HSM computes and outputs the value f (LTS P , x). During a
Page  751: can also model much stronger attacks, in which the adversary can actively probe the HSM with
Page  751: trivially obtain HSM security. However, we would prefer the interface to the HSM be as simple as
Page  752: certificates and signatures it receives.
Page  753: algorithm on a given public key and given message. Although semantic security implies that this
Page  757: be a passive observer, or even an active participant in the protocol.
Page  758: In the case where the adversary is a passive observer, and the two users running the protocol
Page  758: stations. Identity protection should prevent an adversary from tracking the location of a given
Page  758: this. However, a more aggressive adversary may try to interact with a mobile device, pretending
Page  759: somewhat, so that all of the necessary keys are derived directly from the hash function H. Again,
Page  760: construct key exchange protocols that e↵ectively allow a client and server to establish a one-
Page  760: sided authenticated secure channel. Intuitively, when the client establishes such a channel,
Page  760: he e↵ectively has a “data pipe” that connects securely to the server. For example, the client may
Page  760: safely transmit sensitive information (e.g., a credit card number) through the channel, confident
Page  760: that only the server will read this information; also, the client can be sure that any data received
Page  760: other sensitive information, can only be read by the server. Later, in a subsequent transaction with
Page  760: ID and password have been verified, the server can be (relatively) confident that this “data pipe”
Page  760: initially established a relation with the server using the given user ID.
Page  762: then P compares its computed value of k1 to the value it received from Q; if these do not
Page  762: 4. Q compares its computed value of k2 to the value it received from P ; if these do not match,
Page  762: computed in (21.1). In fact, we assume that any given user may have user instances playing both
Page  763: • While it works in the random oracle model, it does not actively manipulate the random oracle
Page  765: provides very strong privacy guarantees for the mobile device:
Page  765: need not give Q evidence that it interacted with P .
Page  766: Intuitively, our definition of security captures the idea that each instance of user should obtain a
Page  766: • The user registration algorithm, which is an interactive protocol algorithm (see Sec-
Page  766: tion 18.1) that takes as input a user ID. This algorithm specifies an interactive subprotocol
Page  766: • The session key establishment algorithm, which is an interactive protocol algorithm (see
Page  766: user registration algorithm). This algorithm specifies an interactive subprotocol that is used
Page  767: counter-intuitive, since one normally thinks of session keys as being hidden from the adversary. See
Page  767: and the given role I.role.
Page  767: Deliver protocol message: The adversary specifies a running honest user instance I along with
Page  768: Deliver TTP message: This is only used in the online TTP setting. The adversary gives a
Page  768: to the logic of the TTP. Any resulting message mout is given to the adversary.
Page  768: any registration requests that would register a given ID as both an honest and corrupt user.
Page  768: • For a deliver protocol message query, the entry (deliver, I, min , mout , status) is appended to
Page  768: • For a deliver TTP message query, the entry (deliverTTP, min , mout ) is added to the log. Recall
Page  768: that in the o✏ine TTP setting of this chapter, there are no deliver TTP message queries, and
Page  768: The partner function will be computed by the challenger in Experiment 1 each time a deliver
Page  769: Recall that our intuitive notion of authenticity translates into saying that if two users share a key,
Page  769: when a user instance I finishes with a session key I.sk, instead of giving the adversary I.sk, the
Page  769: challenger instead gives the adversary an e↵ective session key I.esk, which is determined (in part)
Page  769: that is, the e↵ective session key is set to the actual session key. Otherwise, I.esk    error.
Page  769: that is, the e↵ective session key is chosen at random. Otherwise, I.esk      error.
Page  769: that is, the e↵ective session key is set to that of this honest user instance’s “partner.” Oth-
Page  769: outputs 1 in Experiment b, we define A’s advantage with respect to a given AKE protocol ⇧ and
Page  770: Remark 21.1. Note that in Experiment 1, the e↵ective session key is set to error if certain validity
Page  770: are partners if their conversations match up bit-by-bit. This can sometimes be overly restrictive,
Page  770: Our formal security definition may seem a bit unintuitive at first. For example, one might ask, why
Page  770: is the adversary given the session keys when the goal of the protocol is supposedly to protect the
Page  770: ticated encryption for each one-directional channel. We can derive all of the necessary keys from
Page  770: may now send and receive messages on its bi-directional channel, using these keys.
Page  771: is both a sender and a receiver. In this implementation of the abstract interface, the logic of the
Page  771: out-box and in-box is implemented using an authenticated encryption scheme and the keys derived
Page  771: real session keys with e↵ective session keys, according to the classification of user instances. Some
Page  771: ciphertexts are just handles and messages magically jump from sender to receiver.
Page  772: When a right instance J finishes, we look at the ID of the certificate it receives. If it belongs
Page  772: Compromise user: The adversary specifies an honest user U . The challenger gives the long-term
Page  772: The second change is to the computation of e↵ective session keys in Experiment 1. Specifically,
Page  772: we change the rule for computing the e↵ective session key for a vulnerable user instance I as follows:
Page  772: against a protocol ⇧ in this modified attack game, with respect to a given partner function pf.
Page  773: Remark 21.3. Even after an honest user is compromised, the adversary may continue delivering
Page  774: The second change is to the computation of e↵ective session keys in Experiment 1. Specifically,
Page  774: we change the rule for computing the e↵ective session key for a vulnerable user instance I as follows:
Page  774: when I was activated and when I finished, and
Page  774: modified attack game, with respect to a given partner function pf.
Page  776: Intuitively, it means that it is hard to compute g ↵ , given g ↵ and access to “DH-decision oracle”
Page  776: (g , g µ ). To this end, we run the attack game knowing ↵. Dividing the first component of (21.5)
Page  777: Since ↵ is known, we can divide out the terms involving ↵, which allows us to compute g µ . However,
Page  777: to solve the CDH problem for the problem instance (g , g µ ), provided we also are given access to
Page  777: compute g ↵ given g ↵ as well as access to an oracle that recognizes DH-triples of the form (g ↵ , · , · ).
Page  777: session keys by a random session keys is not detectable, unless the adversary can compute g µ⌫ given
Page  778: as vulnerable if I.pid = anonymous. That is, we change the rule for computing the e↵ective session
Page  778: In Experiment 1 of the attack game, when computing e↵ective a session key for a user instance,
Page  778: This is just a restatement of the informal constraint given in Section 21.9.6 in the language of our
Page  778: formal model. If this constraint is violated, the e↵ective session key is set to error. Otherwise, it is
Page  779: keys, respectively. Finally, the hash functions H1 , H2 are used to derive symmetric keys. They are
Page  779: After receiving the first flow, the server Q examines the “o↵er” sent by the client. It verifies
Page  780: The key ksh used to encrypt these messages and the key ksm used in applying HMAC are derived
Page  780: After receiving the second flow, the client responds with a flow that consists of several encrypted
Page  780: The key kch used to encrypt these messages and the key kcm used in applying HMAC are derived
Page  780: derived from
Page  781: operation in which it starts using the session key before it receives the third flow. To securely
Page  781: master secret that is known to both P and Q. It can be given to a higher-level application for its
Page  781: own use. This key is e↵ectively independent of all the keys used to secure the TLS session, but
Page  781: Another feature is the ability to update traffic keys. In a long lived TLS session it may be
Page  781: full key-exchange. It skips some of the computationally expensive key exchange steps in Fig. 21.12.
Page  782: where H3 is a key derivation function based on HKDF, and N t is a random nonce from Q provided
Page  782: computed, not sent, and not included in the HMAC and HKDF computations. Instead, the derived
Page  782: where H4 and H5 are key derivation functions based on HKDF. Notice that this abbreviated key
Page  782: u := g ↵ and v := g , as in Fig. 21.12. They are used along with g ↵ in the symmetric key derivation
Page  783: is derived from
Page  783: The server derives the same key kce from the received data and uses it to decrypt the ciphertext
Page  783: cannot depend on the server nonce N s . This key must be derived before the client sees N s . All
Page  783: To prevent replays the server can store the client nonce from every 0-RTT request it receives. If
Page  784: similar to the content displayed on the secure login page. This is usually trivial to do. There
Page  785: with the MAC and key derivation all rolled in to the hash function.)
Page  785: into revealing other sensitive information.
Page  785: not only can the adversary try to obtain sensitive information from the client, as above, but since
Page  786: belongs to a relatively small dictionary D of common passwords. Also suppose that the adversary
Page  787: not very secure in practice: via a phishing attack, an adversary can trick a client into divulging
Page  787: These security problems are the motivation for password authenticated key exchange
Page  787: Assume that pw belongs to some relatively small dictionary D of common passwords. Also
Page  788: We shall give an intuitive argument for this. But first, we introduce some notation, and we
Page  788: The CDH problem is this: given random s, t 2 G, compute [s, t]. The CDH assumption asserts that
Page  789: Intuitively, for a dictionary attack to succeed, the adversary will have to query the random oracle
Page  789: decrypt a given encryption of a known plaintext under k.
Page  789: negligible probability, as follows. Given a challenge instance (s, t) of the CDH problem, set u := s
Page  789: and v := t, and give u and v to our eavesdropping adversary. Now, the adversary will make a
Page  789: security against a dictionary attack by a active adversary, that is, an adversary that participates
Page  789: Assume that pw belongs to some relatively small dictionary D of common passwords. Also
Page  790: attack by an active adversary.
Page  790: attack, by both passive and active adversaries. Like PAKE1 , protocol PAKE2 makes use of a cyclic
Page  790: We now give an informal argument that protocol PAKE2 provides security against dictionary
Page  790: attacks by either an eavesdropping or active adversary, under the CDH assumption, and modeling
Page  791: Intuitively, the adversary’s goal is to query the random oracle at as many relevant points as possible,
Page  791: Lemma 21.7. Under the CDH assumption, the following problem is hard: given random a, b, u, v 2
Page  791: Also, note that [x, g µ ] = xµ , so given any two group elements x and y, if we know the discrete
Page  791: problem with non-negligible probability. Given a challenge instance (s, t) for the CDH problem, we
Page  791: and then we give the adversary
Page  791: Next, consider an active adversary that engages in the protocol with an honest user. We consider
Page  792: Lemma 21.8. Under the CDH assumption, the following problem is hard: given random a, b, u 2 G,
Page  792: Suppose we have a Type I adversary, and that we are given an instance (s, t) of the CDH
Page  792: and give the adversary
Page  792: Dividing the second equation by the first, we obtain
Page  792: Now suppose we have a Type II adversary, and that we are given an instance (s, t) of the CDH
Page  792: and give the adversary
Page  792: Dividing the equation for i = 2, raised to the power 1 , by the equation for i = 1, raised to the
Page  793: server’s password file. Given the password file, the adversary can certainly impersonate the server;
Page  793: Given the password file, an adversary can always mount an o✏ine dictionary attack to discover
Page  793: a given client’s password: the adversary can just run both the client and server side of the protocol,
Page  793: by both eavesdropping and active adversaries. The roles of the two users in that protocol are quite
Page  793: Of course, the client can derive (⇡0 , ⇡1 ) from pw . Both users compute the values w = g ↵ and
Page  794: with the client P at some point, giving an arbitrary value v to P , who raises v/b⇡0 to the power
Page  794: ⇡1 , and derives a session key from this value. Because of this, P acts to a certain degree as a DDH
Page  794: oracle, essentially giving the adversary an oracle for recognizing DH-tuples of the form (g, g ⇡1 , ·, ·).
Page  794: we need to make use of the interactive CDH assumption (see Definition 12.4) to prove security;
Page  794: however, a closer examination shows that this is not the case. This is because in deriving the
Page  794: simple form of what is called explicit key confirmation. Instead of just deriving a session key k
Page  794: from the hash, both users P and Q can derive a keys k0 and k1 , and then:
Page  795: • P checks that the value k̃1 it receives is equal to its computed value k1 ,
Page  795: • Q checks that the value k̃0 it receives is equal to its computed value k0 .
Page  795: can take defensive measures (see Section 18.3.1). Thus, in using PAKE protocols such as PAKE2 or
Page  795: the only reasonable way to do this, short of using a more expensive or less convenient type of secure
Page  796: (c) Suppose that we fix the protocol so that it derives two keys (k 0 , k) H(w), where k 0 is used
Page  797: password chosen at random from some small dictionary D. Show that an active adversary can
Page  797: 21.12 (Non-interactive key exchange). Let G be a group of prime order q generated by
Page  798: interaction, other than reading the bulletin board. This is called non-interactive key exchange
Page  799: Part IV
Page  801: 3. The order of g 2 Z⇤p is the smallest positive integer a such that g a = 1.
Page  801: 4. Lagrange’s theorem:     for all g 2 Z⇤p we have that orderp (g) divides p 1. Observe that
Page  802: We know that if a solution to ax2 + bx + c = 0 mod p exists then it is given by:
Page  803: 1. Let g be a generator of Z⇤p . Given x 2 Z⇤p find an r such that x = g r mod p. This is known
Page  803: 2. Let g be a generator of Z⇤p . Given x, y 2 Z⇤p where x = g r1 and y = g r2 . Find z = g r1 r2 . This
Page  803: An element x 2 Zn has an inverse if and only if x and n are relatively prime. In other words,
Page  804: 1. Let g be a generator of Z⇤n . Given x 2 Z⇤n find an r such that x = g r mod n. This is known
Page  804: 2. Let g be a generator of Z⇤n . Given x, y 2 Z⇤n where x = g r1 and y = g r2 . Find z = g r1 r2 . This
Page  808: We are given an n-bit string T and are told that it is either sampled according to the distribu-
Page  811: In 30th IEEE Symposium on Security and Privacy, pages 16–26, 2009.
Page  811: protocols. In 2013 IEEE Symposium on Security and Privacy, pages 526–540, 2013.
Page  811: University Press, 2012.
Page  811: Cambridge University Press, 1997.
Page  812: Cryptology ePrint Archive, 2017:293, 2017.
Page  813: today, a challenge tomorrow. In 31st IEEE Symposium on Security and Privacy, S&P 2010,
Page  813: [34] V. Costan and S. Devadas. Intel sgx explained. IACR Cryptology ePrint Archive, 2016:086,
Page  813: [35] N. T. Courtois, P. Emirdag, and F. Valsorda. Private key recovery combination attacks:
Page  813: in presence of poor rng events. Cryptology ePrint Archive, Report 2014/848, 2014. http:
Page  814: practices. IEEE Security and Privacy, January 2003.
Page  815: [65] J. Haynes and H. Klehr. Venona: Decoding Soviet Espionage in America. Yale University
Page  815: [66] A. Herzberg, S. Jarecki, H. Krawczyk, and M. Yung. Proactive secret sharing or: How to
Page  815: [75] C. Kaufman, P. Ho↵man, Y. Nir, P. Eronen, and T. Kivinen. Internet key exchange protocol
Page  817: [95] D. Naor, M. Naor, and J. Lotspiech. Revocation and tracing schemes for stateless receivers. In
Page  817: [106] R. Rivest. The MD4 message digest algorithm. In Proceedings of Crypto ’90, volume 537 of
Page  817: [107] R. Rivest. The MD5 message digest algorithm. Internet RFC 1321, 1992.
Page  817: keystore. Cryptology ePrint Archive, Report 2016/677, 2016. http://eprint.iacr.org/
Page  818: [112] V. Shoup. A composition theorem for universal one-way hash functions. In Proceedings of
Page  818: equivalent privacy protocol (WEP). ACM Transactions on Information. Systems Security,
